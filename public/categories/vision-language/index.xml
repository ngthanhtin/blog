<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Vision-Language on Clarity</title>
    <link>fingerstin.org/categories/vision-language/</link>
    <description>Recent content in Vision-Language on Clarity</description>
    <generator>Hugo -- gohugo.io</generator>
    <copyright>Copyright © 2008–2018, Steve Francia and the Hugo Authors; all rights reserved.</copyright>
    <lastBuildDate>Mon, 15 Nov 2021 00:00:00 +0000</lastBuildDate><atom:link href="fingerstin.org/categories/vision-language/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Understanding Sentiment, Emotion and its Intensity by Analysing Meme Images</title>
      <link>fingerstin.org/post/challenge/memotion2/</link>
      <pubDate>Mon, 15 Nov 2021 00:00:00 +0000</pubDate>
      
      <guid>fingerstin.org/post/challenge/memotion2/</guid>
      <description>
        
          
            In this post, I want to introduce a new topic which is took place at First Workshop on ​Multimodal Fact-Checking and Hate Speech Detection in AAAI 2022. And I got the 1st position on the leaderboard of this challenge. Link to the challenge: https://aiisc.ai/defactify/memotion_2.html
1. Abstract In this post, I want to talk about Meme Analysis which is about explaining its Sentiment, Emotion and Intensity.  The growing ubiquity of Internet memes on social media platforms such as Facebook, Instagram, and Twitter further suggests that we can not ignore such multimodal content (vision and language) anymore.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Vietnamese Image Captioning - VLSP for Health 2021</title>
      <link>fingerstin.org/post/challenge/vlsp_imagecaptioning/</link>
      <pubDate>Mon, 15 Nov 2021 00:00:00 +0000</pubDate>
      
      <guid>fingerstin.org/post/challenge/vlsp_imagecaptioning/</guid>
      <description>
        
          
            In this post, I want to talk about Vietnamese Image Captioning for Healthcare domains. The problem is important in the context of Covid-19 eppidemic so the Vietnamese Groups have established a competition about it. It is took place in VLSP 2021 Workshop, and I got the 3rd position on the private leaderboard of this challenge. Link to the challenge: https://vlsp.org.vn/vlsp2021/eval/vieCap4H
1. Abstract This study presents our approach on the automatic Vietnamese image captioning for healthcare domains in text processing tasks of Vietnamese Language and Speech Processing (VLSP) Challenge 2021, as shown in Figure \ref{fig:example}.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Instruction Navigation</title>
      <link>fingerstin.org/post/rl/vision_language_navigation/</link>
      <pubDate>Tue, 02 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>fingerstin.org/post/rl/vision_language_navigation/</guid>
      <description>
        
          
            In this post, I want to introduce a hot topic in Reinforcement Learning which is Instruction Navigation. Although Navigation can be tackled by using Supervised Learning, but using Reinforcement Learning help us learn without any human-labeled data.
Link paper: Paper Link code: Code
The content is as following: 1. Introduction to Instruction Navigation  2. Principle  3. Methodology 
 3.1 Image Representation Module  3.2 Text Representation Module  3.
          
          
        
      </description>
    </item>
    
  </channel>
</rss>
