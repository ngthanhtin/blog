<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta http-equiv="X-UA-Compatible" content="ie=edge" />
    <title>Learning Rate Scheduling in Pytorch | Tin&#39;s Blog</title>

    



<meta name="author" content="Nguyen Thanh Tin" />
<meta name="description" content="" />



<meta name="generator" content="Hugo 0.80.0" />

<link rel="canonical" href="https://ngthanhtin.github.io/blog/ml_technique/learningrate-scheduling/" />


<meta property="og:title" content="Learning Rate Scheduling in Pytorch" />
<meta property="og:description" content="Hi, bài viết hôm nay mình sẽ nói qua một số phương pháp điều chỉnh learning rate trong quá trình train một model hay còn gọi là learning rate scheduler. Việc điều chỉnh learning rate trong quá trình train là một việc rất có lợi để model có thể tìm đc local minima một cách hợp lí hơn.
Nội dung chính sẽ bao gồm các phần sau: 
 Lambda LR." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://ngthanhtin.github.io/blog/ml_technique/learningrate-scheduling/" />
<meta property="article:published_time" content="2021-03-25T00:00:00+00:00" />
<meta property="article:modified_time" content="2021-03-25T00:00:00+00:00" />



<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Learning Rate Scheduling in Pytorch"/>
<meta name="twitter:description" content="Hi, bài viết hôm nay mình sẽ nói qua một số phương pháp điều chỉnh learning rate trong quá trình train một model hay còn gọi là learning rate scheduler. Việc điều chỉnh learning rate trong quá trình train là một việc rất có lợi để model có thể tìm đc local minima một cách hợp lí hơn.
Nội dung chính sẽ bao gồm các phần sau: 
 Lambda LR."/>

<link rel="stylesheet" href="/blog/css/font-awesome.min.css" />
<link rel="stylesheet" href="/blog/css/semantic.min.css" />
<link rel="stylesheet" href="/blog/css/icomoon.css" />
<link rel="stylesheet" href="/blog/css/OverlayScrollbars.min.css" />
<link rel="stylesheet" href="/blog/css/github-markdown.css" />
<link rel="stylesheet" href="/blog/css/site.css" />

<style>
  a:not(.ui.button):hover {
    text-decoration: underline;
  }

  
  a:not(.ui.button) {
    color: seagreen !important;
  }
  

  

  
  body.default {
    
    background-color: #f7f7f7;
    

    
  }
  

  
  body.dark {
    
    background-color: black;
    

    
  }
  
</style>


    







    
  </head>

  <body class="default">
    
<nav class="ui secondary menu dream-menu">

  <div class="item">
    <i class="large link bullseye icon dream-flip-toggle" title="Flip it!"></i>
  </div>
  <div class="item">
    <i class="large link home icon" title="Blog" onclick="window.location.href = 'https:\/\/ngthanhtin.github.io\/blog\/'"></i>
  </div>
  <div class="item">
    <a href="https://ngthanhtin.github.io/"><i class="fa fa-flask" title="ngthanhtin.github.io"></i></a>
  </div>
  
  
  <div class="item">
    <i class="large link icon theme-switch" onclick="themeSwitch()"></i>
  </div>
  
  
</nav>

    <div class="flip-container">
      <div class="flipper">
        <section class="front">
          <div class="dream-max-width">
            
<div class="ui relaxed grid dream-grid">
  <aside class="sixteen wide mobile sixteen wide tablet four wide computer column dream-single-aside">
    
    
    <div class="ui segment toc">
      <nav id="TableOfContents">
  <ul>
    <li>
      <ul>
        <li><a href="#1-lambda-lr">1. Lambda LR.</a></li>
        <li><a href="#2-multiplicative-lr">2. Multiplicative LR.</a></li>
        <li><a href="#3-step-lr">3. Step LR.</a></li>
        <li><a href="#4-multistep-lr">4. MultiStep LR.</a></li>
        <li><a href="#5-exponential-lr">5. Exponential LR.</a></li>
        <li><a href="#6-cosineannealing-lr">6. CosineAnnealing LR.</a></li>
        <li><a href="#7-cyclic-lr">7. Cyclic LR.</a></li>
        <li><a href="#8-onecycle-lr">8. OneCycle LR.</a></li>
        <li><a href="#9-cosine-annealing-warm-restarts">9. Cosine Annealing Warm Restarts.</a></li>
      </ul>
    </li>
  </ul>
</nav>
    </div>
    
    <div class="ui segment actions">
      <button
        class="ui circular icon button save-as-image"
        title="Save as image"
        onclick="savePostAsImg()">
        <i class="save icon"></i>
      </button>

      <a href="https://twitter.com/intent/tweet?text=Learning%20Rate%20Scheduling%20in%20Pytorch&url=https%3a%2f%2fngthanhtin.github.io%2fblog%2fml_technique%2flearningrate-scheduling%2f" class="ui circular twitter icon button">
  <i class="twitter icon"></i>
</a>
<a href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fngthanhtin.github.io%2fblog%2fml_technique%2flearningrate-scheduling%2f" class="ui circular facebook icon button">
  <i class="facebook icon"></i>
</a>

    </div>
  </aside>
  <div class="sixteen wide mobile sixteen wide tablet twelve wide computer column markdown-body dream-single" id="dream-save-post-as-img">
    
    <section class="ui top attached segment">
      <header>
        <h1 class="ui large header">Learning Rate Scheduling in Pytorch<div class="sub header">
            @
            
              Nguyen Thanh Tin
            

            | 
                Thursday, Mar 25, 2021
              

            | 4 minutes read

            | Update at
              
                Thursday, Mar 25, 2021
              
          </div>
        </h1>
      </header>

      <article class="main"><p>Hi, bài viết hôm nay mình sẽ nói qua một số phương pháp điều chỉnh learning rate trong quá trình train một model hay còn gọi là <b>learning rate scheduler</b>. Việc điều chỉnh learning rate trong quá trình train là một việc rất có lợi để model có thể tìm đc local minima một cách hợp lí hơn.</p>
<p>Nội dung chính sẽ bao gồm các phần sau: <br/></p>
<ol>
<li>Lambda LR.</li>
<li>Multiplicative LR.</li>
<li>Step LR.</li>
<li>MultiStep LR.</li>
<li>Exponential LR.</li>
<li>CosineAnnealing LR.</li>
<li>Cyclic LR.</li>
<li>OneCycle LR.</li>
<li>Cosine Annealing Warm Restarts.</li>
</ol>
<h3 id="1-lambda-lr">1. Lambda LR.</h3>
<p align="center">
<img src="https://render.githubusercontent.com/render/math?math=lr_{epoch} = lr_{initial} * lambda_{epoch}">
</p>
<pre><code>model = torch.nn.Linear(2, 1)
optimizer = torch.optim.SGD(model.parameters(), lr=100)
lambda1 = lambda epoch: 0.65 ** epoch
scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda1)


lrs = []

for i in range(10):
    optimizer.step()
    lrs.append(optimizer.param_groups[0][&quot;lr&quot;])
    scheduler.step()

plt.plot(range(10),lrs)
</code></pre><p align="center">
  <img src="/blog/img/learningrate_scheduling/lambdaLR.png">
</p>
<h3 id="2-multiplicative-lr">2. Multiplicative LR.</h3>
<p align="center">
<img src="https://render.githubusercontent.com/render/math?math=lr_{epoch} = lr_{epoch-1} * lambda_{epoch}">
</p>
<pre><code>model = torch.nn.Linear(2, 1)
optimizer = torch.optim.SGD(model.parameters(), lr=100)
lmbda = lambda epoch: 0.65 ** epoch
scheduler = torch.optim.lr_scheduler.MultiplicativeLR(optimizer, lr_lambda=lmbda)
lrs = []

for i in range(10):
    optimizer.step()
    lrs.append(optimizer.param_groups[0][&quot;lr&quot;])
#     print(&quot;Factor = &quot;,0.95,&quot; , Learning Rate = &quot;,optimizer.param_groups[0][&quot;lr&quot;])
    scheduler.step()

plt.plot(range(10),lrs)
</code></pre><p align="center">
  <img src="/blog/img/learningrate_scheduling/multiplicativeLR.png">
</p>
<h3 id="3-step-lr">3. Step LR.</h3>
<p>Giảm learning rate theo gamma ở mỗi step size của mỗi epoch.<br/></p>
<p align="center">
<img src="https://render.githubusercontent.com/render/math?math=lr_{epoch} =  \begin{cases}
                  \gamma * lr_{epoch-1} \\
                  lr_{epoch-1}
                  \end{cases}">
</p>
<pre><code>model = torch.nn.Linear(2, 1)
optimizer = torch.optim.SGD(model.parameters(), lr=100)
scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.1)
lrs = []

for i in range(10):
    optimizer.step()
    lrs.append(optimizer.param_groups[0][&quot;lr&quot;])
#     print(&quot;Factor = &quot;,0.1 if i!=0 and i%2!=0 else 1,&quot; , Learning Rate = &quot;,optimizer.param_groups[0][&quot;lr&quot;])
    scheduler.step()

plt.plot(range(10),lrs)
</code></pre><p align="center">
  <img src="/blog/img/learningrate_scheduling/stepLR.png">
</p>
<h3 id="4-multistep-lr">4. MultiStep LR.</h3>
<p>Giảm learning rate theo gamma mỗi khi số lượng epoch đạt tới một giá trị trong milestones (<img src="https://render.githubusercontent.com/render/math?math=lr_{epoch} \in milestones">)</p>
<p align="center">
<img src="https://render.githubusercontent.com/render/math?math=lr_{epoch} =  \begin{cases}
                  \gamma * lr_{epoch-1} \\
                  lr_{epoch-1}
                  \end{cases}">
</p>
<pre><code>model = torch.nn.Linear(2, 1)
optimizer = torch.optim.SGD(model.parameters(), lr=100)
scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[6,8,9], gamma=0.1)
lrs = []

for i in range(10):
    optimizer.step()
    lrs.append(optimizer.param_groups[0][&quot;lr&quot;])
#     print(&quot;Factor = &quot;,0.1 if i in [6,8,9] else 1,&quot; , Learning Rate = &quot;,optimizer.param_groups[0][&quot;lr&quot;])
    scheduler.step()

plt.plot(range(10),lrs)
</code></pre><p align="center">
  <img src="/blog/img/learningrate_scheduling/multistepLR.png">
</p>
<h3 id="5-exponential-lr">5. Exponential LR.</h3>
<p align="center">
<img src="https://render.githubusercontent.com/render/math?math=lr_{epoch} = lr_{epoch-1} * \gamma">
</p>
<pre><code>model = torch.nn.Linear(2, 1)
optimizer = torch.optim.SGD(model.parameters(), lr=100)
scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.1)
lrs = []


for i in range(10):
    optimizer.step()
    lrs.append(optimizer.param_groups[0][&quot;lr&quot;])
#     print(&quot;Factor = &quot;,0.1,&quot; , Learning Rate = &quot;,optimizer.param_groups[0][&quot;lr&quot;])
    scheduler.step()

plt.plot(lrs)
</code></pre><p align="center">
  <img src="/blog/img/learningrate_scheduling/exponentialLR.png">
</p>
<h3 id="6-cosineannealing-lr">6. CosineAnnealing LR.</h3>
<p>Được đề xuất trong bài SGDR: Stochastic Gradient Descent with Warm Restarts. Link: <a href="https://arxiv.org/abs/1608.03983">https://arxiv.org/abs/1608.03983</a></p>
<p align="center">
<img src="https://render.githubusercontent.com/render/math?math=\eta_{t}_ = \eta_{min} %2B \frac{1}{2}(\eta_{max} - \eta_{min})(1 - cos(\frac{T_{cur}}{T_{max}}\pi))">
</p>
<pre><code>model = torch.nn.Linear(2, 1)
optimizer = torch.optim.SGD(model.parameters(), lr=100)
scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10, eta_min=0)
lrs = []


for i in range(100):
    optimizer.step()
    lrs.append(optimizer.param_groups[0][&quot;lr&quot;])
#     print(&quot;Factor = &quot;,i,&quot; , Learning Rate = &quot;,optimizer.param_groups[0][&quot;lr&quot;])
    scheduler.step()

plt.plot(lrs)
</code></pre><p align="center">
  <img src="/blog/img/learningrate_scheduling/cosineanealingLR.png">
</p>
<h3 id="7-cyclic-lr">7. Cyclic LR.</h3>
<h4 id="71-triangular">7.1 Triangular.</h4>
<pre><code>model = torch.nn.Linear(2, 1)
optimizer = torch.optim.SGD(model.parameters(), lr=0.1)
scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=0.001, max_lr=0.1,step_size_up=5,mode=&quot;triangular&quot;)
lrs = []


for i in range(100):
    optimizer.step()
    lrs.append(optimizer.param_groups[0][&quot;lr&quot;])
#     print(&quot;Factor = &quot;,i,&quot; , Learning Rate = &quot;,optimizer.param_groups[0][&quot;lr&quot;])
    scheduler.step()

plt.plot(lrs)
</code></pre><p align="center">
  <img src="/blog/img/learningrate_scheduling/cyclicalLR_triangular.png">
</p>
<h4 id="72-triangular2">7.2 Triangular2.</h4>
<pre><code>model = torch.nn.Linear(2, 1)
optimizer = torch.optim.SGD(model.parameters(), lr=0.1)
scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=0.001, max_lr=0.1,step_size_up=5,mode=&quot;triangular2&quot;)
lrs = []


for i in range(100):
    optimizer.step()
    lrs.append(optimizer.param_groups[0][&quot;lr&quot;])
#     print(&quot;Factor = &quot;,i,&quot; , Learning Rate = &quot;,optimizer.param_groups[0][&quot;lr&quot;])
    scheduler.step()

plt.plot(lrs)
</code></pre><p align="center">
  <img src="/blog/img/learningrate_scheduling/cyclicalLR_triangular2.png">
</p>
<h4 id="73-exp_range">7.3 Exp_range.</h4>
<pre><code>model = torch.nn.Linear(2, 1)
optimizer = torch.optim.SGD(model.parameters(), lr=100)
scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=0.001, max_lr=0.1,step_size_up=5,mode=&quot;exp_range&quot;,gamma=0.85)
lrs = []


for i in range(100):
    optimizer.step()
    lrs.append(optimizer.param_groups[0][&quot;lr&quot;])
#     print(&quot;Factor = &quot;,i,&quot; , Learning Rate = &quot;,optimizer.param_groups[0][&quot;lr&quot;])
    scheduler.step()

plt.plot(lrs)
</code></pre><p align="center">
  <img src="/blog/img/learningrate_scheduling/cyclicalLR_exp.png">
</p>
<h3 id="8-onecycle-lr">8. OneCycle LR.</h3>
<p>Learning rate được thay đổi theo phương pháp 1cycle learning rate policy. 1cycle policy tăng learning rate từ giá trị ban đầu tới một giá trị maximum nào đó sau đó giảm xuống một giá trị minimum còn nhỏ hơn giá trị learning rate ban đầu.<br/>
Phương pháp này được đề xuất đầu tiên ở paper Super-Convergence: Very Fast Training of Neural Networks Using Large Learning Rates.<br/>
The 1cycle learning rate policy thay đổi the learning rate sau mỗi batch.<br/></p>
<h4 id="81-cos">8.1 Cos.</h4>
<pre><code>model = torch.nn.Linear(2, 1)
optimizer = torch.optim.SGD(model.parameters(), lr=0.1)
scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=0.1, steps_per_epoch=10, epochs=10)
lrs = []


for i in range(100):
    optimizer.step()
    lrs.append(optimizer.param_groups[0][&quot;lr&quot;])
#     print(&quot;Factor = &quot;,i,&quot; , Learning Rate = &quot;,optimizer.param_groups[0][&quot;lr&quot;])
    scheduler.step()

plt.plot(lrs)
</code></pre><p align="center">
  <img src="/blog/img/learningrate_scheduling/onecycleLR_cos.png">
</p>
<h4 id="81-linear">8.1 Linear.</h4>
<pre><code>model = torch.nn.Linear(2, 1)
optimizer = torch.optim.SGD(model.parameters(), lr=0.1)
scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=0.1, steps_per_epoch=10, epochs=10,anneal_strategy='linear')
lrs = []


for i in range(100):
    optimizer.step()
    lrs.append(optimizer.param_groups[0][&quot;lr&quot;])
#     print(&quot;Factor = &quot;,i,&quot; , Learning Rate = &quot;,optimizer.param_groups[0][&quot;lr&quot;])
    scheduler.step()

plt.plot(lrs)
</code></pre><p align="center">
  <img src="/blog/img/learningrate_scheduling/onecycleLR_linear.png">
</p>
<h3 id="9-cosine-annealing-warm-restarts">9. Cosine Annealing Warm Restarts.</h3>
<p>Đặt learning rate sử dụng một cosine annealing schedule, và restarts lại sau Ti epochs.<br/></p>
<p align="center">
<img src="https://render.githubusercontent.com/render/math?math=\eta_{t}_ = \eta_{min} %2B \frac{1}{2}(\eta_{max} - \eta_{min})(1 - cos(\frac{T_{cur}}{T_{i}}\pi))">
</p>
<pre><code>import torch
import matplotlib.pyplot as plt

model = torch.nn.Linear(2, 1)
optimizer = torch.optim.SGD(model.parameters(), lr=0.1)
lr_sched = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=1, eta_min=0.001, last_epoch=-1)


lrs = []

for i in range(100):
    lr_sched.step()
    lrs.append(
        optimizer.param_groups[0][&quot;lr&quot;]
    )

plt.plot(lrs)
</code></pre><p align="center">
  <img src="/blog/img/learningrate_scheduling/cosineanealing_warmrestartLR.png">
</p>
<pre><code>import torch
import matplotlib.pyplot as plt

model = torch.nn.Linear(2, 1)
optimizer = torch.optim.SGD(model.parameters(), lr=0.1)
lr_sched = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2, eta_min=0.01, last_epoch=-1)


lrs = []

for i in range(300):
    lr_sched.step()
    lrs.append(
        optimizer.param_groups[0][&quot;lr&quot;]
    )

plt.plot(lrs)
</code></pre><p align="center">
  <img src="/blog/img/learningrate_scheduling/cosineanealing_warmrestartLR2.png">
</p>
<div style="text-align: right"> (Tín Nguyễn) </div>
</article>
    </section>

    

    
    <article class="ui segment utterances-comments" data-html2canvas-ignore>
      <script src="https://utteranc.es/client.js"
        repo="ngthanhtin/blog"
        issue-term="pathname"
        label="comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
      </script>
    </article>
    

    
  </div>
</div>


            <footer class="ui basic center aligned segment" style="background-color: transparent;">
              
              <p>© 2021 Tin&#39;s Blog</p>
              

              <p>Powered by <a href="https://gohugo.io/" target="_blank">Hugo</a> with theme <a href="https://github.com/g1eny0ung/hugo-theme-dream" target="_blank">Dream</a>.</p>

              
            </footer>
          </div>
        </section>
        <section class="back">
          <div class="dream-max-width">
            <header class="ui basic very padded segment dream-header">
  <div class="ui small circular image">
    
    <img src="/blog/img/avatar.png" />
    
  </div>

  <div class="content">
    <h1 class="ui medium header">Nguyen Thanh Tin&#39;s blog<div class="sub header">luffy</div>
    </h1>

    <article class="ui horizontal list">
      
      <a class="item" href="/blog/categories">
        <i class="th list icon" title="All Categories"></i>
      </a>
      <a class="item" href="/blog/tags">
        <i class="tags icon" title="All Tags"></i>
      </a>
    </article>

    
    <article class="dream-tags">
    
      
      
      <a class="ui label" href="/blog/tags/donate/" title="Donate">Donate</a>
    
      
      
      <a class="ui label" href="/blog/tags/english/" title="English">English</a>
    
      
      
      <a class="ui label" href="/blog/tags/ielts/" title="Ielts">Ielts</a>
    
      
      
      <a class="ui label" href="/blog/tags/korea/" title="Korea">Korea</a>
    
      
      
      <a class="ui label" href="/blog/tags/ml-basic/" title="Ml Basic">Ml Basic</a>
    
      
      
      <a class="ui label" href="/blog/tags/ml-technique/" title="Ml Technique">Ml Technique</a>
    
      
      
      <a class="ui label" href="/blog/tags/multiple-object-tracking/" title="Multiple Object Tracking">Multiple Object Tracking</a>
    
      
      
      <a class="ui label" href="/blog/tags/optimization-math/" title="Optimization Math">Optimization Math</a>
    
      
      
      <a class="ui label" href="/blog/tags/personal/" title="Personal">Personal</a>
    
      
      
      <a class="ui label" href="/blog/tags/reinforcement-learning/" title="Reinforcement Learning">Reinforcement Learning</a>
    
      
      
      <a class="ui label" href="/blog/tags/scholarship/" title="Scholarship">Scholarship</a>
    
      
      
      <a class="ui label" href="/blog/tags/single-object-tracking/" title="Single Object Tracking">Single Object Tracking</a>
    
      
      
      <a class="ui label" href="/blog/tags/slam/" title="Slam">Slam</a>
    
      
      
      <a class="ui label" href="/blog/tags/software-tips/" title="Software Tips">Software Tips</a>
    
      
      
      <a class="ui label" href="/blog/tags/vision-language/" title="Vision Language">Vision Language</a>
    
      
      
      <a class="ui label" href="/blog/tags/winter/" title="Winter">Winter</a>
    
    </article>
    
  </div>
</header>


<div class="ui relaxed grid dream-grid dream-back">
  
  
  

  <div class="sixteen wide mobile eight wide tablet four wide computer column dream-column">
    <article class="ui segment">
      <h3 class="ui header">Social Links</h3>
      <nav class="ui secondary menu dream-menu dream-socials">
  

  
  <div class="item">
    <a href="mailto:ngthanhtinqn@gmail.com">
      <i class="large mail icon" title="Email"></i>
    </a>
  </div>
  

  

  

  

  

  

  

  

  
</nav>

    </article>
  </div>

  <div class="sixteen wide mobile eight wide tablet four wide computer column dream-column">
    
  </div>

  
  
  
</div>

          </div>
        </section>
      </div>
    </div>

    <script>
  window.defaultDark =  null 
  window.backgroundDark = "black"
  window.backgroundImageDark =  null 
  window.darkNav =  null 
  window.hasTwitterEmbed =  null 

  if (window.hasTwitterEmbed) {
    
    window.twttr = (function (d, s, id) {
      var js,
        fjs = d.getElementsByTagName(s)[0],
        t = window.twttr || {}
      if (d.getElementById(id)) return t
      js = d.createElement(s)
      js.id = id
      js.src = 'https://platform.twitter.com/widgets.js'
      fjs.parentNode.insertBefore(js, fjs)

      t._e = []
      t.ready = function (f) {
        t._e.push(f)
      }

      return t
    })(document, 'script', 'twitter-wjs')
  }
</script>
<script src="/blog/js/jquery.min.js"></script>
<script src="/blog/js/semantic.min.js"></script>
<script src="/blog/js/jquery.overlayScrollbars.min.js"></script>
<script src="/blog/js/header.js"></script>
<script src="/blog/js/main.js"></script>
<script src="/blog/js/theme.js"></script>

    
<script src="/blog/js/html2canvas.min.js"></script>
<script src="/blog/js/post.js"></script>





    

    

    
  </body>
</html>
