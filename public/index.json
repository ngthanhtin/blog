[{"body":"","link":"fingerstin.org/","section":"","tags":null,"title":""},{"body":"","link":"fingerstin.org/tags/idea/","section":"tags","tags":null,"title":"idea"},{"body":"","link":"fingerstin.org/series/personal/","section":"series","tags":null,"title":"Personal"},{"body":"","link":"fingerstin.org/tags/personal/","section":"tags","tags":null,"title":"personal"},{"body":"","link":"fingerstin.org/post/","section":"post","tags":["index"],"title":"Posts"},{"body":"","link":"fingerstin.org/tags/presentation/","section":"tags","tags":null,"title":"presentation"},{"body":" Idea 2024\n [2024] Idea Proposal   Lab Meeting 2024\n [Jul 10, 2024] Why are Visually-Grounded Language Models Bad at Image Classification   [May 16, 2024] Hierarchical Open-vocabulary Universal Image Segmentation   [Apr 16, 2024] GLaMM: Pixel Grounding Large Multimodal Model   [Mar 12, 2024] Improved Zero-shot Classification by Adapting VLMs with Text Descriptions   [Jan 30, 2024] Classification based on Boxes and Phrases (Research Project)  2023\n [Nov 21, 2023] What does CLIP know about a red circle? Visual prompt engineering for VLMs   [Oct 3, 2023] CLIP-Event: Connecting Text and Images with Event Structures   [Aug 25, 2023] How does ‚Äúhabitat‚Äù help fine-grained bird identification? (Research Project)   [Apr 25, 2023] Zero-Shot Classification by Logical Reasoning on Natural Language Explanations   [Mar 21, 2023] Open-Vocabulary Semantic Segmentation With Mask-Adapted CLIP    [Feb 14, 2023] STAIR: Learning Sparse Text and Image Representation in Grounded Tokens  2022\n [Nov 22, 2022] Re-labeling ImageNet - from Single to Multi-Labels, from Global to Localized Labels   [Oct 18, 2022] Class Activation Latent Mapping - Keep CALM and Improve Visual Feature Attribution   [Sep 20, 2022] Mask2Former: Masked-attention Mask Transformer for Universal Image Segmentation    ","link":"fingerstin.org/post/personal/presentations/","section":"post","tags":["personal","idea","presentation","talk"],"title":"Presentations"},{"body":"","link":"fingerstin.org/series/","section":"series","tags":null,"title":"Series"},{"body":"","link":"fingerstin.org/tags/","section":"tags","tags":null,"title":"Tags"},{"body":"","link":"fingerstin.org/tags/talk/","section":"tags","tags":null,"title":"talk"},{"body":"","link":"fingerstin.org/tags/guitar/","section":"tags","tags":null,"title":"Guitar"},{"body":"    Start learning guitar: 12-2023. K·ªâ ni·ªám 8 th√°ng h·ªçc guitar, c≈©ng d√°nh s∆° s∆° ƒë∆∞·ª£c fingerstyle. Hi v·ªçng c√≥ nhi·ªÅu th·ªùi gian h∆°n ƒë·ªÉ luy·ªán ng√≥n, c·∫£m √¢m v√† t·∫≠p th√™m b√†i m·ªõi, th√™m ƒë·ªám h√°t v√† nh·∫°c l√≠ n·ªØa. ü§ò Youtube Channel: https://www.youtube.com/@tinnguyen2828\nEtude 1:  Kiss the rain: Em c√≥ ·ªïn kh√¥ng: https://www.youtube.com/watch?v=afnC5jO4HC4  Sunflower: X·ª© thanh hoa:\n","link":"fingerstin.org/post/guitar/guitar/","section":"post","tags":["Guitar","Hobby"],"title":"Guitar"},{"body":"","link":"fingerstin.org/tags/hobby/","section":"tags","tags":null,"title":"Hobby"},{"body":"","link":"fingerstin.org/tags/ai/","section":"tags","tags":null,"title":"AI"},{"body":"  Deep Learning Foundations and Concepts (Christopher M. Bishop with Hugh Bishop) 2024    Build a Large Language Model (From Scratch) (Sebastian Raschka)   ","link":"fingerstin.org/post/books/ai/","section":"post","tags":["Book","AI"],"title":"AI Books"},{"body":"","link":"fingerstin.org/tags/book/","section":"tags","tags":null,"title":"Book"},{"body":"Things I want to do before I die. Please let me know if you have any recommendation. Progress as of Jul 12, 2024: 8/100.\n ‚ùå Learn Japanese ‚úÖ Study abroad „ÄΩÔ∏è Learn guitar and start a youtube channel „ÄΩÔ∏è Learn soccer and establish a team ‚úÖ Work in an international company ‚úÖ Publish paper in some pronounced conferences/journals „ÄΩÔ∏è Become the first author of a paper at a top-tier conference ~ (had a pub in a top-tier NLP conf, waiting for a top-tier CV conf) ‚úÖ Fall in love  ","link":"fingerstin.org/post/personal/list100/","section":"post","tags":["personal"],"title":"List 100"},{"body":"","link":"fingerstin.org/post/books/misc/","section":"post","tags":["Book"],"title":"Misc Books"},{"body":"General Questions You Will be Asked: Tip: Ask early on: What the interviewing faculty is working on? (this gives an idea of what he/she sees as a possible alignment to your own research work).\nRead up on their recent work and ask relevant questions or pose possible extensions. Ask good questions.\n Tell us about yourself. Why‚Äôd you apply here? Or What drew you to this program?   Research fit, what is that they are doing that excites you? Interdisciplinary, collaborations, etc.  Why do you want to work with ___? What‚Äôs something you want to study? Tell us about your interests, and what you wish to work on? What do you hope to do after? What are your strengths \u0026amp; weaknesses?   Strengths: Good at collaborations, perseverance, hardworking, help others, learning, teaching, decent research experience. Weaknesses: improve my writing (I am getting better at it). Overcome this with experience and practice.  Questions for us?  Describe your research experiences.   Know the big picture/significance of the work, and also the finer details of what you specifically did experimentally.\n  What would you do if you could continue to work on the research project longer term?\nComments: Be honest, positive, enthusiastic, have ideas, do not come across as rigid.\nYour Story and Todos:  Read your SOPs Research Interests Read all your papers and make notes. Key contributions, your role, shortcomings, future work. Have a short sales pitch presentation on your work (~10 slides). Keep backup slides in case you might have to go into more details.  Questions to Ask the Faculty:  What are the current projects that your group is involved with? Or possible newer projects?  What are some of the projects that you and your students are currently working on?   What is the lab structure? (how collaborative/disjointed are lab members‚Äô projects?)  Ask about collaborations, training grants, the campus, the city, etc.   Are there lab meetings? What are other meetings you will see your advisor in a group with other people? What progress does the advisor generally expect from a student in the course of a semester? (Submission/Publication pace) How much freedom do you think I‚Äôd have in selecting my own projects? What other expectations does the advisor have for their students: time/vacation/paper/project/experiment wise etc. Where does their funding primarily come from? (If military / industry-focused funding bothers you, figure this out).  Is there a TA requirement? / How often would I be expected to TA?   What have previous lab members done after getting their PhD? How many students are in the group? (Number of undergrad/masters/phd/post doc)  NOTE: Most of these might seem generic, but tailor them according to your research area, and speak with confidence on the work you have done. Technical Interview Questions: https://github.com/Sroy20/machine-learning-interview-questions\nReferences  PhD Interview Prep: https://docs.google.com/document/d/13ZUx7AvLUIV4IUkzjU1HoT2czex9DA3NLd8zkeyGUlE/edit Grad School Interview Questions and Answers!: https://www.youtube.com/watch?v=Jt1YP1Th4ZE PhD Interview Questions: https://www.youtube.com/watch?v=0t51IEfiSMg PhD Admissions Visit: https://www.youtube.com/watch?v=OugQPPVM-wc  (T√≠n Nguy·ªÖn)  ","link":"fingerstin.org/post/personal/faq_phd_interviews/","section":"post","tags":["scholarship","personal","US"],"title":"PhD Interviews"},{"body":"","link":"fingerstin.org/tags/scholarship/","section":"tags","tags":null,"title":"scholarship"},{"body":"","link":"fingerstin.org/tags/us/","section":"tags","tags":null,"title":"US"},{"body":"","link":"fingerstin.org/categories/","section":"categories","tags":null,"title":"Categories"},{"body":"In this post, I want to introduce a new topic which is took place at First Workshop on ‚ÄãMultimodal Fact-Checking and Hate Speech Detection in AAAI 2022. And I got the 1st position on the leaderboard of this challenge. Link to the challenge: https://aiisc.ai/defactify/memotion_2.html\n1. Abstract In this post, I want to talk about Meme Analysis which is about explaining its Sentiment, Emotion and Intensity.  The growing ubiquity of Internet memes on social media platforms such as Facebook, Instagram, and Twitter further suggests that we can not ignore such multimodal content (vision and language) anymore. To the best of our knowledge, there is not much attention towards meme emotion, and sentiment analysis.  The task of Memotion analysis consists of three task (1) sentiment(positive, negative, neutral) classification, (2) emotion (sarcastic,funny,offensive, motivation) classification and (3) their corresponding intensity. \nHere is some example of Meme Images, they contain two information simultaneously which is text and image: \n2. Model The models consist of 3 primary types which are Unimodal for Only Text, Unimodal for Only Image, Multimodal for Text and Image. In the Multimodal, I also employed several fusion mechanism such as Concatenation, Multihop Attention, and Stacked Attention. \n2.1 Unimodal for Text BERT and its variant, e.g., RoBERTa, are widely used in Natural Language Processing (NLP) tasks and have demonstrated as efficient methods. In this competition, we employed them for three subtasks. In subtasks A and B, a RoBERTa is used while in subtask C, four RoBERTa models are adopted so that every backbone corresponds classifying the intensity of each emotion.\n2.2 Unimodal for Image As a vision-based approach, EfficientNet-v2 is a well-known backbone with respect to speedy inference and a low number of parameters. In three subtasks, EfficientNet-v2 is used as an extractor to create embeddings. Subtask A has one classification branch to deal with three sentiment types while subtasks B and C have four branches which each is responsible for classifying four types of emotions as well as their intensity.\n2.3 Multimodal Multi-modality is to aggregate vision and text to obtain correlated information. In this challenge, we build three different fusion models including concatenation, multi-hop attention, and stacked attention network.\n2.3.1 Concatenation Traditionally, concatenation of two feature vectors, a.k.a two modalities, has been a typical solution to obtain aggregated features. However, the method does not take into account the importance of each word that is within corresponding regions of the image.\n2.3.2 Multi-hop Attention Multi-hop attention focuses parts of a given image together with texts within it. The technique aims to emphasize dissimilar features between image regions and textual utterances by defining a relevant matrix $R$, which is the cosine distance between textual and visual features.\n2.3.3 Stacked Attention While a multi-hop attention network is used to learn attention maps between an image and texts within it, a stacked attention network has a capability of learning an attention map in multiple times. Through such attention layers, interested regions are promoted through a referred concept within a given sentence.\n3. Techniques In this competition, I have used some techniques to improve the F1 scores of the model.\n3.1 Scence Text Detection Although both textual and visual features are important for meme emotion analysis, there is little correlation between them in the MEMOTION 2.0 dataset. Besides, the caption is also provided as a part of the dataset. Therefore, in this study, the text is removed from the image before extracting and training the proposed model.\nBased on the previous works that summarized both traditional and deep learning approaches for text detection and recognition, we design a preprocessing scheme to remove texts from images as follows. First, we employ the EAST module to detect all text regions in an image. Then these regions are removed from the image, and we use the output image as the input for EfficientNet-v2 in the proposed framework.\nPreprocessing scheme: Given an image as input, we use the EAST detector to detect the region of texts on the image and then remove them 3.2 Auto Augmentation Augmentation is a simple but important technique to increase the size of a given dataset, leading to a better generalization of a training model. However, current data augmentation is based on a set of manually designed algorithms such as Crop, Rotation, and Resize. In our experiment, we adopt the Auto Augment technique which uses reinforcement learning to automatically search for a better data augmentation strategy.\n3.3 Canonical Correlation Analysis The Canonical correlation analysis (CCA) is based on a well-established statistical technique that searches for a linear combination of input vectors by maximizing their correlations. Deep CCA tries to utilize the power of both deep neural networks and CCA to overcome projection constraints of CCA . In this study, correlation scores obtained from Deep CCA is included to our loss function to maximize the correlation between two features, leading to a higher classification rate.\n3.4 Loss function, Optimizer, etc For the classification task, I use CrossEntropy typically, but I also tested on Training Signal Anealing CrossEntropy which is a loss function that helps mitigate the imbalance effect of the dataset.  In terms of Optimizer, I tried several ones such as Adam, SGD, AdamW, LookAHead, etc.\n4. Result Some note about this competition: This is not a fair competition because after the private phase, they recruited more teams to submit and manipulated the results several times. This is quite a pity because I didn't notice that all the chair is Indian.... 5. Application Analysis meme images can help social media platforms such as Facebook, Twitter mitigate the false information that are disemminating widely. Moreover, the technique in this post can be applied to other Vision Language problems.\n6. Code and Paper Link code: Code  Link paper: Paper\n(T√≠n Nguy·ªÖn) ","link":"fingerstin.org/post/challenge/memotion2/","section":"post","tags":["Vision-Language"],"title":"Understanding Sentiment, Emotion and its Intensity by Analysing Meme Images"},{"body":" In this post, I want to talk about Vietnamese Image Captioning for Healthcare domains. The problem is important in the context of Covid-19 eppidemic so the Vietnamese Groups have established a competition about it. It is took place in VLSP 2021 Workshop, and I got the 3rd position on the private leaderboard of this challenge. Link to the challenge: https://vlsp.org.vn/vlsp2021/eval/vieCap4H\n1. Abstract This study presents our approach on the automatic Vietnamese image captioning for healthcare domains in text processing tasks of Vietnamese Language and Speech Processing (VLSP) Challenge 2021, as shown in Figure \\ref{fig:example}. In recent years, image captioning often employs a convolutional neural network-based architecture as an encoder and a long short-term memory (LSTM) as a decoder to generate sentences. These models perform remarkably well in different datasets. Our proposed model also has an encoder and a decoder, but we instead use a Swin Transformer in the encoder, and a LSTM combined with an attention module in the decoder. The study presents our training experiments and techniques used during the competition. Our model achieves a BLEU4 score of 0.293 in the vietCap4H dataset, and the score is ranked 3$^{rd}$ on the private leaderboard.\nHere is some example of the dataset including an image and its caption\n2. Model Our model as shown here is an end-to-endfusion of a Swin Transformer encoder and bidirec-tional LSTM (biLSTM) decoder. The model takes in an image and outputs the corresponding caption. \n3. Techniques In this competition, I have used some techniques to improve the BLEU4 score, they are listed below: \n3.1 Cross Validation Cross Validation is a well-known technique that helps us choose the best model checkpoint among different folds. In this challenge, we train with 4 folds and choose the one that gives the best score on the leaderboard.\n3.2 Noise Injection In the field of image captioning, the accuracy ofprediction for the next character can be relativelyhigh if we can ensure that the previous sequenceis predicted correctly. However, if a character is mispredicted, then the prediction failure rate will gradually increase. To tackle the above issue, we use noise injection, which is done by randomly replacing ground truth characters with other characters during training, and new sentences will be called fake_labels. Then, using the modified sentences as the input for the decoder will force it to correctly predict the next character on the basis that the previous one was wrong.\n3.3 Beam search The algorithm is a best first search algorithm which iteratively considers the set of the k best sentences up to time (t) as candidates to generate sentences of size(t+ 1), and keep only the resulting bestkof them because this better approximates the probability of getting the global maximum. We tried beam search sizes from 1 to 10, and the best BLEU4 score achieved with a beam size 2.\n4. Result I got the 3rd position on the leaderboard, and some evolution of my attempt is shown here: \n5. Application Solving the problem leads to several practical applications such as virtual assistants for blind and visually impaired people, conducting visual content indexing and searching.\n6. Code and Paper Link code: Code  Link paper: Paper\n(T√≠n Nguy·ªÖn) ","link":"fingerstin.org/post/challenge/vlsp_imagecaptioning/","section":"post","tags":["Vision-Language"],"title":"Vietnamese Image Captioning - VLSP for Health 2021"},{"body":"","link":"fingerstin.org/tags/vision-language/","section":"tags","tags":null,"title":"Vision-Language"},{"body":"","link":"fingerstin.org/categories/vision-language/","section":"categories","tags":null,"title":"Vision-Language"},{"body":"    Hi, xin ch√†o c√°c b·∫°n, l√¢u r·ªìi ch∆∞a review l·∫°i nh·ªØng c√¥ng vi·ªác m√¨nh ƒë√£ t·ª´ng l√†m t·ª´ h·ªìi c√≤n l√† sinh vi√™n cho t·ªõi b√¢y gi·ªù cho n√™n h√¥m nay tui ng·ªìi t·ªïng h·ª£p l·∫°i ƒë·ªÉ xem m√¨nh ƒë√£ h·ªçc ƒë∆∞·ª£c nh·ªØng g√¨ v√† m·∫•t nh·ªØng g√¨ tr√™n con ƒë∆∞·ªùng s·ª± nghi·ªáp c·ªßa m√¨nh\n1. 6-2016 (NƒÉm 2 ƒê·∫°i h·ªçc) V√†o h√® nƒÉm 2 (6-2016) M√¨nh c√≥ ƒë∆∞·ª£c c√¥ng vi·ªác ƒë·∫ßu ti√™n l√† ·ªü m·ªôt c√¥ng ty game n·ªïi ti·∫øng ·ªü HCM, v√† ·ªü v·ªã tr√≠ Intern, sau khi intern 3 th√°ng h√® th√¨ m√¨nh quy·∫øt ƒë·ªãnh tr·ªü th√†nh nh√¢n vi√™n ch√≠nh th·ª©c. L√∫c ƒë√≥ m√¨nh r·∫•t th√≠ch l√†m game, c√≥ l·∫Ω l√† v√¨ l√∫c ƒë√≥ c√°i m√¨nh bi·∫øt duy nh·∫•t l√† C++, l·∫≠p tr√¨nh game n√™n nghƒ© r·∫±ng m√¨nh s·∫Ω th√≠ch l√†m game developer, v√† l√∫c ƒë√≥ m√¨nh c≈©ng ƒë√£ c√≥ suy nghƒ© r·∫±ng b·ªè h·ªçc ƒë·ªÉ l√†m cho c√¥ng ty n√†y, nh∆∞ng may m·∫Øn m√¨nh ƒë√£ suy nghƒ© r·∫•t kƒ© n√™n quy·∫øt ƒë·ªãnh ngh·ªâ l√†m ·ªü ƒë√¢y v√† t·∫≠p trung v√†o h·ªçc h√†nh, nh·ªù v·∫≠y m√† b√¢y gi·ªù m√¨nh ƒë√£ ƒë·ª° h∆°n x√≠ :rofl:. M√¨nh ƒë∆∞·ª£c tham gia v√†o m·ªôt nh√≥m l√†m v·ªÅ game Dragon City (n·∫øu nh·ªõ kh√¥ng nh·∫ßm), trong team m√¨nh ·∫•n t∆∞·ª£ng nh·∫•t l√† m·ªôt nh√≥c nh·ªè h∆°n m√¨nh 2 tu·ªïi, n√≥ r·ªõt ƒë·∫°i h·ªçc nh∆∞ng bi·∫øt code t·ª´ kh√° l√¢u n√™n n√≥ xin v√†o ch√≠nh th·ª©c ·ªü cty lu√¥n, nh∆∞ng n√≥ c≈©ng t√¢m s·ª± l√† xin chuy·ªÉn vi·ªác kh√° kh√≥ cho n√≥ v√¨ n√≥ kh√¥ng c√≥ b·∫±ng ƒë·∫°i h·ªçc, m·∫∑c d√π kƒ© nƒÉng code c≈©ng t·ªët, bi·∫øt nhi·ªÅu framework, ch·ªãu ƒë∆∞·ª£c √°p l·ª±c. Trong team c≈©ng c√≥ m·ªôt √¥ng anh l√†m 2,3 nƒÉm nh∆∞ng th·∫•y ch√°n v√† quy·∫øt ƒë·ªãnh v·ªÅ qu√™ b√°n tr√°i c√¢y. Nh·ªØng tr∆∞·ªùng h·ª£p n√†y l√†m m√¨nh suy nghƒ© kh√° nhi·ªÅu v·ªÅ t∆∞∆°ng lai :thinking: ƒêi·ªÅu m√¨nh h·ªçc ƒë∆∞·ª£c ·ªü cty n√†y l√† c√°ch l√†m vi·ªác nh√≥m, h·ªçc ƒë∆∞·ª£c th√™m m·ªôt framework l√†m game (cocos2d-x) v√† nh·ªØng kinh nghi·ªám l√†m game c·ªßa c√°c ƒë√†n anh trong cty. Th·∫ø nh∆∞ng khi v√†o ch√≠nh th·ª©c th√¨ c√¥ng vi·ªác kh√° ch√°n ƒë√≥ l√† ng·ªìi fix bug cho game t·ª´ c√¥ng ty m·∫π g·ª≠i v·ªÅ :expressionless: (c√°i n√†y t√πy ng c·∫£m nh·∫≠n ch·ª© m√¨nh kh√¥ng ph·∫£i ƒëi ch√™ cty ƒë√¢u). ƒê·∫∑c bi·ªát l√† chuy·∫øn ƒëi teambuilding ·ªü ƒê√† L·∫°t c·ª±c k√¨ tuy·ªát v·ªùi, l·∫ßn ƒë·∫ßu ti√™n ·ªü kh√°ch s·∫°n 5*, v√† m√¨nh ƒë∆∞·ª£c tr·∫£i qua hai ƒë√™m v√¥ c√πng tuy·ªát v·ªùi v·ªõi c√°c anh em :satisfied:.\n2. NƒÉm 3 ƒë·∫øn g·∫ßn cu·ªëi nƒÉm 4 C√¥ng vi·ªác th·ª© 2 m√¨nh c√≥ ƒë∆∞·ª£c l√† ·ªü mot c√¥ng ty Nh·∫≠t. M√¨nh c√≥ ƒë∆∞·ª£c c√¥ng vi·ªác n√†y l√† do m·ªôt l·∫ßn a Leader trong cty c√≥ nh·ªù th·∫ßy c·ªßa m√¨nh gi·ªõi thi·ªáu sinh vi√™n, v√† m√¨nh ƒë√£ ·ª©ng tuy·ªÉn c√¥ng vi·ªác n√†y ·ªü v·ªã tr√≠ AI Intern (m·∫∑c d√π l√†m nh∆∞ nh√¢n vi√™n ch√≠nh th·ª©c :joy:. ·ªû cty n√†y, m√¨nh ƒë√£ c√≥ c∆° h·ªôi l√†m v·ªÅ AI/Computer Vision, v√† c√≥ 2 d·ª± √°n l·ªõn m√† m√¨nh ƒë√£ tham gia ƒë√≥ l√† OCR tr√™n ti·∫øng nh·∫≠t v√† Face Recognition m·∫∑c d√π l√∫c ƒë√≥ v·∫´n c√≤n r·∫•t non tay trong vi·ªác tuning, modifiy model nh∆∞ng nh·ªØng d·ª± √°n ƒë√≥ l√† ti·∫øp th√™m cho m√¨nh ƒëam m√™ ƒë·ªÉ ti·∫øp t·ª•c con ƒë∆∞·ªùng AI c·ªßa m√¨nh. Khi l√†m vi·ªác ·ªü cty n√†y, m√¨nh r·∫•t may m·∫Øn v√¨ ƒë∆∞·ª£c a Leader ∆∞u √°i t√¨m hi·ªÉu r·∫•t nhi·ªÅu th·ª© v√† ƒë·∫∑c bi·ªát l√† cho l√†m lu·∫≠n vƒÉn c·ªßa m√¨nh v√† cung c·∫•p laptop ƒë·ªÉ training model. Tuy nhi√™n, ·ªü gi·ªØa nƒÉm 4, m√¨nh ƒë√£ ph·∫£i xin ngh·ªâ ƒë·ªÉ t·∫≠p trung v√†o lu·∫≠n vƒÉn v√¨ v·ªõi m√¨nh lu·∫≠n vƒÉn th·ª±c s·ª± quan tr·ªçng v√† m√¨nh c√≤n ƒë·∫∑t m·ª•c ti√™u ra ƒë∆∞·ª£c paper n√™n m√¨nh ph·∫£i xin ngh·ªâ ƒë·ªÉ t·∫≠p trung v√†o vi·ªác n√†y. Ngo√†i ra, Gumi th·∫≠t s·ª± ko ph·∫£i l√† m·ªôt cty l√†m ch√≠nh v·ªÅ AI n√™n m√°y m√≥c r·∫•t h·∫°n ch·∫ø, nh√¢n l·ª±c v·ªÅ AI c√≤n non n·ªõt, n√™n ƒë√≥ c≈©ng l√† m·ªôt ph·∫ßn nguy√™n do m√¨nh xin ngh·ªâ. ·ªû cty n√†y m√¨nh ƒë∆∞·ª£c t·ª± h·ªçc nhi·ªÅu th·ª©, c≈©ng v√¨ do team AI ch·ªâ bao g·ªìm nh·ªØng b·∫°n tr·∫ª, ch∆∞a co kinh nghi·ªám nhi·ªÅu n√™n m·ªói ng∆∞·ªùi ph·∫£i t·ª± ƒë√†o b·ªõi ki·∫øn th·ª©c. Tuy nhi√™n, cty n√†y c·ªßa nh·∫≠t n√™n c√°ch l√†m vi·ªác c≈©ng kh√° c·ª©ng nh·∫Øc, anyway, do tui k th√≠ch phong c√°ch l√†m vi·ªác n√†y th√¥i, kh√° kh√≥ ƒë·ªÉ n√≥i chuy·ªán v·ªõi c·∫•p tr√™n ƒë·ªÉ tr√¨nh b√†y √Ω ki·∫øn.\n3. Nam 4 + 1 nam sau DH M√¨nh ƒë∆∞·ª£c th·∫ßy m√¨nh gi·ªõi thi·ªáu v√†o cty n√†y, l√∫c ƒë√≥ ch·ªâ c√≥ 2,3 b·∫°n l√† ƒë∆∞·ª£c th·∫ßy \u0026quot;g·ª≠i g·∫Øm\u0026quot; ƒë·ªÉ c√≥ th·ªÉ v√†o ƒë√≥ ho√†n th√†nh lu·∫≠n vƒÉn.V√† th·∫≠t s·ª± cty n√†y ban ƒë·∫ßu l√†m m√¨nh cho√°ng ng·ª£p b·ªüi m√°y m√≥c v√¥ c√πng t·ªëi t√¢n, nh√¢n vi√™n th√¨ c·ª±c k√¨ gi·ªèi v√† ƒë·∫∑c bi·ªát l√† n√≥ g·∫ßn nh√† m√¨nh :joy:.  Tuy nhi√™n, m√¨nh ƒë√£ qu√° n√≥ng v·ªôi khi xin v√†o v·ªã tr√≠ nh√¢n vi√™n ch√≠nh th·ª©c ch·ª© ko ph·∫£i intern nh∆∞ c√°c b·∫°n kh√°c, vi·ªác n√†y l√†m cho m√¨nh r·∫•t √°p l·ª±c v√¨ m√¨nh ph·∫£i l√†m lu·∫≠n vƒÉn v√† ch·∫°y d·ª± √°n cty c√πng m·ªôt l√∫c, v√† k·∫øt qu·∫£ th√¨ ko n√≥i c≈©ng bi·∫øt, m√¨nh ch·ªâ c√≥ th·ªÉ ho√†n th√†nh ƒë∆∞·ª£c lu·∫≠n vƒÉn m√† k ƒë·∫£m b·∫£o ƒë∆∞·ª£c nghi√™n c·ª©u cho cty. Nh∆∞ng may m·∫Øn l√† m√¨nh v·∫´n ƒë∆∞·ª£c ƒë·∫©y qua team product ƒë·ªÉ l√†m sau ƒë√≥, l√∫c n√†y m√¨nh tho·∫£i m√°i h∆°n v√¨ ƒë√£ xong lu·∫≠n vƒÉn, v√† l√∫c n√†y m√¨nh ƒë∆∞·ª£c l√†m v·ªõi m·ªôt team product r·∫•t gi·ªèi, m·∫∑c d√π ko ph·∫£i l√†m research nh∆∞ng team n√†y c√≥ nh·ªØng √Ω t∆∞·ªüng r·∫•t hay, code c≈©ng r·∫•t t·ªët n√™n m√¨nh ƒë√£ h·ªçc ƒë∆∞·ª£c r·∫•t nhi·ªÅu. H√¨nh th·ª©c c·ªßa cty l√† startup n√™n c≈©ng c√≥ nhi·ªÅu l·∫ßn ph·∫£i th·ª©c qua ƒë√™m ƒë·ªÉ ch·∫°y d·ª± √°n, ƒë√¢y l√† nh·ªØng k·ªâ ni·ªám ƒë·∫ßu ƒë·ªùi c√≥ l·∫Ω m√¨nh ko th·ªÉ qu√™n ƒë∆∞·ª£c v·ªõi c√°c ƒë·ªìng nghi·ªáp c·ªßa m√¨nh. Tuy nhi√™n, v√¨ m·ªôt v√†i l√≠ do, m√¨nh c≈©ng ph·∫£i r·ªùi cty, ph·∫ßn l·ªõn l√† do m√¨nh c·∫£m th·∫•y con ƒë∆∞·ªùng c·ªßa m√¨nh ko ph√π h·ª£p v·ªõi ƒë·ªãnh h∆∞·ªõng c·ªßa cty v√¨ th·∫ø m√¨nh quy·∫øt ƒë·ªãnh r·ªùi ƒëi v√† ƒë·∫øn v·ªõi 1 cong ty khac.\n4. Truoc khi roi khoi VN D√¢y l√† m·ªôt m√¥i tr∆∞·ªùng l√≠ t∆∞·ªüng, c√°c anh ch·ªã ·ªü ƒë√¢y c·ª±c k√¨ nice v√† professional. V√† ·ªü cty n√†y m√¨nh c≈©ng ƒë∆∞·ª£c l√†m ƒëi·ªÅu m√¨nh th√≠ch ƒë√≥ l√† Robotics Vision, tuy nhi√™n cty k t·∫≠p trung l√†m AI m√† l√† v·ªÅ web,apps v√† ph·∫ßn c·ª©ng c·ªßa Robot n√™n m√¨nh c·∫£m th·∫•y kh√≥ ƒë·ªÉ ti·∫øn b·ªô, team AI l√∫c ƒë√≥ c≈©ng ch·ªâ c√≥ 2 ng v√† m·ªôt ng∆∞·ªùi th√¨ t·ª´ BlockChain qua, c≈©ng ch∆∞a c√≥ nhi·ªÅu kinh nghi·ªám v·ªÅ AI. L√∫c n√†y m√¨nh m·ªõi quy·∫øt ƒë·ªãnh ƒëi l√†m nghi√™n c·ª©u ƒë·ªÉ c√≥ th·ªÉ ho√†n to√†n l√†m th·ª© m√¨nh th√≠ch, v√¨ th·∫ø m√¨nh ch·ªçn du h·ªçc HQ.\n5. Du h·ªçc HQ Khi paper ƒë·∫ßu ti√™n c·ªßa m√¨nh ƒëc accept c√πng v·ªõi vi·ªác m√¨nh ƒë√£ c√≥ ielts, th·∫ßy m√¨nh ƒë√£ gi√≥i thi·ªáu lu√¥n h·ªçc b·ªïng gi√°o s∆∞ h√†n qu·ªëc cho m√¨nh. L√∫c ƒë√≥ c≈©ng kh√° bƒÉn khoƒÉn do ƒëang d·ªãch v√† m√¨nh c≈©ng ƒëang mu·ªën ƒëi ch√¢u √¢u h∆°n (c·ª• th·ªÉ l√† Ph·∫ßn Lan), tuy nhi√™n th·∫ßy c≈©ng ƒë·ªông vi√™n v√† m√¨nh c≈©ng ham h·ªë ƒëi n√™n th√¥i nh·∫Øm m·∫Øt ch·ªçn lu√¥n :joy:. Khi qua ƒë√¢y th√¨ m√¨nh ƒëc v√†o m·ªôt lab c√≥ ƒëi·ªÅu ki·ªán c≈©ng kh√° t·ªët, gi√°o c≈©ng kh√° nice, tuy nhi√™n th√¨ c≈©ng c√≥ m·ªôt v√†i ƒëi·ªÅu kh√¥ng th√≠ch th√¨ ƒë√≥ l√† do c√°ch c·∫£m nh·∫≠n c·ªßa m·ªói ng∆∞·ªùi khi l√†m vi·ªác ·ªü lab th√¥i, b·∫£n th√¢n m√¨nh c·∫£m th·∫•y ch∆∞a c√≥ g√¨ l√† qu√° ƒë√°ng. Tuy nhi√™n, ƒëi·ªÅu m√¨nh c·∫£m th·∫•y thi·∫øu ·ªü lab hi·ªán t·∫°i l√† c√°c member trong lab m·ªói ng∆∞·ªùi l√†m m·ªôt vi·ªác kh√°c nhau n√™n c≈©ng kh√≥ c√≥ th·ªÉ trao ƒë·ªïi, h∆°n n·ªØa, c√° nh√¢n m√¨nh th√≠ch c√°c cu√¥c thi ƒë·ªÉ n√¢ng cao kh·∫£ nƒÉng nh∆∞ng trong lab ko ai th√≠ch th√∫ c·∫£, c√≥ ng∆∞·ªùi th√¨ ch·ªâ ƒëƒÉng k√≠ xong, r·ªìi download data, xong r·ªìi ƒë·ªÉ ƒë√≥ c≈©ng ch·∫≥ng l√†m g√¨, v√¨ v·∫≠y m√¨nh hi·ªán t·∫°i v·∫´n ƒëang alone (c√¥ ƒë·ªôc) trong lab =)))))))\n6. Future Trong t∆∞∆°ng lai, c√≥ th·ªÉ m√¨nh s·∫Ω ko ho√†n th√†nh ch∆∞∆°ng tr√¨nh Ti·∫øn sƒ© m√† s·∫Ω xin xu·ªëng Th·∫°c sƒ© v√† v·ªÅ n∆∞·ªõc xin vi·ªác, ho·∫∑c m√¨nh s·∫Ω ho√†n th√†nh lu√¥n Ti·∫øn sƒ© v√† xin Postdoc ·ªü m·ªôt n∆∞·ªõc kh√°c ho·∫∑c c√≥ th·ªÉ v·ªÅ n∆∞·ªõc xin vi·ªác =))), 2 ƒë·∫•t n∆∞·ªõc m√† m√¨nh th√≠ch nh·∫•t b√¢y gi·ªù c√≥ l·∫Ω l√† n∆∞·ªõc Anh (v√† tr∆∞·ªùng m√† m√¨nh th√≠ch nh·∫•t ·ªü Anh l√† Imperial College London) v√† Th·ª•y ƒêi·ªÉn (tr∆∞·ªùng m√¨nh th√≠ch nh·∫•t l√† Royal KTH), anyway, ƒë√≥ l√† m·ªôt c√¢u chuy·ªán kh√° xa, b√¢y gi·ªù m√¨nh ch·ªâ mu·ªën ra ƒëc m·ªôt, hai paper th√¥i, th·ªÉ l√† ƒë·ªß ƒë·ªÉ t·ªët nghi·ªáp, kakaka.\n(T√≠n Nguy·ªÖn)  ","link":"fingerstin.org/post/personal/career/","section":"post","tags":["personal"],"title":"My Career"},{"body":"Hi, xin ch√†o c√°c b·∫°n, h√¥m n√†y m√¨nh s·∫Ω gi·ªõi thi·ªáu cho c√°c b·∫°n b√†i to√°n Multiple Object Tracking s·ª≠ d·ª•ng Kalman Filter ƒë·ªÉ theo v·∫øt ƒë·ªëi t∆∞·ª£ng v√† thu·∫≠t to√°n Hungary ƒë·ªÉ gi·∫£i b√†i to√°n credit assignment, n√≥i n√¥m na l√† l√†m sao g√°n t·ª´ng tracker v√†o m·ªói object sao cho chi ph√≠ l√† √≠t nh·∫•t. Ngo√†i ra, ·ªü b√†i n√†y, m√¨nh ch·ªâ s·ª≠ d·ª•ng ph∆∞∆°ng ph√°p tr·ª´ n·ªÅn (Background Subtraction) ƒë·ªÉ detect ƒë·ªëi t∆∞·ª£ng ƒë·ªông. C√°c b·∫°n c√≥ th·ªÉ thay th·∫ø b·∫±ng c√°c thu·∫≠t to√°n object detection kh√°c nh∆∞ YOLO, Faster RCNN, Centernet, etc. Link code: ƒê√¢y l√† code c·ªßa thu·∫≠t to√°n, ƒë√£ ƒë∆∞·ª£c m√¨nh implement b·∫±ng C++, ƒë√¢y c≈©ng l√† ƒë·ªì √°n m√¥n Computer Vision c·ªßa m√¨nh h·ªìi nƒÉm 3 t·∫°i tr∆∞·ªùng ƒë·∫°i h·ªçc khoa h·ªçc t·ª± nhi√™n, H·ªì Ch√≠ Minh. Code\nN·ªôi dung ch√≠nh s·∫Ω bao g·ªìm c√°c ph·∫ßn sau: 1. Gi·ªõi thi·ªáu b√†i to√†n Multiple Object Tracking  2. Nguy√™n l√Ω  3. Ph∆∞∆°ng ph√°p \n 3.1 Background Generation 3.2 Object Detection  3.3 Kalman Filter  3.4 Hungary Algorithm   4. ·ª®ng d·ª•ng  5. Tham kh·∫£o \n1. Gi·ªõi thi·ªáu b√†i to√°n Multiple Object Tracking  ƒê√¢y ƒë∆°n gi·∫£n l√† b√†i to√°n theo v·∫øt nhi·ªÅu ƒë·ªëi t∆∞·ª£ng c√πng m·ªôt l√∫c. 2. Nguy√™n l√Ω  Nguy√™n l√≠ c·ªßa b√†i to√°n n√†y v·∫´n l√† t√¨m ki·∫øm nhi·ªÅu ƒë·ªëi t∆∞·ª£ng (object detection) v√† so kh·ªõp (matching) ƒë·ªëi t∆∞·ª£ng v·ªõi nh·ªØng ƒë·ªëi t∆∞·ª£ng ·ªü frame tr∆∞·ªõc ƒë·ªÉ x√°c ƒë·ªãnh ƒë√¢u l√† nh·ªØng ƒë·ªëi t∆∞·ª£ng c·∫ßn theo v·∫øt. 3. Ph∆∞∆°ng ph√°p  ·ªû frame ƒë·∫ßu ti√™n, ta s·∫Ω d√πng ph∆∞∆°ng ph√°p tr·ª´ n·ªÅn ƒë·ªÉ ph√°t hi·ªán ƒë·ªëi t∆∞·ª£ng v√† c≈©ng s·∫Ω ƒë∆∞·ª£c d√πng ·ªü nh·ªØng frame sau v·ªõi m·ª•c ƒë√≠ch detect ƒë·ªëi t∆∞·ª£ng ƒë·ªông. Sau ƒë√≥, ta s·∫Ω d√πng Kalman Filter (KF) ƒë·ªÉ d·ª± ƒëo√°n v·ªã tr√≠ ti·∫øp theo c·ªßa t·ª´ng ƒë·ªëi t∆∞·ª£ng.\nƒê·ªÉ c√≥ th·ªÉ d·ª± ƒëo√°n ƒë∆∞·ª£c v·ªã tr√≠ b·∫±ng KF ch√≠nh x√°c, ta ph·∫£i th·ª±c hi·ªán so kh·ªõp (matching). ·ªû b∆∞·ªõc n√†y, ta ph·∫£i x√°c ƒë·ªãnh ƒë∆∞·ª£c ƒë·ªëi t∆∞·ª£ng n√†o l√† ƒë·ªëi t∆∞·ª£ng n√†o ·ªü frame tr∆∞·ªõc ƒë√≥, v√† ta s·∫Ω gi·∫£i quy·∫øt b·∫±ng thu·∫≠t to√°n Hungary Algorithm.\nCu·ªëi c√πng l√† l·∫∑p l·∫°i qu√° tr√¨nh tr√™n ƒë·∫øn khi video k·∫øt th√∫c.\n  3.1 Background Generation ƒê·ªÉ s·ª≠ d·ª•ng ph∆∞∆°ng ph√°p tr·ª´ n·ªÅn, y√™u c·∫ßu l√† background c·ªßa ch√∫ng ta ph·∫£i kh√° tƒ©nh, n·∫øu background ƒë·ªông th√¨ ph∆∞∆°ng ph√°p kh√¥ng c√≤n t√°c d·ª•ng v√¨ ph∆∞∆°ng ph√°p n√†y m·ª•c ƒë√≠ch l√† ƒë·ªÉ tr√≠ch xu·∫•t ƒë∆∞·ª£c nh·ªØng ƒë·ªëi t∆∞·ª£ng ƒë·ªông.  ƒê·ªÉ tr·ª´ n·ªÅn, ta ƒë∆°n gi·∫£n ch·ªâ c·∫ßn d√πng background ·ªü frame (t) - background ·ªü frame (t-1). Tuy nhi√™n, m√¨nh ƒë√£ th·ª≠ v√† th·∫•y c√≥ m·ªôt ph∆∞∆°ng ph√°p kh√°c hay h∆°n, ƒë√≥ l√† Pixel Histrogram. Pixel Histogram l√† ph∆∞∆°ng ph√°p t√°i t·∫°o n·ªÅn, input s·∫Ω l√† m·ªôt histogram, output l√† n·ªÅn ƒë∆∞·ª£c t√°i t·∫°o d∆∞·ªõi d·∫°ng grayscale. Gi·∫£ s·ª≠ m·ªói k√≠ch th∆∞·ªõc c·ªßa m·ªôt frame l√† w (width) v√† h (height). ·ª®ng v·ªõi m·ªói pixel tr√™n frame, ta s·∫Ω c√≥ m·ªôt histogram 256 chi·ªÅu. Sau khi c√≥ ƒë∆∞·ª£c t·∫•t c·∫£ l√† (w x h) histogram, ta s·∫Ω l·∫•y ra gi√° tr·ªã m√†u l·ªõn nh·∫•t ·ªü m·ªói histogram v√† ƒë·∫∑t l√†m gi√° tr·ªã m√†u t·∫°i pixel t∆∞∆°ng ·ª©ng. Cu·ªëi c√πng s·∫Ω t√°i t·∫°o ƒë∆∞·ª£c background. ƒê·ªÉ t·∫°o ra ƒë∆∞·ª£c t·ª´ng histogram ƒë√≥, ta c·∫ßn ph·∫£i l∆∞·ªõt qua K frame c·ªßa video, ·ª©ng v·ªõi m·ªói frame ta s·∫Ω l∆∞·ªõt t·ª´ng pixel, l·∫•y ra gi√° tr·ªã m√†u ·ªü pixel ƒë√≥ v√† cu·ªëi c√πng l√† tƒÉng th√™m 1 cho bin m√†u t∆∞∆°ng ·ª©ng c·ªßa histogram. Sau khi l∆∞·ªõt h·∫øt K frame, ta s·∫Ω c√≥ ƒë∆∞·ª£c (w x h) histogram.\n  3.2 Object Detection Sau khi c√≥ ƒë∆∞·ª£c n·ªÅn, ta s·∫Ω b∆∞·ªõc ƒë·∫øn giai ƒëo·∫°n detection \u0026amp; tracking. ƒê·ªÉ detect nh·ªØng ƒë·ªëi t∆∞·ª£ng ƒë·ªông, m·ªói l·∫ßn process frame, ta s·∫Ω l·∫•y frame ƒë√≥ tr·ª´ cho n·ªÅn ƒë√£ ƒë∆∞·ª£c t√°i t·∫°o b·∫±ng ph∆∞∆°ng ph√°p ·ªü tr√™n. Ph∆∞∆°ng ph√°p n√†y r·∫•t ƒë∆°n gi·∫£n, n·∫øu 2 ƒë·ªëi t∆∞·ª£ng ƒëi g·∫ßn nhau qu√° s·∫Ω b·ªã d√≠nh v√† cho l√† 1 ƒë·ªëi t∆∞·ª£ng nh∆∞ng ƒë∆∞·ª£c c√°i l√† n√≥ c·ª±c k√¨ nhanh =)) ƒê√¢y l√† ph∆∞∆°ng ph√°p ƒë∆°n gi·∫£n, v√¨ h·ªìi ƒë√≥ m·ªõi sinh vi√™n, c√≥ bi·∫øt deep learning ƒë√¢u n√™n l√†m c√°ch n√†y haha. B√¢y gi·ªù c√°c b·∫°n c√≥ th·ªÉ d√πng YOLO ho·∫∑c Faster RCNN, CenterNet ƒë·ªÉ detect cho ch√≠nh x√°c h∆°n.\n    3.3 Kalman Filter Kalman Filter l√† m·ªôt m√¥ h√¨nh l·ªçc nhi·ªÖu, n√≥ bao g·ªìm 2 ph·∫ßn ƒë√≥ l√† d·ª± ƒëo√°n (predict) v√† c·∫≠p nh·∫≠t (update). ·ªû b∆∞·ªõc predict, n√≥ s·∫Ω d·ª± ƒëo√°n v·ªã tr√≠ c·ªßa t·ª´ng ƒë·ªëi t∆∞·ª£ng, sau ƒë√≥ ·ªü b∆∞·ªõc Update n√≥ s·∫Ω c·∫≠p nh·∫≠t, s·ª≠a l·∫°i cho ƒë√∫ng h∆°n.\n  3.4 Hungary Algorithm ƒê√¢y l√† thu·∫≠t to√°n d√πng ƒë·ªÉ gi·∫£i quy·∫øt assignment problem. Assignment Problem l√† b√†i to√°n c√≥ N ƒë·ªëi t∆∞·ª£ng, v√† M c√¥ng vi·ªác, m·ªói ƒë·ªëi t∆∞·ª£ng khi l√†m m·ªôt c√¥ng vi·ªác n√†o ƒë√≥ s·∫Ω c√≥ m·ªôt chi ph√≠ nh·∫•t ƒë·ªãnh. V√† nhi·ªám v·ª• ƒë√≥ l√† l√†m sao g√°n m·ªói ƒë·ªëi t∆∞·ª£ng cho m·ªôt c√¥ng vi·ªác n√†o ƒë√≥ sao cho t·ªïng chi ph√≠ l√† nh·ªè nh·∫•t. \n  ƒê·ªëi v·ªõi b√†i to√°n tracking, ta c√≥ th·ªÉ √°p d·ª•ng nh∆∞ sau: Ta c√≥ N tracker v√† M ƒë·ªëi t∆∞·ª£ng detect ƒë∆∞·ª£c, v√† ta ph·∫£i g√°n t·ª´ng tracker v·ªõi t·ª´ng ƒë·ªëi t∆∞·ª£ng sao cho chi ph√≠ l√† nh·ªè nh·∫•t. V·∫≠y chi ph√≠ ·ªü ƒë√¢y l√† g√¨ ? M·ªói tracker ƒë√≥ ch√≠nh l√† m·ªôt Kalman Filter (KF), ·ªü m·ªói frame, KF s·∫Ω d·ª± ƒëo√°n v·ªã tr√≠ c·ªßa ƒë·ªëi t∆∞·ª£ng tr∆∞·ªõc, g·ªçi l√† p_predict, v√† ·ªü m·ªói frame ta l·∫°i detect ƒë·ªëi t∆∞·ª£ng v√† ra ƒë∆∞·ª£c v·ªã tr√≠ c·ªßa ch√∫ng g·ªçi l√† p_object. V·∫≠y, kh·ªèang c√°ch gi·ªØa p_predict v√† p_object ch√≠nh l√† chi ph√≠. Ta s·∫Ω ƒë∆∞a th√¥ng tin n√†y qua thu·∫≠t to√°n Hungary ƒë·ªÉ gi·∫£i quy·∫øt b√†i to√°n assignment, v√† KF s·∫Ω c·∫≠p nh·∫≠t l·∫°i v·ªã tr√≠ tracking c·ªßa m√¨nh. 5. ·ª®ng d·ª•ng v√† B√†n lu·∫≠n  B√†i to√°n n√†y ƒë∆∞·ª£c ·ª©ng d·ª•ng trong theo v·∫øt ƒë·ªëi t∆∞·ª£ng giao th√¥ng, ƒë·ªëi t∆∞·ª£ng trong c√°c si√™u th·ªã, c·ª≠a h√†ng, ... ·ªû b√†i vi·∫øt n√†y, m√¨nh ch·ªâ vi·∫øt tr√¨nh b√†y ƒë∆°n gi·∫£n c√°c b∆∞·ªõc, ch∆∞a tr√¨nh b√†y kƒ© thu·∫≠t to√°n c≈©ng nh∆∞ c√≥ code minh h·ªça v√¨ m√¨nh kh√¥ng c√≥ th·ªùi gian nhi·ªÅu ƒë·ªÉ l√†m kƒ©, mong c√°c b·∫°n th√¥ng c·∫£m. ƒê·ªÉ hi·ªÉu h∆°n v·ªÅ b√†i vi·∫øt, c√°c b·∫°n c√≥ th·ªÉ tham kh·∫£o link repo c·ªßa m√¨nh nh√©. N·∫øu th·∫•y hay, cho m√¨nh m·ªôt star ho·∫∑c fork tr√™n repo nh√©. Thank you for reading.\n6. Tham kh·∫£o  Code\n(T√≠n Nguy·ªÖn) ","link":"fingerstin.org/post/tracking/multiple_object_tracking/","section":"post","tags":["multiple-object-tracking"],"title":"Multiple Object Tracking with Kalman Filter and Hungary Algorithm"},{"body":"","link":"fingerstin.org/tags/multiple-object-tracking/","section":"tags","tags":null,"title":"multiple-object-tracking"},{"body":"","link":"fingerstin.org/categories/object-tracking/","section":"categories","tags":null,"title":"Object Tracking"},{"body":"In this post, I want to introduce a hot topic in Reinforcement Learning which is Instruction Navigation. Although Navigation can be tackled by using Supervised Learning, but using Reinforcement Learning help us learn without any human-labeled data.\nLink paper: Paper Link code: Code\nThe content is as following: 1. Introduction to Instruction Navigation  2. Principle  3. Methodology \n 3.1 Image Representation Module  3.2 Text Representation Module  3.3 Attented Representation Module  3.4 Policy Learning   4. Application  5. Reference \n1. Introduction to Instruction Navigation  Navigation problem is a familiar topic and it has been carried out many experiments in so many years. The problem is to make an agent move in an environment and achieve a predefined target. In general, this problem can be solved by Reinforcement Learning, the agent will receive an observation which contains several information such as image, depth, segmentation or sensor information, etc. Howerver, human want to make command for the agent through instruction, so the agent now has an additional information which is a text, or voice. The low-level instruction will be simple commands such as go straight, go left, go right, etc, but in practice, the instruction is more complex, it needs to consider other elements such as size, color, etc of the objects nearby. And that is the motivation of the Instruction Navigation problem. 2. Principle  The principle of Vision-Language problems is how to fuse multiple features together.  And with this problem, it composes of 3 components, (1) is to get image features, (2) is to get textual features, (3) is how to fuse these features together which is the most important part. In this paper, the fusion strategy they've used is concatenation and Hadarmard (element-wise) product. The final stage is the decision-making part, which employs a policy learning algorithm to make decision. A well-known but simple algorithm used in this situation is Asynchronous Actor Critic (A3C). 3. Methodology  The methodology simply takes an image and an instruction as inputs. Noted that, with each episode, there is only one instruction, but the image changes continually.   3.1 Image Representation Module In order to extract visual features, they employed a simple 3-layer CNN.\n  3.2 Text Representation Module In terms of extracting textual features, first, they employed Word Embedding on the text input, then converted it to sentence embedding by using LSTM or GRU.\n  3.3 Attented Representation Module\n  After getting a hold of 2 feature vectors, they use Hadardmard (element-wise) product to fuse the features together, and this is called Gated Attention.  3.4 Policy Learning  The policy learning will help the agent make decision which direction is going on. In this paper, the author use A3C, which is a well-known but simple reinforcement learning algorithm. 5. Application  This algorithm can be applied to robotics, however, this stll have some limits such as only handling short, and simple instructions. 6. Reference  Paper Code\n(T√≠n Nguy·ªÖn) ","link":"fingerstin.org/post/rl/vision_language_navigation/","section":"post","tags":["Reinforcement Learning","Vision Language"],"title":"Instruction Navigation"},{"body":"","link":"fingerstin.org/tags/korea/","section":"tags","tags":null,"title":"korea"},{"body":"L·∫ßn ƒë·∫ßu ti√™n th·∫•y tuy·∫øt, wow, nƒÉm nay l·∫°i l√† nƒÉm m√† Seoul l·∫°nh k·ªâ l·ª•c, nh·ªõ kh√¥ng nh·∫ßm l√† nhi·ªát ƒë·ªô r∆°i xu·ªëng t·∫≠n -2x ƒë·ªô C. N√≥i chung c·∫£m gi√°c l·∫ßn ƒë·∫ßu th·∫•y tuy·∫øt r∆°i kh√° th√∫ v·ªã, nh∆∞ng m√¨nh l·∫°i ko th√≠ch l·∫°nh nh∆∞ th·∫ø v√¨ m√¨nh c√≥ v·∫•n ƒë·ªÅ v·ªÅ m≈©i, c·ªông th√™m n·ªØa l√† ƒëi b·ªô m·ªôt m√¨nh d∆∞·ªõi tuy·∫øt ch√°n th·∫≠t s·ª± :smiling_face_with_tear:, n·∫øu c√≥ th√™m b·∫°n g√°i ƒëi c√πng n·ªØa th√¨ tuy·ªát :rofl:.\n ","link":"fingerstin.org/post/personal/winter-korean-2020/","section":"post","tags":["korea","winter"],"title":"M√πa ƒë√¥ng ƒë·∫ßu ti√™n t·∫°i H√†n Qu·ªëc 12/2020"},{"body":"","link":"fingerstin.org/tags/reinforcement-learning/","section":"tags","tags":null,"title":"Reinforcement Learning"},{"body":"","link":"fingerstin.org/categories/reinforcement-learning/","section":"categories","tags":null,"title":"Reinforcement Learning"},{"body":"","link":"fingerstin.org/tags/winter/","section":"tags","tags":null,"title":"winter"},{"body":"Hi everyone, h√¥m nay m√¨nh quy·∫øt ƒë·ªãnh chia s·∫Ω v·ªÅ qu√° tr√¨nh xin h·ªçc b·ªïng ·ªü H√†n Qu·ªëc c·ªßa m√¨nh trong m√πa d·ªãch Covid 2020. N√≥i s∆° qua m·ªôt ch√∫t, m√¨nh may m·∫Øn nh·∫≠n ƒë∆∞·ª£c h·ªçc b·ªïng gi√°o s∆∞ t·∫°i HQ v√†o th√°ng 9/2020 t·∫°i tr∆∞·ªùng ƒë·∫°i h·ªçc Sejong ng√†nh Computer Science and Engineering nh·ªù v√†o s·ª± gi·ªõi thi·ªáu c·ªßa gi√°o s∆∞ ·ªü tr∆∞·ªùng ƒë·∫°i h·ªçc c·ªßa m√¨nh. V√† c≈©ng may m·∫Øn khi gi√°o s∆∞ trao m√¨nh h·ªçc b·ªïng c√≥ h∆∞·ªõng nghi√™n c·ª©u m√† m√¨nh ∆∞a th√≠ch ƒë√≥ l√† Computer Vision in Robotics, Drone.\nP/s: L√∫c ƒë·∫ßu m√¨nh c≈©ng ko mu·ªën ƒëi qua H√†n v√¨ kh√° nhi·ªÅu l√≠ do, m·ªôt l√† ƒëang trong m√πa d·ªãch, m√¨nh c≈©ng ch·∫£ mu·ªën ƒëi ƒë√¢u v√¨ s·ª£ b·ªã d√≠nh covid, hai l√† c·∫£m th·∫•y b·∫£n th√¢n ch∆∞a ƒë·ªß t·ªët ƒë·ªÉ ƒëi h·ªçc ti·∫øp l√™n, ba l√† m√¨nh ko bi·∫øt ti·∫øng H√†n, nh∆∞ng gi√°o s∆∞ ·ªü VN c·ªßa m√¨nh ƒë√£ ƒë·ªông vi√™n v√† c≈©ng th·∫•y nhi·ªÅu a/c ƒë√£ sang H√†n v√† th√†nh c√¥ng n√™n m√¨nh quy·∫øt ƒë·ªãnh th·ª≠ s·ª©c. Sau 2 nƒÉm, m√¨nh c·∫£m th·∫•y ƒë√¢y l√† m·ªôt quy·∫øt ƒë·ªãnh b∆∞·ªõc ngo·∫∑t c·ªßa m√¨nh, v√¨ m√¨nh h·ªçc ƒë∆∞·ª£c r·∫•t nhi·ªÅu th·ª©, k·ªÉ c·∫£ ki·∫øn th·ª©c l·∫´n kƒ© nƒÉng s·ªëng ·ªü m·ªôt ƒë·∫•t n∆∞·ªõc xa l·∫°.\n!(Sejong Computer Science Department)(/images/scholarship/sejong.jpg)\n1. Apply h·ªçc b·ªïng Vi·ªác apply h·ªçc b·ªïng gi√°o s∆∞ ƒë∆°n gi·∫£n h∆°n c√°c lo·∫°i h·ªçc b·ªïng kh√°c, ƒë∆∞∆°ng nhi√™n l√† n·∫øu h·ªì s∆° c·ªßa b·∫°n c√†ng t·ªët th√¨ kh·∫£ nƒÉng b·∫°n ƒë∆∞·ª£c nh·∫≠n c√†ng cao. T·∫°i th·ªùi ƒëi·ªÉm m√¨nh xin h·ªçc b·ªïng, h·ªì s∆° c·ªßa m√¨nh c≈©ng kh√¥ng thu·ªôc d·∫°ng qu√° kh·ªßng, m√¨nh ch·ªâ c√≥ 1 paper n·ªôp ·ªü m·ªôt t·∫°p ch√≠ qu·ªëc t·∫ø b√¨nh th∆∞·ªùng, ti·∫øng anh th√¨ c√≥ b·∫±ng ielts 6.0, 1 CV, b·∫£ng ƒëi·ªÉm thu·ªôc d·∫°ng kh√° v√† m·ªôt k·∫ø ho·∫°ch h·ªçc t·∫≠p (study plan). Ngo√†i ra, n·∫øu b·∫°n c√≥ th√™m th√†nh t√≠ch, ch·ª©ng ch·ªâ g√¨ th√¨ n·ªôp th√™m c≈©ng ƒë∆∞·ª£c, mi·ªÖn l√† th·∫•y n√≥ ph√π h·ª£p.\nKhi c√≥ ƒë·ªß gi·∫•y t·ªù tr√™n, b·∫°n c·∫ßn li√™n l·∫°c v·ªõi gi√°o s∆∞ s·ªõm ƒë·ªÉ n·ªôp h·ªì s∆°, n·∫øu gs ch·∫•p nh·∫≠n th√¨ s·∫Ω ph·ªèng v·∫•n ƒë·ªÉ h·ªèi v·ªÅ th√†nh t√≠ch c·ªßa b·∫°n, n·∫øu gs ƒë·ªìng √Ω cho b·∫°n h·ªçc b·ªïng th√¨ 99% l√† b·∫°n ƒëi sang hq ƒë∆∞·ª£c r·ªìi ƒë·∫•y, 1% c√≤n l·∫°i l√† l√†m c√°c th·ªß t·ª•c c·∫ßn thi·∫øt ƒë·ªÉ tr∆∞·ªùng x√©t v√† xin visa.\n2. Chu·∫©n b·ªã gi·∫•y t·ªù n·ªôp cho tr∆∞·ªùng V·ªÅ ph·∫ßn n√†y th√¨ t√πy t·ª´ng tr∆∞·ªùng y√™u c·∫ßu, b·∫°n n√™n l√™n trang web c·ªßa tr∆∞·ªùng ƒë·ªÉ t√¨m hi·ªÉu ho·∫∑c li√™n l·∫°c v·ªõi ph√≤ng quan h·ªá qu·ªëc t·∫ø c·ªßa tr∆∞·ªùng ƒë√≥ ƒë·ªÉ h·ªèi cho ch·∫Øc. May m·∫Øn tr∆∞·ªùng m√¨nh xin v√†o c√≥ c·ªông ƒë·ªìng ng∆∞·ªùi Vi·ªát kh√° nhi·ªÅu n√™n m√¨nh c≈©ng ƒë∆∞·ª£c h·ªç gi√∫p ƒë·ª° gi·∫•y t·ªù l·∫´n xin ·ªü k√≠ t√∫c x√° ·ªü tr∆∞·ªùng. M√¨nh c·∫£m th·∫•y kh√° may m·∫Øn v√¨ m√¨nh kh√¥ng bi·∫øt ti·∫øng h√†n v√† c≈©ng ƒëi trong m√πa d·ªãch n√™n c√≥ r·∫•t nhi·ªÅu kh√≥ khƒÉn trong giao ti·∫øp v√† n∆°i ·ªü trong th·ªùi gian ƒë·∫ßu qua H√†n.\n3. Ch·ªù gi·∫•y m·ªùi nh·∫≠p h·ªçc, ƒë√≥ng ti·ªÅn v√† xin visa Sau khi xong 2 b∆∞·ªõc tr√™n, th√¨ b·∫°n ph·∫£i ch·ªù 1,2 th√°ng ƒë·ªÉ tr∆∞·ªùng ra danh s√°ch sinh vi√™n ƒë·∫≠u v√†o tr∆∞·ªùng, sau ƒë√≥ l√† ƒë√≥ng ti·ªÅn v√† ch·ªù gi·∫•y b√°o nh·∫≠p h·ªçc g·ª≠i v·ªÅ, cu·ªëi c√πng l√† kh√°m s·ª©c kh·ªèe v√† xin visa.\n3. Xin Visa Khi xin visa, b·∫°n n√™n li√™n h·ªá v·ªõi trung t√¢m ƒëƒÉng k√≠ visa h√†n qu·ªëc (Korea Visa Application Center) ƒë·ªÉ h·ªèi c√°c gi·∫•y t·ªù c·∫ßn thi·∫øt thay v√¨ ch·ªâ nghe m·ªôt chi·ªÅu t·ª´ ph√≤ng quan h·ªá qu·ªëc t·∫ø c·ªßa tr∆∞·ªùng m√† b·∫°n du h·ªçc, tr√°nh tr∆∞·ªùng h·ª£p ph·∫£i l√†m ƒëi l√†m l·∫°i gi·∫•y t·ªù. Trong tr∆∞·ªùng h·ª£p c·ªßa m√¨nh, m√¨nh ƒë√£ ph·∫£i m·∫•t t·∫≠n 5 l·∫ßn m·ªõi ho√†n th√†nh ƒë∆∞·ª£c h·ªì s∆° xin visa, l·∫ßn 1 th√¨ thi·∫øu gi·∫•y b·∫£o l√£nh, gi·∫•y s·ªë d∆∞ t√†i kho·∫£n v√† gi·∫•y ch·ª©ng nh·∫≠n RA (Research Assistant), l·∫ßn 2 th√¨ sai form gi·∫•y b·∫£o l√£nh c·ªßa trung t√¢m visa, thi·∫øu gi·∫•y ch·ª©ng nh·∫≠n con d·∫•u c·ªßa gi√°o s∆∞ (c√°i n√†y gi√°o s∆∞ ph·∫£i ra c∆° quan ƒë·ªãa ph∆∞∆°ng xin), l·∫ßn 3 th√¨ do con d·∫•u trong gi·∫•y b·∫£o l√£nh kh√¥ng kh·ªõp v·ªõi gi·∫•y ch∆∞ng nh·∫≠n con d·∫•u (do 1 gi√°o s∆∞ c√≥ th·ªÉ c√≥ nhi·ªÅu con d·∫•u), l·∫ßn 4 th√¨ b√™n trung t√¢m visa kh√¥ng ch·∫•p nh·∫≠n gi·∫•y Ch·ª©ng nh·∫≠n RA v√† gi·∫•y b·∫£o l√£nh v√¨ th·ªùi ƒëi·ªÉm m√† gi√°o s∆∞ k√≠ 2 gi·∫•y ƒë√≥ qu√° 3 th√°ng g·∫ßn nh·∫•t, th·∫ø l√† m√¨nh ph·∫£i nh·ªù gs g·ª≠i l·∫°i 2 b·∫£n m·ªõi v·ªõi th·ªùi ƒëi·ªÉm ƒë∆∞·ª£c c·∫≠p nh·∫≠t, v√† t·ªõi l·∫ßn 5 th√¨ m·ªõi oke.  P/s: C√° nh√¢n m√¨nh th·∫•y trung t√¢m Visa l√†m vi·ªác kh√° thi·∫øu chuy√™n nghi·ªáp, nh·ªØng th√¥ng tin n√†y ko h·ªÅ ƒë∆∞·ª£c ghi tr√™n web, nh√¢n vi√™n th√¨ ko n√≥i r√µ r√†ng ƒë·ªÉ tr√°nh vi·ªác xin ƒëi xin l·∫°i. V√† ri√™ng ƒë·ªëi v·ªõi m√¨nh, cay nh·∫•t l√† ·ªü l·∫ßn xin visa th·ª© 3, b√™n KVAC c√≥ b·∫£o m√¨nh b·ªï sung m·ªôt lo·∫°i gi·∫•y t·ªù th·ªÉ hi·ªán th√¥ng tin c·ªßa gs v√† m√¨nh, nh∆∞ng t·ªõi l·∫ßn 4 l√™n n·ªôp th√¨ trung t√¢m l·∫°i b·∫£o kh√¥ng c·∫ßn gi·∫•y ƒë√≥ n·ªØa. V√¨ v·∫≠y, c√°c b·∫°n n√™n h·ªèi th·∫≠t kƒ© trung t√¢m nh√©.\nTr√™n ƒë√¢y l√† nh·ªØng kinh nghi·ªám ƒë√∫t k·∫øt c·ªßa m√¨nh, b·∫°n n√†o c√≥ √Ω ƒë·ªãnh sang H√†n h√£y t√¨m hi·ªÉu k·ªπ nh√©. Good luck!\n(T√≠n Nguy·ªÖn) ","link":"fingerstin.org/post/personal/korea_prof_scholarship/","section":"post","tags":["scholarship","korea"],"title":"Professor Scholarship in Korea"},{"body":"","link":"fingerstin.org/archives/","section":"","tags":null,"title":""},{"body":"Written in Go, Hugo is an open source static site generator available under the Apache Licence 2.0. Hugo supports TOML, YAML and JSON data file types, Markdown and HTML content files and uses shortcodes to add rich content. Other notable features are taxonomies, multilingual mode, image processing, custom output formats, HTML/CSS/JS minification and support for Sass SCSS workflows.\nHugo makes use of a variety of open source projects including:\n https://github.com/yuin/goldmark https://github.com/alecthomas/chroma https://github.com/muesli/smartcrop https://github.com/spf13/cobra https://github.com/spf13/viper  Hugo is ideal for blogs, corporate websites, creative portfolios, online magazines, single page applications or even a website with thousands of pages.\nHugo is for people who want to hand code their own website without worrying about setting up complicated runtimes, dependencies and databases.\nWebsites built with Hugo are extremelly fast, secure and can be deployed anywhere including, AWS, GitHub Pages, Heroku, Netlify and any other hosting provider.\nLearn more and contribute on GitHub.\n","link":"fingerstin.org/about/","section":"","tags":null,"title":"About"},{"body":"Using Notices functionality within this theme\nThe \u0026quot;Notices\u0026quot; shortcode enables you to call out pieces of information - sidebars, warnings, tips, etc.\nTo create a notice on a page, you can use the notice shortcode.\nYou use the notice shortcode, with the first parameter being one of note, info, tip, and warning. Then add a title for your note in quotes as the second parameter. The inner body of the note can be whatever markdown you want to create.\nThe following shortcode syntax within a markdown doc:\n1{{% notice note \u0026#34;Note\u0026#34; %}} 2This is a standard \u0026#34;note\u0026#34; style. 3{{% /notice %}} will render as:\nNote This is a standard \u0026quot;note\u0026quot; style.\n The other three variants follow.\nInfo Here is the \u0026quot;info\u0026quot; style.\n Tip Here is a \u0026quot;tip\u0026quot; variant of a notice.\n Warning Here is the \u0026quot;warning\u0026quot; flavor of a notice.\n Also note that the content of a notice can contain anything you could put on a normal page - as shown below:\nComplex Notices are Possible! This is a notice that has a lot of various kinds of content in it.\n Here is a bulleted list With more than one bullet  And even more than one level    Code blocks are fine here, too....\n1public void SayHello() 2{ 3Console.WriteLine(\u0026#34;Hello, world!\u0026#34;); 4}   Productivity Booster! If you're using VS Code for your editing, copy the .vscode\\clarity.code-snippets file into a .vscode root folder on your repo. This will enable you to type note then \u0026lt;tab\u0026gt; then choose with up/down arrows which flavor notice you want, then \u0026lt;tab\u0026gt; again to provide a title, then \u0026lt;tab\u0026gt; to add your content!\n    To use the snippet, you need to first enable quickSuggestions for Markdown (one time only):\n Go to Preferences-\u0026gt;Settings then search for quickSuggestions Follow the link to Edit in settings.json Toward the bottom of the file, paste in the following JSON:  1\u0026#34;[markdown]\u0026#34;: { 2\u0026#34;editor.quickSuggestions\u0026#34;: true 3} Close and save the settings.    Emoji can be enabled in a Hugo project in a number of ways.\nThe emojify function can be called directly in templates or Inline Shortcodes.\nTo enable emoji globally, set enableEmoji to true in your site's configuration and then you can type emoji shorthand codes directly in content files; e.g.\nüôà :see_no_evil: üôâ :hear_no_evil: üôä :speak_no_evil:\nThe Emoji cheat sheet is a useful reference for emoji shorthand codes.\n N.B. The above steps enable Unicode Standard emoji characters and sequences in Hugo, however the rendering of these glyphs depends on the browser and the platform. To style the emoji you can either use a third party emoji font or a font stack; e.g.\n1.emoji { 2font-family: Apple Color Emoji, Segoe UI Emoji, NotoColorEmoji, Segoe UI Symbol, Android Emoji, EmojiSymbols; 3}  Mathematical notation in a Hugo project can be enabled by using third party JavaScript libraries.\n In this example we will be using KaTeX\n Create a partial under /layouts/partials/math.html Within this partial reference the Auto-render Extension or host these scripts locally. Include the partial in your templates like so:  1{{ if or .Params.math .Site.Params.math }} 2{{ partial \u0026#34;math.html\u0026#34; . }} 3{{ end }}  To enable KaTex globally set the parameter math to true in a project's configuration To enable KaTex on a per page basis include the parameter math: true in content files  Note: Use the online reference of Supported TeX Functions\nExamples Block math: $$ \\varphi = 1+\\frac{1} {1+\\frac{1} {1+\\frac{1} {1+\\cdots} } } $$\n This article offers a sample of basic Markdown syntax that can be used in Hugo content files, also it shows whether basic HTML elements are decorated with CSS in a Hugo theme.\n Headings The following HTML \u0026lt;h1\u0026gt;‚Äî\u0026lt;h6\u0026gt; elements represent six levels of section headings. \u0026lt;h1\u0026gt; is the highest section level while \u0026lt;h6\u0026gt; is the lowest.\nH1 H2 H3 H4 H5 H6 Paragraph Xerum, quo qui aut unt expliquam qui dolut labo. Aque venitatiusda cum, voluptionse latur sitiae dolessi aut parist aut dollo enim qui voluptate ma dolestendit peritin re plis aut quas inctum laceat est volestemque commosa as cus endigna tectur, offic to cor sequas etum rerum idem sintibus eiur? Quianimin porecus evelectur, cum que nis nust voloribus ratem aut omnimi, sitatur? Quiatem. Nam, omnis sum am facea corem alique molestrunt et eos evelece arcillit ut aut eos eos nus, sin conecerem erum fuga. Ri oditatquam, ad quibus unda veliamenimin cusam et facea ipsamus es exerum sitate dolores editium rerore eost, temped molorro ratiae volorro te reribus dolorer sperchicium faceata tiustia prat.\nItatur? Quiatae cullecum rem ent aut odis in re eossequodi nonsequ idebis ne sapicia is sinveli squiatum, core et que aut hariosam ex eat.\nImages Local image, alt text as caption The following image is located within the Hugo site. Because it has alt text but no title text, the caption is generated by the alt text.\n    Remote image, specified caption The following image is loaded from a remote URL. The alt text is the same (for screen readers and in cases when the image doesn't load) but because a separate title is provided, the title is used for the caption:\n  This is Jane Doe  Image with alt text and no caption Alt text is always recommended for SEO, accessibility and in cases when images don't load. However, you don't necessarily always want an image to have a caption. In that case, use a title with one space:\n    Blockquotes The blockquote element represents content that is quoted from another source, optionally with a citation which must be within a footer or cite element, and optionally with in-line changes such as annotations and abbreviations.\nBlockquote without attribution  Tiam, ad mint andaepu dandae nostion secatur sequo quae. Note that you can use Markdown syntax within a blockquote.\n Blockquote with attribution  Don't communicate by sharing memory, share memory by communicating.\n‚Äî Rob Pike1\n Tables Tables aren't part of the core Markdown spec, but Hugo supports supports them out-of-the-box.\n   Name Age     Bob 27   Alice 23    Inline Markdown within tables    Italics Bold Code     italics bold code    Code Blocks Code block with backticks 1\u0026lt;!doctype html\u0026gt; 2\u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; 3\u0026lt;head\u0026gt; 4\u0026lt;meta charset=\u0026#34;utf-8\u0026#34;\u0026gt; 5\u0026lt;title\u0026gt;Example HTML5 Document\u0026lt;/title\u0026gt; 6\u0026lt;/head\u0026gt; 7\u0026lt;body\u0026gt; 8\u0026lt;p\u0026gt;Test\u0026lt;/p\u0026gt; 9\u0026lt;/body\u0026gt; 10\u0026lt;!-- this line is extraneous 2Error from server (Forbidden): deployments.apps is forbidden: User \u0026#34;chiptest\u0026#34; cannot create resource \u0026#34;deployments\u0026#34; in API group \u0026#34;apps\u0026#34; in the namespace \u0026#34;default\u0026#34; --\u0026gt; 11\u0026lt;/html\u0026gt; Code block indented with four spaces \u0026lt;!doctype html\u0026gt; \u0026lt;html lang=\u0026quot;en\u0026quot;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026quot;utf-8\u0026quot;\u0026gt; \u0026lt;title\u0026gt;Example HTML5 Document\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;Test\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt;  Code block with Hugo's internal highlight shortcode 1\u0026lt;!doctype html\u0026gt; 2\u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; 3\u0026lt;head\u0026gt; 4\u0026lt;meta charset=\u0026#34;utf-8\u0026#34;\u0026gt; 5\u0026lt;title\u0026gt;Example HTML5 Document\u0026lt;/title\u0026gt; 6\u0026lt;/head\u0026gt; 7\u0026lt;body\u0026gt; 8\u0026lt;p\u0026gt;Test\u0026lt;/p\u0026gt; 9\u0026lt;/body\u0026gt; 10\u0026lt;/html\u0026gt; List Types Ordered List  First item Second item Third item  Unordered List  List item Another item And another item  Nested list  Fruit  Apple Orange Banana   Dairy  Milk Cheese    Other Elements ‚Äî abbr, sub, sup, kbd, mark GIF is a bitmap image format.\nH2O\nXn + Yn = Zn\nPress CTRL+ALT+Delete to end the session.\nMost salamanders are nocturnal, and hunt for insects, worms, and other small creatures.\n Lorem est tota propiore conpellat pectoribus de pectora summo. Redit teque digerit hominumque toris verebor lumina non cervice subde tollit usus habet Arctonque, furores quas nec ferunt. Quoque montibus nunc caluere tempus inhospita parcite confusaque translucet patri vestro qui optatis lumine cognoscere flos nubis! Fronde ipsamque patulos Dryopen deorum.\n Exierant elisi ambit vivere dedere Duce pollice Eris modo Spargitque ferrea quos palude  Rursus nulli murmur; hastile inridet ut ab gravi sententia! Nomine potitus silentia flumen, sustinet placuit petis in dilapsa erat sunt. Atria tractus malis.\n Comas hunc haec pietate fetum procerum dixit Post torum vates letum Tiresia Flumen querellas Arcanaque montibus omnes Quidem et  Vagus elidunt \nThe Van de Graaf Canon\nMane refeci capiebant unda mulcebat Victa caducifer, malo vulnere contra dicere aurato, ludit regale, voca! Retorsit colit est profanae esse virescere furit nec; iaculi matertera et visa est, viribus. Divesque creatis, tecta novat collumque vulnus est, parvas. Faces illo pepulere tempus adest. Tendit flamma, ab opes virum sustinet, sidus sequendo urbis.\nIubar proles corpore raptos vero auctor imperium; sed et huic: manus caeli Lelegas tu lux. Verbis obstitit intus oblectamina fixis linguisque ausus sperare Echionides cornuaque tenent clausit possit. Omnia putatur. Praeteritae refert ausus; ferebant e primus lora nutat, vici quae mea ipse. Et iter nil spectatae vulnus haerentia iuste et exercebat, sui et.\nEurytus Hector, materna ipsumque ut Politen, nec, nate, ignari, vernum cohaesit sequitur. Vel mitis temploque vocatus, inque alis, oculos nomen non silvis corpore coniunx ne displicet illa. Crescunt non unus, vidit visa quantum inmiti flumina mortis facto sic: undique a alios vincula sunt iactata abdita! Suspenderat ego fuit tendit: luna, ante urbem Propoetides parte.\n Hugo ships with several Built-in Shortcodes for rich content, along with a Privacy Config and a set of Simple Shortcodes that enable static and no-JS versions of various social media embeds.\n  Instagram Simple Shortcode  YouTube Privacy Enhanced Shortcode    Twitter Simple Shortcode Owl bet you\u0026#39;ll lose this staring contest ü¶â pic.twitter.com/eJh4f2zncC\n\u0026mdash; San Diego Zoo Wildlife Alliance (@sandiegozoo) October 26, 2021  See documentation https://gohugo.io/content-management/shortcodes/#tweet for more details\n Vimeo Simple Shortcode  .__h_video { position: relative; padding-bottom: 56.23%; height: 0; overflow: hidden; width: 100%; background: #000; } .__h_video img { width: 100%; height: auto; color: #000; } .__h_video .play { height: 72px; width: 72px; left: 50%; top: 50%; margin-left: -36px; margin-top: -36px; position: absolute; cursor: pointer; }    Page bundles are an optional way to organize page resources within Hugo.\nYou can opt-in to using page bundles in Hugo Clarity with usePageBundles in your site configuration or in a page's front matter. Read more about usePageBundles.\nWith page bundles, resources for a page or section, like images or attached files, live in the same directory as the content itself rather than in your static directory.\nHugo Clarity supports the use of leaf bundles, which are any directories within the content directory that contain an index.md file. Hugo's documentation gives this example:\n1content 2‚îú‚îÄ‚îÄ about 3‚îÇ ‚îú‚îÄ‚îÄ index.md 4‚îú‚îÄ‚îÄ posts 5‚îÇ ‚îú‚îÄ‚îÄ my-post 6‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ content1.md 7‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ content2.md 8‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ image1.jpg 9‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ image2.png 10‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ index.md 11‚îÇ ‚îî‚îÄ‚îÄ my-other-post 12‚îÇ ‚îî‚îÄ‚îÄ index.md 13‚îÇ 14‚îî‚îÄ‚îÄ another-section 15‚îú‚îÄ‚îÄ .. 16‚îî‚îÄ‚îÄ not-a-leaf-bundle 17‚îú‚îÄ‚îÄ .. 18‚îî‚îÄ‚îÄ another-leaf-bundle 19‚îî‚îÄ‚îÄ index.md  In the above example `content` directory, there are four leaf bundles: about: This leaf bundle is at the root level (directly under content directory) and has only the index.md.\nmy-post: This leaf bundle has the index.md, two other content Markdown files and two image files. image1 is a page resource of my-post and only available in my-post/index.md resources. image2 is a page resource of my-post and only available in my-post/index.md resources.\nmy-other-post: This leaf bundle has only the index.md.\nanother-leaf-bundle: This leaf bundle is nested under couple of directories. This bundle also has only the index.md.\nThe hierarchy depth at which a leaf bundle is created does not matter, as long as it is not inside another leaf bundle.\n Advantages to using page bundles The image below is part of the bundle of this page, and is located at content/post/bundle/building.png. Because it's within this page's bundle, the markup for the image only has to specify the image's filename, building.png.\n    If you ever change the name of the directory in which this Markdown file and the image reside, the reference to the image would not need to be updated.\nIn addition to more cleanly organizing your content and related assets, when using page bundles, Hugo Clarity will automatically generate markup for modern image formats, which are smaller in file size.\nFor instance, when you reference an image like building.png, Hugo Clarity will check to see if the same image (based on filename) exists in WebP, AVIF or JXL formats. If you inspect the image above, you'll see a \u0026lt;source\u0026gt; element for building.webp, because that file is also present. Hugo Clarity will only include the markup if these images exist.\nBrowsers that support these formats and the \u0026lt;picture\u0026gt; element will load them, while browsers that do not will fall-back to the default image. Read more about this process.\nFinally, note that page assets can be further managed and refined within the page's front matter if you wish, and are not limited to images alone.\nDisadvantages to using page bundles Page resources in a bundle are only available to the page with which they are bundled ‚Äî that means you can't include an image with one page and then reference it from another.\nImages that are being used in multiple places are more appropriate for your Hugo assets directory. Unlike files in the Hugo static directory, files in the assets directory can be run through Hugo Pipes, which includes image processing.\n  The above quote is excerpted from Rob Pike's talk during Gopherfest, November 18, 2015.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n  ","link":"fingerstin.org/post/hugo_guidance/","section":"post","tags":null,"title":"Hugo Usage"},{"body":"","link":"fingerstin.org/tags/index/","section":"tags","tags":null,"title":"index"}]