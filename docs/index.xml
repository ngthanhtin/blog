<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Tin&#39;s Blog</title>
    <link>https://ngthanhtin.github.io/blog/</link>
    <description>Recent content on Tin&#39;s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Mon, 26 Apr 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://ngthanhtin.github.io/blog/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>(St) Relationship</title>
      <link>https://ngthanhtin.github.io/blog/personal/relationship/</link>
      <pubDate>Mon, 26 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://ngthanhtin.github.io/blog/personal/relationship/</guid>
      <description>RELATIONSHIP Lâu nay, thấy nhiều bạn trẻ vầy nè, hông đầu tư xây dựng, kiến tạo quan hệ gì hết. Nhưng khi cần thì lao vào hỏi han nhờ vả như đúng rồi. Rồi chỉ biết xong chuyện của mình, lo cho mình, lợi mình mình, còn đương nhiên người khác có trách nhiệm phải giúp mình một cách vô mong cầu, bất vụ lợi. Ở đâu ra giống loài thanh cao như thế chỉ để phục vụ các cậu thế?</description>
    </item>
    
    <item>
      <title>Tản mạn phờ hắc đi (3)</title>
      <link>https://ngthanhtin.github.io/blog/personal/tan-man-phd3/</link>
      <pubDate>Mon, 26 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://ngthanhtin.github.io/blog/personal/tan-man-phd3/</guid>
      <description>Như đã nói lần trước, mình bây giờ đã quyết tâm stop phd để lấy master thôi, r về nước làm một thời gian rồi đi tiếp. Nếu mọi việc trơn tru thì tháng 3/2022 mình sẽ xin hb giáo sư, sau đó sẽ nộp giấy tờ cho trường, nhưng tháng 8 thì mới có bằng master nên ko thể nào nhập học kì tháng 9 ở chỗ mới được, nên là phải đợi đến kì học tháng 3/2023 thì mới đi được.</description>
    </item>
    
    <item>
      <title>Bilinear (Trilinear) Attention</title>
      <link>https://ngthanhtin.github.io/blog/ml_technique/2021-02-02-bi-tri-attention/</link>
      <pubDate>Mon, 29 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://ngthanhtin.github.io/blog/ml_technique/2021-02-02-bi-tri-attention/</guid>
      <description>Hi các bạn, ở bài post này mình tiếp tục chia sẽ một kĩ thuật Attention dùng trong bài toán Visual Question Answering (VQA) đó là Bi-Attention (Tri-Attention), ở bài trước mình có đề cập tới một kĩ thuật khác gọi là Stacked Attention Link paper: Bilinear Attention Link code: Code
1. Introduction Đầu tiên, chúng ta cần hiểu VQA là gì, nếu bạn chưa biết thì có thể xem bài viết trước của mình để hiểu nó, link.</description>
    </item>
    
    <item>
      <title>Tản mạn phờ hắc đi (2)</title>
      <link>https://ngthanhtin.github.io/blog/personal/tan-man-phd2/</link>
      <pubDate>Mon, 29 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://ngthanhtin.github.io/blog/personal/tan-man-phd2/</guid>
      <description>Dạo gần đây cảm thấy khá chán nản, một phần vì đang mùa covid, một phần vì ở lab hơi chán, một phần nữa là cảm thấy mình kém cỏi thật. Hahaa. Lúc mới bắt đầu đi học PhD, mình nghĩ sẽ học thẳng một lèo luôn 4,5 năm để xong r đi đâu đi, nhưng giờ lại cảm thấy hơi lung lay bởi vì lab mình khá là ko active, mỗi người làm một thứ đổi lại thì giáo thoải mái, nhưng cá nhân mình là một người thích thử thách, nên khi ở trong một môi trường như thế này làm cho mình cảm thấy ko thoải mái và muốn bứt ra.</description>
    </item>
    
    <item>
      <title>Learning Rate Scheduling in Pytorch</title>
      <link>https://ngthanhtin.github.io/blog/ml_technique/learningrate-scheduling/</link>
      <pubDate>Thu, 25 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://ngthanhtin.github.io/blog/ml_technique/learningrate-scheduling/</guid>
      <description>Hi, bài viết hôm nay mình sẽ nói qua một số phương pháp điều chỉnh learning rate trong quá trình train một model hay còn gọi là learning rate scheduler. Việc điều chỉnh learning rate trong quá trình train là một việc rất có lợi để model có thể tìm đc local minima một cách hợp lí hơn.
Nội dung chính sẽ bao gồm các phần sau: 
 Lambda LR.</description>
    </item>
    
    <item>
      <title>Optmization - Direct Method: Nelder Mead Simplex</title>
      <link>https://ngthanhtin.github.io/blog/algorithms_for_optimization/direct_method/optimization-direct-method-nelder-mead-simplex/</link>
      <pubDate>Thu, 18 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://ngthanhtin.github.io/blog/algorithms_for_optimization/direct_method/optimization-direct-method-nelder-mead-simplex/</guid>
      <description>Hi, xin chào các bạn, hôm này mình sẽ giới thiệu cho các bạn thêm về một phương pháp Optmization bằng Direct Method đó là Nelder Mead Simplex. Phương pháp này được 2 nhà khoa học John Nelder và Roger Mead tạo ra trong một paper mang tên A Simplex Method for Function Minimization năm 1965.
Nội dung chính sẽ bao gồm các phần sau: 
 Giới thiệu phương pháp Nelder-Mead-Simplex.</description>
    </item>
    
    <item>
      <title>Optmization - Direct Method - Powell Method</title>
      <link>https://ngthanhtin.github.io/blog/algorithms_for_optimization/direct_method/optimization-direct-method-powell/</link>
      <pubDate>Mon, 15 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://ngthanhtin.github.io/blog/algorithms_for_optimization/direct_method/optimization-direct-method-powell/</guid>
      <description>Hi, xin chào các bạn, hôm này mình sẽ giới thiệu cho các bạn thêm về một phương pháp Optmization bằng Direct Method đó là Powell Method. Trước khi bước vào nội dung, nếu bạn nào chưa biết Optimization là gì hoặc phương pháp Direct là gì có thể ghé qua 2 bài post sau: Optimization: https://ngthanhtin.github.io/blog/optimization-gioi-thieu/ Direct Method: https://ngthanhtin.github.io/blog/optimization-direct-method-gioi-thieu/ Nội dung chính sẽ bao gồm các phần sau:</description>
    </item>
    
    <item>
      <title>Optmization - Direct Method Introduction</title>
      <link>https://ngthanhtin.github.io/blog/algorithms_for_optimization/direct_method/optimization-direct-method-gioi-thieu/</link>
      <pubDate>Mon, 15 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://ngthanhtin.github.io/blog/algorithms_for_optimization/direct_method/optimization-direct-method-gioi-thieu/</guid>
      <description>Hi, xin chào các bạn, hôm này mình sẽ giới thiệu cho các bạn về một phương pháp Optmization khác nữa đó là Direct Method. Phương pháp này thường được gọi là zero-order, black box, pattern search, hoặc derivative-free methods vì nó không sử dụng đạo hàm để tìm được local minimum, mà phương pháp này sẽ dùng những cách khác để chọn ra hướng tìm kiếm ở mỗi step để tìm ra local minimum và làm sao để biết khi nào là convergence.</description>
    </item>
    
    <item>
      <title>Optmization - Direct Method: Divided Rectangle (DIRECT)</title>
      <link>https://ngthanhtin.github.io/blog/algorithms_for_optimization/direct_method/optimization-direct-method-direct/</link>
      <pubDate>Mon, 15 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://ngthanhtin.github.io/blog/algorithms_for_optimization/direct_method/optimization-direct-method-direct/</guid>
      <description>Hi, xin chào các bạn, hôm này mình sẽ giới thiệu cho các bạn về một phương pháp Optmization bằng Direct Method đó là DIvided RECTangle (DIRECT).
Nội dung chính sẽ bao gồm các phần sau: 
 Giới thiệu phương pháp Divided Rectangle (DIRECT). Thuật toán. Code. Bàn luận. Tham khảo.  1. Giới thiệu phương pháp Divided Rectangle (DIRECT). Thuật toán DIRECT là một thuật toán sampling, nghĩa là nó ko dùng thông tin về gradient để tìm điểm design point tiếp theo.</description>
    </item>
    
    <item>
      <title>Optmization - Direct Method: Hooke Jeeves and Pattern Search</title>
      <link>https://ngthanhtin.github.io/blog/algorithms_for_optimization/direct_method/optimization-direct-method-hooke-jeeves-pattern-search/</link>
      <pubDate>Mon, 15 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://ngthanhtin.github.io/blog/algorithms_for_optimization/direct_method/optimization-direct-method-hooke-jeeves-pattern-search/</guid>
      <description>Hi, xin chào các bạn, hôm này mình sẽ giới thiệu cho các bạn thêm về một phương pháp Optmization bằng Direct Method đó là Hooke-Jeeves method và Pattern Search. Trước khi bước vào nội dung, nếu bạn nào chưa biết Optimization là gì hoặc phương pháp Direct là gì có thể ghé qua 2 bài post sau: Optimization: https://ngthanhtin.github.io/blog/optimization-gioi-thieu/ Direct Method: https://ngthanhtin.github.io/blog/optimization-direct-method-gioi-thieu/
Nội dung chính sẽ bao gồm các phần sau:</description>
    </item>
    
    <item>
      <title>Giới thiệu về Optmization</title>
      <link>https://ngthanhtin.github.io/blog/algorithms_for_optimization/direct_method/optimization-gioi-thieu/</link>
      <pubDate>Sun, 14 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://ngthanhtin.github.io/blog/algorithms_for_optimization/direct_method/optimization-gioi-thieu/</guid>
      <description>Hi, xin chào các bạn, hôm này mình sẽ giới thiệu cho các bạn về toán Optmization. Nói về Deep Learning thì không thể thiếu được Optimization, chắc hẳn ai làm DL đều đã xài qua những cái như SGD, Adam, Adagrad, KAFC, etc. Tác dụng của optimization đó là giúp tìm ra local minima của model, khi đó ta có thể nói model đã converge.
Tuy nhiên, để hiểu rõ cách thức hoạt động của optimization, chúng ta phải hiểu nó là gì, và nó áp dụng như thế nào?</description>
    </item>
    
    <item>
      <title>Label Smoothing</title>
      <link>https://ngthanhtin.github.io/blog/ml_technique/2021-02-21-label-smoothing/</link>
      <pubDate>Sun, 21 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://ngthanhtin.github.io/blog/ml_technique/2021-02-21-label-smoothing/</guid>
      <description>Hi, xin chào các bạn, hôm này mình sẽ giới thiệu cho các bạn một cách để tránh overfitting và overconfidence đó là phương pháp Label Smoothing
Nội dung chính sẽ bao gồm các phần sau: 
1. Label Smoothing là gì? Đối với một model classification, model thường gặp phải 2 vấn đề: overfitting, and overconfidence. Label smoothing là một phương pháp regularization có thể giải quyết 2 vấn đề kể trên.</description>
    </item>
    
    <item>
      <title>My Career (1)</title>
      <link>https://ngthanhtin.github.io/blog/personal/2021-02-22-con-duong-su-nghiepp1/</link>
      <pubDate>Sun, 21 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://ngthanhtin.github.io/blog/personal/2021-02-22-con-duong-su-nghiepp1/</guid>
      <description>Hi, xin chào các bạn, lâu rồi chưa review lại những công việc mình đã từng làm từ hồi còn là sinh viên cho tới bây giờ cho nên hôm nay tui ngồi tổng hợp lại để xem mình đã học được những gì và mất những gì trên con đường sự nghiệp của mình
1. Gameloft Vào hè năm 2 (6-2016) Mình có được công việc đầu tiên là ở Gameloft, và ở vị trí Intern, sau khi intern 3 tháng hè thì mình quyết định trở thành nhân viên chính thức.</description>
    </item>
    
    <item>
      <title>Tìm hiểu Categorical Cross-Entropy Loss, Binary Cross-Entropy Loss, Softmax Loss, Logistic Loss, Focal Loss, you name it</title>
      <link>https://ngthanhtin.github.io/blog/ml_technique/2021-02-21-tim-hieu-mot-so-ham-loss/</link>
      <pubDate>Sun, 21 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://ngthanhtin.github.io/blog/ml_technique/2021-02-21-tim-hieu-mot-so-ham-loss/</guid>
      <description>Hi, xin chào các bạn, hôm này mình sẽ giải thích một số hàm loss cho các bạn như Cross entropy loss, binary cross-entropy loss, etc Mình làm bài viết này bởi vì tên của các hàm loss này thường rất dễ bị nhầm lẫn, cộng với việc mỗi framework lại có những cái tên na ná nhau, vì vậy mình sẽ giúp các bạn phân biệt chúng.
Nội dung chính sẽ bao gồm các phần sau:</description>
    </item>
    
    <item>
      <title>Tản mạn phờ hắc đi (1)</title>
      <link>https://ngthanhtin.github.io/blog/personal/2021-02-24-tan-man-phd/</link>
      <pubDate>Sun, 21 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://ngthanhtin.github.io/blog/personal/2021-02-24-tan-man-phd/</guid>
      <description>Hi, hôm nay mình quyết định viết về quá trình phờ hắc đi của mình, do cũng chán chả có gì làm, tự hỏi sao các bạn phd khác bận vãi trong khi mình ngồi coi yutube đồ các kiểu, chán quá
1. Viết blog Mình đã muốn viết blog từ lâu r, nhưng lúc đó k biết tới githubio, viết bằng wordpress thì tốn tiền hosting nữa nên thoai kaka.</description>
    </item>
    
    <item>
      <title>Buy Me A Coffee</title>
      <link>https://ngthanhtin.github.io/blog/personal/buy-me-a-coffe/</link>
      <pubDate>Sat, 06 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://ngthanhtin.github.io/blog/personal/buy-me-a-coffe/</guid>
      <description>&lt;p&gt;If you like my open source projects or they can help you. You can buy me a coffee ☕.~&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Stacked Attention Network</title>
      <link>https://ngthanhtin.github.io/blog/ml_technique/2021-02-01-stacked-attention-network/</link>
      <pubDate>Fri, 05 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://ngthanhtin.github.io/blog/ml_technique/2021-02-01-stacked-attention-network/</guid>
      <description>Hi, xin chào các bạn, hôm này mình sẽ giới thiệu cho các bạn mô hình Stacked Attention được dùng trong bài toán Visual Question Answering (VQA) Link paper: Stacked Attention Networks for Image Question Answering (2016) Link code: Code
Nội dung chính sẽ bao gồm các phần sau: 
1. Giới thiệu bài toàn Visual Question Answering
2. Nguyên lý
3. Phương pháp
4. Giải thuật
5. Ứng dụng</description>
    </item>
    
    <item>
      <title>Giới thiệu SLAM</title>
      <link>https://ngthanhtin.github.io/blog/slam/2020-02-24-slam/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ngthanhtin.github.io/blog/slam/2020-02-24-slam/</guid>
      <description>Hello các bạn, ở bài post này mình sẽ giới thiệu qua bài toán Song định tuyến đồ hay còn gọi là SLAM (Simultaneous localization and mapping).
## Giới thiệu Bài toán này là bài toán định vị vị trí robot và xây dựng lại bản đồ cùng lúc. Ta sử dụng SLAM khi robot không biết trước bản đồ môi trường làm việc cũng như pose của nó. Đặc điểm của SLAM là: Ước lượng liên tục: ước lượng robot pose và vị trí của các vật thể trong bản đồ.</description>
    </item>
    
    <item>
      <title>Install Cuda on Ubuntu 18.04</title>
      <link>https://ngthanhtin.github.io/blog/software/2020-10-14-install-cuda-on-ubuntu-18-04/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ngthanhtin.github.io/blog/software/2020-10-14-install-cuda-on-ubuntu-18-04/</guid>
      <description>Hi các bạn, ở bài viết này mình sẽ hướng dẫn các bạn cách cài đặt Cuda trên Ubuntu 18.04 1. Start terminal and remove any NVIDIA traces you may have on your machine.
sudo rm /etc/apt/sources.list.d/cuda*  sudo apt remove &amp;ndash;autoremove nvidia-cuda-toolkit  sudo apt remove &amp;ndash;autoremove nvidia-* 
2. Setup the correct CUDA PPA on your system 
sudo apt update  sudo add-apt-repository ppa:graphics-drivers sudo apt-key adv &amp;ndash;fetch-keys http://developer.</description>
    </item>
    
    <item>
      <title>Install Torch with Cuda 10.0</title>
      <link>https://ngthanhtin.github.io/blog/software/2020-10-14-install-torch-with-cuda-10-0/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ngthanhtin.github.io/blog/software/2020-10-14-install-torch-with-cuda-10-0/</guid>
      <description>Hi các bạn, ở bài viết này mình sẽ hướng dẫn các bạn cách cài đặt Torch và cách làm sao để Torch làm việc với Cuda 10.0
In the terminal, run the commands WITHOUT sudo git clone https://github.com/torch/distro.git ~/torch &amp;ndash;recursive  cd ~/torch  bash install-deps 
Ở bước này các bạn có thể gõ :  ./install.sh để cài đặt, nhưng nó chỉ làm việc với cuda 5.0</description>
    </item>
    
    <item>
      <title>Instruction Navigation</title>
      <link>https://ngthanhtin.github.io/blog/rl/2021-02-02-instruction-navigation/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ngthanhtin.github.io/blog/rl/2021-02-02-instruction-navigation/</guid>
      <description>Hi, xin chào các bạn, hôm này mình sẽ giới thiệu cho các bạn bài toán Instruction Navigation sử dụng Reinforcement Learning (có nhiều cách để giải bài toán này, chúng ta cũng có thể sử dụng Supervised Learning để giải). Link paper: Paper Link code: Code
Nội dung chính sẽ bao gồm các phần sau: 1. Giới thiệu bài toàn Instruction Navigation  2. Nguyên lý  3. Phương pháp</description>
    </item>
    
    <item>
      <title>Kinh nghiệm ôn thi IELTS từ 4.5 lên 6.0</title>
      <link>https://ngthanhtin.github.io/blog/personal/2020-02-24-kinh-nghiem-hoc-ielts-4.5-6.0/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ngthanhtin.github.io/blog/personal/2020-02-24-kinh-nghiem-hoc-ielts-4.5-6.0/</guid>
      <description>Hello các bạn, mình mới thi ielts 7/12/2019 và đạt 6.0. Mình sẽ chia sẽ cách mà mình đã ôn luyện để đạt được mục tiêu này.
Đây là số điểm của mình:
Listening Về phần này, mình chỉ luyện tập bằng bộ Cambridge test 7-14 thần thánh.
Đối với listening, mình học hết cách làm các dạng bài bằng quyển Official Guide to IELTS. Sau đó, mình bắt đầu luyện đề.</description>
    </item>
    
    <item>
      <title>Multiple Object Tracking with Kalman Filter and Hungary Algorithm</title>
      <link>https://ngthanhtin.github.io/blog/tracking/2021-02-04-multiple-object-tracking-with-kalman-filter/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ngthanhtin.github.io/blog/tracking/2021-02-04-multiple-object-tracking-with-kalman-filter/</guid>
      <description>Hi, xin chào các bạn, hôm này mình sẽ giới thiệu cho các bạn bài toán Multiple Object Tracking sử dụng Kalman Filter để theo vết đối tượng và thuật toán Hungary để giải bài toán credit assignment, nói nôm na là làm sao gán từng tracker vào mỗi object sao cho chi phí là ít nhất. Ngoài ra, ở bài này, mình chỉ sử dụng phương pháp trừ nền (Background Subtraction) để detect đối tượng động.</description>
    </item>
    
    <item>
      <title>Mùa đông đầu tiên tại Hàn Quốc 2020</title>
      <link>https://ngthanhtin.github.io/blog/personal/2021-02-02-winter-korean-2020/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ngthanhtin.github.io/blog/personal/2021-02-02-winter-korean-2020/</guid>
      <description> </description>
    </item>
    
    <item>
      <title>Professor Scholarship in Korea</title>
      <link>https://ngthanhtin.github.io/blog/personal/2020-12-07-hoc-bong-giao-su-han-quoc/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ngthanhtin.github.io/blog/personal/2020-12-07-hoc-bong-giao-su-han-quoc/</guid>
      <description>Hi everyone, bài này mình sẽ chia sẽ về quá trình xin học bổng ở Hàn Quốc, làm giấy tờ và một số lưu ý khác.
Nói sơ qua một chút, mình may mắn nhận được học bổng giáo sư tại HQ vào tháng 9/2020 tại trường đại học Sejong ngành Computer Science and Engineering, trường này cũng khá nổi tiếng về ngành Computer Science. Tuy nhiên, mình chọn ngôi trường là vì mình tìm được giáo sư có hướng nghiên cứu mà mình ưa thích đó là Computer Vision in Robotics, Drone, etc.</description>
    </item>
    
    <item>
      <title>Review sách Lexicode</title>
      <link>https://ngthanhtin.github.io/blog/personal/2020-02-24-review-lexicode/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ngthanhtin.github.io/blog/personal/2020-02-24-review-lexicode/</guid>
      <description>Trong một post gần đây của Tổng thống Trump, ông có viết “to contain the Coronavirus”. Cứ theo nghĩa thông thường thì Google dịch là “chứa đựng”. Còn theo sách “Lexicode” thì lại là “kiềm chế, kiểm soát”.
Lexicode là cuốn sách giải nghĩa những từ khó trong tiếng Anh, nhưng rất hay được sử dụng bởi người bản xứ. Sách giải thích rất chi tiết, cặn kẽ, nhiều ví dụ minh hoạ.</description>
    </item>
    
    <item>
      <title>Single Object Tracking with Particle Filter</title>
      <link>https://ngthanhtin.github.io/blog/tracking/2021-02-04-single-object-tracking-with-pf/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ngthanhtin.github.io/blog/tracking/2021-02-04-single-object-tracking-with-pf/</guid>
      <description>Hi, xin chào các bạn, hôm này mình sẽ giới thiệu cho các bạn bài toán Single Object Tracking sử dụng Particle Filter Link paper: A New Framework of Moving Object Tracking based on Object Detection-Tracking with Removal of Moving Features using Stereo Camera and IMU Link code: Code. Đây chỉ là code implementation của module face tracking bằng c++, tuy nhiên nó sẽ giúp bạn biết được khái quát particle filter được implement như thế nào.</description>
    </item>
    
    <item>
      <title>SLAM Roadmap</title>
      <link>https://ngthanhtin.github.io/blog/slam/2021-01-31-slam-roadmap/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ngthanhtin.github.io/blog/slam/2021-01-31-slam-roadmap/</guid>
      <description>Hi các bạn, mình đang học về SLAM nên hôm nay quyết định tổng hợp lại kiến thức về SLAM thành một dạng như Roadmap. Các bạn hãy tham khảo và cho ý kiến nhé.
Beginner Làm quen với SLAM Monocular SLAM RGB-D SLAM Tham khảo https://github.com/changh95/visual-slam-roadmap</description>
    </item>
    
  </channel>
</rss>
