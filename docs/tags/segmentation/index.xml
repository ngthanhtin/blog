<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>segmentation on Tin&#39;s Blog</title>
    <link>https://ngthanhtin.github.io/blog/tags/segmentation/</link>
    <description>Recent content in segmentation on Tin&#39;s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Wed, 05 Jul 2023 00:00:00 +0000</lastBuildDate><atom:link href="https://ngthanhtin.github.io/blog/tags/segmentation/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Train a MaskFormer Segmentation Model with Hugging Face Transformers</title>
      <link>https://ngthanhtin.github.io/blog/research_papers/2023-06-05-mask2former-training/</link>
      <pubDate>Wed, 05 Jul 2023 00:00:00 +0000</pubDate>
      
      <guid>https://ngthanhtin.github.io/blog/research_papers/2023-06-05-mask2former-training/</guid>
      <description>Hello everyone, Link paper: MaskFormer
1. Introduction Đầu tiên, chúng ta cần hiểu VQA là gì, nếu bạn chưa biết thì có thể xem bài viết trước của mình để hiểu nó, link.  Nguyên lý của bài toán này đó là làm sao có thể kết hợp 2 feature vision và text lại với nhau thành một vector chung, sau đó đưa vector này sang một classifier để tìm ra answer, và có nhiều phương pháp hiện nay sử dụng để kết hợp 2 feature đó lại với nhau.</description>
    </item>
    
  </channel>
</rss>
