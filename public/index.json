[{"body":"","link":"fingerstin.org/","section":"","tags":null,"title":""},{"body":"","link":"fingerstin.org/tags/idea/","section":"tags","tags":null,"title":"idea"},{"body":"","link":"fingerstin.org/series/personal/","section":"series","tags":null,"title":"Personal"},{"body":"","link":"fingerstin.org/tags/personal/","section":"tags","tags":null,"title":"personal"},{"body":"","link":"fingerstin.org/post/","section":"post","tags":["index"],"title":"Posts"},{"body":"","link":"fingerstin.org/tags/presentation/","section":"tags","tags":null,"title":"presentation"},{"body":" Idea 2024\n [2024] Idea Proposal   Lab Meeting 2024\n [Jul 10, 2024] Why are Visually-Grounded Language Models Bad at Image Classification   [May 16, 2024] Hierarchical Open-vocabulary Universal Image Segmentation   [Apr 16, 2024] GLaMM: Pixel Grounding Large Multimodal Model   [Mar 12, 2024] Improved Zero-shot Classification by Adapting VLMs with Text Descriptions   [Jan 30, 2024] Classification based on Boxes and Phrases (Research Project)  2023\n [Nov 21, 2023] What does CLIP know about a red circle? Visual prompt engineering for VLMs   [Oct 3, 2023] CLIP-Event: Connecting Text and Images with Event Structures   [Aug 25, 2023] How does â€œhabitatâ€ help fine-grained bird identification? (Research Project)   [Apr 25, 2023] Zero-Shot Classification by Logical Reasoning on Natural Language Explanations   [Mar 21, 2023] Open-Vocabulary Semantic Segmentation With Mask-Adapted CLIP    [Feb 14, 2023] STAIR: Learning Sparse Text and Image Representation in Grounded Tokens  2022\n [Nov 22, 2022] Re-labeling ImageNet - from Single to Multi-Labels, from Global to Localized Labels   [Oct 18, 2022] Class Activation Latent Mapping - Keep CALM and Improve Visual Feature Attribution   [Sep 20, 2022] Mask2Former: Masked-attention Mask Transformer for Universal Image Segmentation    ","link":"fingerstin.org/post/personal/presentations/","section":"post","tags":["personal","idea","presentation","talk"],"title":"Presentations"},{"body":"","link":"fingerstin.org/series/","section":"series","tags":null,"title":"Series"},{"body":"","link":"fingerstin.org/tags/","section":"tags","tags":null,"title":"Tags"},{"body":"","link":"fingerstin.org/tags/talk/","section":"tags","tags":null,"title":"talk"},{"body":"","link":"fingerstin.org/tags/guitar/","section":"tags","tags":null,"title":"Guitar"},{"body":"    Start learning guitar: 12-2023. Ká»‰ niá»‡m 8 thÃ¡ng há»c guitar, cÅ©ng dÃ¡nh sÆ¡ sÆ¡ Ä‘Æ°á»£c fingerstyle. Hi vá»ng cÃ³ nhiá»u thá»i gian hÆ¡n Ä‘á»ƒ luyá»‡n ngÃ³n, cáº£m Ã¢m vÃ  táº­p thÃªm bÃ i má»›i, thÃªm Ä‘á»‡m hÃ¡t vÃ  nháº¡c lÃ­ ná»¯a. ğŸ¤˜ Youtube Channel: https://www.youtube.com/@tinnguyen2828\nEtude 1:  Kiss the rain: Em cÃ³ á»•n khÃ´ng: https://www.youtube.com/watch?v=afnC5jO4HC4  Sunflower: Xá»© thanh hoa:\n","link":"fingerstin.org/post/guitar/guitar/","section":"post","tags":["Guitar","Hobby"],"title":"Guitar"},{"body":"","link":"fingerstin.org/tags/hobby/","section":"tags","tags":null,"title":"Hobby"},{"body":"","link":"fingerstin.org/tags/ai/","section":"tags","tags":null,"title":"AI"},{"body":"  Deep Learning Foundations and Concepts (Christopher M. Bishop with Hugh Bishop) 2024    Build a Large Language Model (From Scratch) (Sebastian Raschka)   ","link":"fingerstin.org/post/books/ai/","section":"post","tags":["Book","AI"],"title":"AI Books"},{"body":"","link":"fingerstin.org/tags/book/","section":"tags","tags":null,"title":"Book"},{"body":"Things I want to do before I die. Please let me know if you have any recommendation. Progress as of Jul 12, 2024: 8/100.\n âŒ Learn Japanese âœ… Study abroad ã€½ï¸ Learn guitar and start a youtube channel ã€½ï¸ Learn soccer and establish a team âœ… Work in an international company âœ… Publish paper in some pronounced conferences/journals ã€½ï¸ Become the first author of a paper at a top-tier conference ~ (had a pub in a top-tier NLP conf, waiting for a top-tier CV conf) âœ… Fall in love  ","link":"fingerstin.org/post/personal/list100/","section":"post","tags":["personal"],"title":"List 100"},{"body":"","link":"fingerstin.org/post/books/misc/","section":"post","tags":["Book"],"title":"Misc Books"},{"body":"General Questions You Will be Asked: Tip: Ask early on: What the interviewing faculty is working on? (this gives an idea of what he/she sees as a possible alignment to your own research work).\nRead up on their recent work and ask relevant questions or pose possible extensions. Ask good questions.\n Tell us about yourself. Whyâ€™d you apply here? Or What drew you to this program?   Research fit, what is that they are doing that excites you? Interdisciplinary, collaborations, etc.  Why do you want to work with ___? Whatâ€™s something you want to study? Tell us about your interests, and what you wish to work on? What do you hope to do after? What are your strengths \u0026amp; weaknesses?   Strengths: Good at collaborations, perseverance, hardworking, help others, learning, teaching, decent research experience. Weaknesses: improve my writing (I am getting better at it). Overcome this with experience and practice.  Questions for us?  Describe your research experiences.   Know the big picture/significance of the work, and also the finer details of what you specifically did experimentally.\n  What would you do if you could continue to work on the research project longer term?\nComments: Be honest, positive, enthusiastic, have ideas, do not come across as rigid.\nYour Story and Todos:  Read your SOPs Research Interests Read all your papers and make notes. Key contributions, your role, shortcomings, future work. Have a short sales pitch presentation on your work (~10 slides). Keep backup slides in case you might have to go into more details.  Questions to Ask the Faculty:  What are the current projects that your group is involved with? Or possible newer projects?  What are some of the projects that you and your students are currently working on?   What is the lab structure? (how collaborative/disjointed are lab membersâ€™ projects?)  Ask about collaborations, training grants, the campus, the city, etc.   Are there lab meetings? What are other meetings you will see your advisor in a group with other people? What progress does the advisor generally expect from a student in the course of a semester? (Submission/Publication pace) How much freedom do you think Iâ€™d have in selecting my own projects? What other expectations does the advisor have for their students: time/vacation/paper/project/experiment wise etc. Where does their funding primarily come from? (If military / industry-focused funding bothers you, figure this out).  Is there a TA requirement? / How often would I be expected to TA?   What have previous lab members done after getting their PhD? How many students are in the group? (Number of undergrad/masters/phd/post doc)  NOTE: Most of these might seem generic, but tailor them according to your research area, and speak with confidence on the work you have done. Technical Interview Questions: https://github.com/Sroy20/machine-learning-interview-questions\nReferences  PhD Interview Prep: https://docs.google.com/document/d/13ZUx7AvLUIV4IUkzjU1HoT2czex9DA3NLd8zkeyGUlE/edit Grad School Interview Questions and Answers!: https://www.youtube.com/watch?v=Jt1YP1Th4ZE PhD Interview Questions: https://www.youtube.com/watch?v=0t51IEfiSMg PhD Admissions Visit: https://www.youtube.com/watch?v=OugQPPVM-wc  (TÃ­n Nguyá»…n)  ","link":"fingerstin.org/post/personal/faq_phd_interviews/","section":"post","tags":["scholarship","personal","US"],"title":"PhD Interviews"},{"body":"","link":"fingerstin.org/tags/scholarship/","section":"tags","tags":null,"title":"scholarship"},{"body":"","link":"fingerstin.org/tags/us/","section":"tags","tags":null,"title":"US"},{"body":"","link":"fingerstin.org/categories/","section":"categories","tags":null,"title":"Categories"},{"body":"In this post, I want to introduce a new topic which is took place at First Workshop on â€‹Multimodal Fact-Checking and Hate Speech Detection in AAAI 2022. And I got the 1st position on the leaderboard of this challenge. Link to the challenge: https://aiisc.ai/defactify/memotion_2.html\n1. Abstract In this post, I want to talk about Meme Analysis which is about explaining its Sentiment, Emotion and Intensity.  The growing ubiquity of Internet memes on social media platforms such as Facebook, Instagram, and Twitter further suggests that we can not ignore such multimodal content (vision and language) anymore. To the best of our knowledge, there is not much attention towards meme emotion, and sentiment analysis.  The task of Memotion analysis consists of three task (1) sentiment(positive, negative, neutral) classification, (2) emotion (sarcastic,funny,offensive, motivation) classification and (3) their corresponding intensity. \nHere is some example of Meme Images, they contain two information simultaneously which is text and image: \n2. Model The models consist of 3 primary types which are Unimodal for Only Text, Unimodal for Only Image, Multimodal for Text and Image. In the Multimodal, I also employed several fusion mechanism such as Concatenation, Multihop Attention, and Stacked Attention. \n2.1 Unimodal for Text BERT and its variant, e.g., RoBERTa, are widely used in Natural Language Processing (NLP) tasks and have demonstrated as efficient methods. In this competition, we employed them for three subtasks. In subtasks A and B, a RoBERTa is used while in subtask C, four RoBERTa models are adopted so that every backbone corresponds classifying the intensity of each emotion.\n2.2 Unimodal for Image As a vision-based approach, EfficientNet-v2 is a well-known backbone with respect to speedy inference and a low number of parameters. In three subtasks, EfficientNet-v2 is used as an extractor to create embeddings. Subtask A has one classification branch to deal with three sentiment types while subtasks B and C have four branches which each is responsible for classifying four types of emotions as well as their intensity.\n2.3 Multimodal Multi-modality is to aggregate vision and text to obtain correlated information. In this challenge, we build three different fusion models including concatenation, multi-hop attention, and stacked attention network.\n2.3.1 Concatenation Traditionally, concatenation of two feature vectors, a.k.a two modalities, has been a typical solution to obtain aggregated features. However, the method does not take into account the importance of each word that is within corresponding regions of the image.\n2.3.2 Multi-hop Attention Multi-hop attention focuses parts of a given image together with texts within it. The technique aims to emphasize dissimilar features between image regions and textual utterances by defining a relevant matrix $R$, which is the cosine distance between textual and visual features.\n2.3.3 Stacked Attention While a multi-hop attention network is used to learn attention maps between an image and texts within it, a stacked attention network has a capability of learning an attention map in multiple times. Through such attention layers, interested regions are promoted through a referred concept within a given sentence.\n3. Techniques In this competition, I have used some techniques to improve the F1 scores of the model.\n3.1 Scence Text Detection Although both textual and visual features are important for meme emotion analysis, there is little correlation between them in the MEMOTION 2.0 dataset. Besides, the caption is also provided as a part of the dataset. Therefore, in this study, the text is removed from the image before extracting and training the proposed model.\nBased on the previous works that summarized both traditional and deep learning approaches for text detection and recognition, we design a preprocessing scheme to remove texts from images as follows. First, we employ the EAST module to detect all text regions in an image. Then these regions are removed from the image, and we use the output image as the input for EfficientNet-v2 in the proposed framework.\nPreprocessing scheme: Given an image as input, we use the EAST detector to detect the region of texts on the image and then remove them 3.2 Auto Augmentation Augmentation is a simple but important technique to increase the size of a given dataset, leading to a better generalization of a training model. However, current data augmentation is based on a set of manually designed algorithms such as Crop, Rotation, and Resize. In our experiment, we adopt the Auto Augment technique which uses reinforcement learning to automatically search for a better data augmentation strategy.\n3.3 Canonical Correlation Analysis The Canonical correlation analysis (CCA) is based on a well-established statistical technique that searches for a linear combination of input vectors by maximizing their correlations. Deep CCA tries to utilize the power of both deep neural networks and CCA to overcome projection constraints of CCA . In this study, correlation scores obtained from Deep CCA is included to our loss function to maximize the correlation between two features, leading to a higher classification rate.\n3.4 Loss function, Optimizer, etc For the classification task, I use CrossEntropy typically, but I also tested on Training Signal Anealing CrossEntropy which is a loss function that helps mitigate the imbalance effect of the dataset.  In terms of Optimizer, I tried several ones such as Adam, SGD, AdamW, LookAHead, etc.\n4. Result Some note about this competition: This is not a fair competition because after the private phase, they recruited more teams to submit and manipulated the results several times. This is quite a pity because I didn't notice that all the chair is Indian.... 5. Application Analysis meme images can help social media platforms such as Facebook, Twitter mitigate the false information that are disemminating widely. Moreover, the technique in this post can be applied to other Vision Language problems.\n6. Code and Paper Link code: Code  Link paper: Paper\n(TÃ­n Nguyá»…n) ","link":"fingerstin.org/post/challenge/memotion2/","section":"post","tags":["Vision-Language"],"title":"Understanding Sentiment, Emotion and its Intensity by Analysing Meme Images"},{"body":" In this post, I want to talk about Vietnamese Image Captioning for Healthcare domains. The problem is important in the context of Covid-19 eppidemic so the Vietnamese Groups have established a competition about it. It is took place in VLSP 2021 Workshop, and I got the 3rd position on the private leaderboard of this challenge. Link to the challenge: https://vlsp.org.vn/vlsp2021/eval/vieCap4H\n1. Abstract This study presents our approach on the automatic Vietnamese image captioning for healthcare domains in text processing tasks of Vietnamese Language and Speech Processing (VLSP) Challenge 2021, as shown in Figure \\ref{fig:example}. In recent years, image captioning often employs a convolutional neural network-based architecture as an encoder and a long short-term memory (LSTM) as a decoder to generate sentences. These models perform remarkably well in different datasets. Our proposed model also has an encoder and a decoder, but we instead use a Swin Transformer in the encoder, and a LSTM combined with an attention module in the decoder. The study presents our training experiments and techniques used during the competition. Our model achieves a BLEU4 score of 0.293 in the vietCap4H dataset, and the score is ranked 3$^{rd}$ on the private leaderboard.\nHere is some example of the dataset including an image and its caption\n2. Model Our model as shown here is an end-to-endfusion of a Swin Transformer encoder and bidirec-tional LSTM (biLSTM) decoder. The model takes in an image and outputs the corresponding caption. \n3. Techniques In this competition, I have used some techniques to improve the BLEU4 score, they are listed below: \n3.1 Cross Validation Cross Validation is a well-known technique that helps us choose the best model checkpoint among different folds. In this challenge, we train with 4 folds and choose the one that gives the best score on the leaderboard.\n3.2 Noise Injection In the field of image captioning, the accuracy ofprediction for the next character can be relativelyhigh if we can ensure that the previous sequenceis predicted correctly. However, if a character is mispredicted, then the prediction failure rate will gradually increase. To tackle the above issue, we use noise injection, which is done by randomly replacing ground truth characters with other characters during training, and new sentences will be called fake_labels. Then, using the modified sentences as the input for the decoder will force it to correctly predict the next character on the basis that the previous one was wrong.\n3.3 Beam search The algorithm is a best first search algorithm which iteratively considers the set of the k best sentences up to time (t) as candidates to generate sentences of size(t+ 1), and keep only the resulting bestkof them because this better approximates the probability of getting the global maximum. We tried beam search sizes from 1 to 10, and the best BLEU4 score achieved with a beam size 2.\n4. Result I got the 3rd position on the leaderboard, and some evolution of my attempt is shown here: \n5. Application Solving the problem leads to several practical applications such as virtual assistants for blind and visually impaired people, conducting visual content indexing and searching.\n6. Code and Paper Link code: Code  Link paper: Paper\n(TÃ­n Nguyá»…n) ","link":"fingerstin.org/post/challenge/vlsp_imagecaptioning/","section":"post","tags":["Vision-Language"],"title":"Vietnamese Image Captioning - VLSP for Health 2021"},{"body":"","link":"fingerstin.org/tags/vision-language/","section":"tags","tags":null,"title":"Vision-Language"},{"body":"","link":"fingerstin.org/categories/vision-language/","section":"categories","tags":null,"title":"Vision-Language"},{"body":"    Hi, xin chÃ o cÃ¡c báº¡n, lÃ¢u rá»“i chÆ°a review láº¡i nhá»¯ng cÃ´ng viá»‡c mÃ¬nh Ä‘Ã£ tá»«ng lÃ m tá»« há»“i cÃ²n lÃ  sinh viÃªn cho tá»›i bÃ¢y giá» cho nÃªn hÃ´m nay tui ngá»“i tá»•ng há»£p láº¡i Ä‘á»ƒ xem mÃ¬nh Ä‘Ã£ há»c Ä‘Æ°á»£c nhá»¯ng gÃ¬ vÃ  máº¥t nhá»¯ng gÃ¬ trÃªn con Ä‘Æ°á»ng sá»± nghiá»‡p cá»§a mÃ¬nh\n1. 6-2016 (NÄƒm 2 Äáº¡i há»c) VÃ o hÃ¨ nÄƒm 2 (6-2016) MÃ¬nh cÃ³ Ä‘Æ°á»£c cÃ´ng viá»‡c Ä‘áº§u tiÃªn lÃ  á»Ÿ má»™t cÃ´ng ty game ná»•i tiáº¿ng á»Ÿ HCM, vÃ  á»Ÿ vá»‹ trÃ­ Intern, sau khi intern 3 thÃ¡ng hÃ¨ thÃ¬ mÃ¬nh quyáº¿t Ä‘á»‹nh trá»Ÿ thÃ nh nhÃ¢n viÃªn chÃ­nh thá»©c. LÃºc Ä‘Ã³ mÃ¬nh ráº¥t thÃ­ch lÃ m game, cÃ³ láº½ lÃ  vÃ¬ lÃºc Ä‘Ã³ cÃ¡i mÃ¬nh biáº¿t duy nháº¥t lÃ  C++, láº­p trÃ¬nh game nÃªn nghÄ© ráº±ng mÃ¬nh sáº½ thÃ­ch lÃ m game developer, vÃ  lÃºc Ä‘Ã³ mÃ¬nh cÅ©ng Ä‘Ã£ cÃ³ suy nghÄ© ráº±ng bá» há»c Ä‘á»ƒ lÃ m cho cÃ´ng ty nÃ y, nhÆ°ng may máº¯n mÃ¬nh Ä‘Ã£ suy nghÄ© ráº¥t kÄ© nÃªn quyáº¿t Ä‘á»‹nh nghá»‰ lÃ m á»Ÿ Ä‘Ã¢y vÃ  táº­p trung vÃ o há»c hÃ nh, nhá» váº­y mÃ  bÃ¢y giá» mÃ¬nh Ä‘Ã£ Ä‘á»¡ hÆ¡n xÃ­ :rofl:. MÃ¬nh Ä‘Æ°á»£c tham gia vÃ o má»™t nhÃ³m lÃ m vá» game Dragon City (náº¿u nhá»› khÃ´ng nháº§m), trong team mÃ¬nh áº¥n tÆ°á»£ng nháº¥t lÃ  má»™t nhÃ³c nhá» hÆ¡n mÃ¬nh 2 tuá»•i, nÃ³ rá»›t Ä‘áº¡i há»c nhÆ°ng biáº¿t code tá»« khÃ¡ lÃ¢u nÃªn nÃ³ xin vÃ o chÃ­nh thá»©c á»Ÿ cty luÃ´n, nhÆ°ng nÃ³ cÅ©ng tÃ¢m sá»± lÃ  xin chuyá»ƒn viá»‡c khÃ¡ khÃ³ cho nÃ³ vÃ¬ nÃ³ khÃ´ng cÃ³ báº±ng Ä‘áº¡i há»c, máº·c dÃ¹ kÄ© nÄƒng code cÅ©ng tá»‘t, biáº¿t nhiá»u framework, chá»‹u Ä‘Æ°á»£c Ã¡p lá»±c. Trong team cÅ©ng cÃ³ má»™t Ã´ng anh lÃ m 2,3 nÄƒm nhÆ°ng tháº¥y chÃ¡n vÃ  quyáº¿t Ä‘á»‹nh vá» quÃª bÃ¡n trÃ¡i cÃ¢y. Nhá»¯ng trÆ°á»ng há»£p nÃ y lÃ m mÃ¬nh suy nghÄ© khÃ¡ nhiá»u vá» tÆ°Æ¡ng lai :thinking: Äiá»u mÃ¬nh há»c Ä‘Æ°á»£c á»Ÿ cty nÃ y lÃ  cÃ¡ch lÃ m viá»‡c nhÃ³m, há»c Ä‘Æ°á»£c thÃªm má»™t framework lÃ m game (cocos2d-x) vÃ  nhá»¯ng kinh nghiá»‡m lÃ m game cá»§a cÃ¡c Ä‘Ã n anh trong cty. Tháº¿ nhÆ°ng khi vÃ o chÃ­nh thá»©c thÃ¬ cÃ´ng viá»‡c khÃ¡ chÃ¡n Ä‘Ã³ lÃ  ngá»“i fix bug cho game tá»« cÃ´ng ty máº¹ gá»­i vá» :expressionless: (cÃ¡i nÃ y tÃ¹y ng cáº£m nháº­n chá»© mÃ¬nh khÃ´ng pháº£i Ä‘i chÃª cty Ä‘Ã¢u). Äáº·c biá»‡t lÃ  chuyáº¿n Ä‘i teambuilding á»Ÿ ÄÃ  Láº¡t cá»±c kÃ¬ tuyá»‡t vá»i, láº§n Ä‘áº§u tiÃªn á»Ÿ khÃ¡ch sáº¡n 5*, vÃ  mÃ¬nh Ä‘Æ°á»£c tráº£i qua hai Ä‘Ãªm vÃ´ cÃ¹ng tuyá»‡t vá»i vá»›i cÃ¡c anh em :satisfied:.\n2. NÄƒm 3 Ä‘áº¿n gáº§n cuá»‘i nÄƒm 4 CÃ´ng viá»‡c thá»© 2 mÃ¬nh cÃ³ Ä‘Æ°á»£c lÃ  á»Ÿ mot cÃ´ng ty Nháº­t. MÃ¬nh cÃ³ Ä‘Æ°á»£c cÃ´ng viá»‡c nÃ y lÃ  do má»™t láº§n a Leader trong cty cÃ³ nhá» tháº§y cá»§a mÃ¬nh giá»›i thiá»‡u sinh viÃªn, vÃ  mÃ¬nh Ä‘Ã£ á»©ng tuyá»ƒn cÃ´ng viá»‡c nÃ y á»Ÿ vá»‹ trÃ­ AI Intern (máº·c dÃ¹ lÃ m nhÆ° nhÃ¢n viÃªn chÃ­nh thá»©c :joy:. á» cty nÃ y, mÃ¬nh Ä‘Ã£ cÃ³ cÆ¡ há»™i lÃ m vá» AI/Computer Vision, vÃ  cÃ³ 2 dá»± Ã¡n lá»›n mÃ  mÃ¬nh Ä‘Ã£ tham gia Ä‘Ã³ lÃ  OCR trÃªn tiáº¿ng nháº­t vÃ  Face Recognition máº·c dÃ¹ lÃºc Ä‘Ã³ váº«n cÃ²n ráº¥t non tay trong viá»‡c tuning, modifiy model nhÆ°ng nhá»¯ng dá»± Ã¡n Ä‘Ã³ lÃ  tiáº¿p thÃªm cho mÃ¬nh Ä‘am mÃª Ä‘á»ƒ tiáº¿p tá»¥c con Ä‘Æ°á»ng AI cá»§a mÃ¬nh. Khi lÃ m viá»‡c á»Ÿ cty nÃ y, mÃ¬nh ráº¥t may máº¯n vÃ¬ Ä‘Æ°á»£c a Leader Æ°u Ã¡i tÃ¬m hiá»ƒu ráº¥t nhiá»u thá»© vÃ  Ä‘áº·c biá»‡t lÃ  cho lÃ m luáº­n vÄƒn cá»§a mÃ¬nh vÃ  cung cáº¥p laptop Ä‘á»ƒ training model. Tuy nhiÃªn, á»Ÿ giá»¯a nÄƒm 4, mÃ¬nh Ä‘Ã£ pháº£i xin nghá»‰ Ä‘á»ƒ táº­p trung vÃ o luáº­n vÄƒn vÃ¬ vá»›i mÃ¬nh luáº­n vÄƒn thá»±c sá»± quan trá»ng vÃ  mÃ¬nh cÃ²n Ä‘áº·t má»¥c tiÃªu ra Ä‘Æ°á»£c paper nÃªn mÃ¬nh pháº£i xin nghá»‰ Ä‘á»ƒ táº­p trung vÃ o viá»‡c nÃ y. NgoÃ i ra, Gumi tháº­t sá»± ko pháº£i lÃ  má»™t cty lÃ m chÃ­nh vá» AI nÃªn mÃ¡y mÃ³c ráº¥t háº¡n cháº¿, nhÃ¢n lá»±c vá» AI cÃ²n non ná»›t, nÃªn Ä‘Ã³ cÅ©ng lÃ  má»™t pháº§n nguyÃªn do mÃ¬nh xin nghá»‰. á» cty nÃ y mÃ¬nh Ä‘Æ°á»£c tá»± há»c nhiá»u thá»©, cÅ©ng vÃ¬ do team AI chá»‰ bao gá»“m nhá»¯ng báº¡n tráº», chÆ°a co kinh nghiá»‡m nhiá»u nÃªn má»—i ngÆ°á»i pháº£i tá»± Ä‘Ã o bá»›i kiáº¿n thá»©c. Tuy nhiÃªn, cty nÃ y cá»§a nháº­t nÃªn cÃ¡ch lÃ m viá»‡c cÅ©ng khÃ¡ cá»©ng nháº¯c, anyway, do tui k thÃ­ch phong cÃ¡ch lÃ m viá»‡c nÃ y thÃ´i, khÃ¡ khÃ³ Ä‘á»ƒ nÃ³i chuyá»‡n vá»›i cáº¥p trÃªn Ä‘á»ƒ trÃ¬nh bÃ y Ã½ kiáº¿n.\n3. Nam 4 + 1 nam sau DH MÃ¬nh Ä‘Æ°á»£c tháº§y mÃ¬nh giá»›i thiá»‡u vÃ o cty nÃ y, lÃºc Ä‘Ã³ chá»‰ cÃ³ 2,3 báº¡n lÃ  Ä‘Æ°á»£c tháº§y \u0026quot;gá»­i gáº¯m\u0026quot; Ä‘á»ƒ cÃ³ thá»ƒ vÃ o Ä‘Ã³ hoÃ n thÃ nh luáº­n vÄƒn.VÃ  tháº­t sá»± cty nÃ y ban Ä‘áº§u lÃ m mÃ¬nh choÃ¡ng ngá»£p bá»Ÿi mÃ¡y mÃ³c vÃ´ cÃ¹ng tá»‘i tÃ¢n, nhÃ¢n viÃªn thÃ¬ cá»±c kÃ¬ giá»i vÃ  Ä‘áº·c biá»‡t lÃ  nÃ³ gáº§n nhÃ  mÃ¬nh :joy:.  Tuy nhiÃªn, mÃ¬nh Ä‘Ã£ quÃ¡ nÃ³ng vá»™i khi xin vÃ o vá»‹ trÃ­ nhÃ¢n viÃªn chÃ­nh thá»©c chá»© ko pháº£i intern nhÆ° cÃ¡c báº¡n khÃ¡c, viá»‡c nÃ y lÃ m cho mÃ¬nh ráº¥t Ã¡p lá»±c vÃ¬ mÃ¬nh pháº£i lÃ m luáº­n vÄƒn vÃ  cháº¡y dá»± Ã¡n cty cÃ¹ng má»™t lÃºc, vÃ  káº¿t quáº£ thÃ¬ ko nÃ³i cÅ©ng biáº¿t, mÃ¬nh chá»‰ cÃ³ thá»ƒ hoÃ n thÃ nh Ä‘Æ°á»£c luáº­n vÄƒn mÃ  k Ä‘áº£m báº£o Ä‘Æ°á»£c nghiÃªn cá»©u cho cty. NhÆ°ng may máº¯n lÃ  mÃ¬nh váº«n Ä‘Æ°á»£c Ä‘áº©y qua team product Ä‘á»ƒ lÃ m sau Ä‘Ã³, lÃºc nÃ y mÃ¬nh thoáº£i mÃ¡i hÆ¡n vÃ¬ Ä‘Ã£ xong luáº­n vÄƒn, vÃ  lÃºc nÃ y mÃ¬nh Ä‘Æ°á»£c lÃ m vá»›i má»™t team product ráº¥t giá»i, máº·c dÃ¹ ko pháº£i lÃ m research nhÆ°ng team nÃ y cÃ³ nhá»¯ng Ã½ tÆ°á»Ÿng ráº¥t hay, code cÅ©ng ráº¥t tá»‘t nÃªn mÃ¬nh Ä‘Ã£ há»c Ä‘Æ°á»£c ráº¥t nhiá»u. HÃ¬nh thá»©c cá»§a cty lÃ  startup nÃªn cÅ©ng cÃ³ nhiá»u láº§n pháº£i thá»©c qua Ä‘Ãªm Ä‘á»ƒ cháº¡y dá»± Ã¡n, Ä‘Ã¢y lÃ  nhá»¯ng ká»‰ niá»‡m Ä‘áº§u Ä‘á»i cÃ³ láº½ mÃ¬nh ko thá»ƒ quÃªn Ä‘Æ°á»£c vá»›i cÃ¡c Ä‘á»“ng nghiá»‡p cá»§a mÃ¬nh. Tuy nhiÃªn, vÃ¬ má»™t vÃ i lÃ­ do, mÃ¬nh cÅ©ng pháº£i rá»i cty, pháº§n lá»›n lÃ  do mÃ¬nh cáº£m tháº¥y con Ä‘Æ°á»ng cá»§a mÃ¬nh ko phÃ¹ há»£p vá»›i Ä‘á»‹nh hÆ°á»›ng cá»§a cty vÃ¬ tháº¿ mÃ¬nh quyáº¿t Ä‘á»‹nh rá»i Ä‘i vÃ  Ä‘áº¿n vá»›i 1 cong ty khac.\n4. Truoc khi roi khoi VN DÃ¢y lÃ  má»™t mÃ´i trÆ°á»ng lÃ­ tÆ°á»Ÿng, cÃ¡c anh chá»‹ á»Ÿ Ä‘Ã¢y cá»±c kÃ¬ nice vÃ  professional. VÃ  á»Ÿ cty nÃ y mÃ¬nh cÅ©ng Ä‘Æ°á»£c lÃ m Ä‘iá»u mÃ¬nh thÃ­ch Ä‘Ã³ lÃ  Robotics Vision, tuy nhiÃªn cty k táº­p trung lÃ m AI mÃ  lÃ  vá» web,apps vÃ  pháº§n cá»©ng cá»§a Robot nÃªn mÃ¬nh cáº£m tháº¥y khÃ³ Ä‘á»ƒ tiáº¿n bá»™, team AI lÃºc Ä‘Ã³ cÅ©ng chá»‰ cÃ³ 2 ng vÃ  má»™t ngÆ°á»i thÃ¬ tá»« BlockChain qua, cÅ©ng chÆ°a cÃ³ nhiá»u kinh nghiá»‡m vá» AI. LÃºc nÃ y mÃ¬nh má»›i quyáº¿t Ä‘á»‹nh Ä‘i lÃ m nghiÃªn cá»©u Ä‘á»ƒ cÃ³ thá»ƒ hoÃ n toÃ n lÃ m thá»© mÃ¬nh thÃ­ch, vÃ¬ tháº¿ mÃ¬nh chá»n du há»c HQ.\n5. Du há»c HQ Khi paper Ä‘áº§u tiÃªn cá»§a mÃ¬nh Ä‘c accept cÃ¹ng vá»›i viá»‡c mÃ¬nh Ä‘Ã£ cÃ³ ielts, tháº§y mÃ¬nh Ä‘Ã£ giÃ³i thiá»‡u luÃ´n há»c bá»•ng giÃ¡o sÆ° hÃ n quá»‘c cho mÃ¬nh. LÃºc Ä‘Ã³ cÅ©ng khÃ¡ bÄƒn khoÄƒn do Ä‘ang dá»‹ch vÃ  mÃ¬nh cÅ©ng Ä‘ang muá»‘n Ä‘i chÃ¢u Ã¢u hÆ¡n (cá»¥ thá»ƒ lÃ  Pháº§n Lan), tuy nhiÃªn tháº§y cÅ©ng Ä‘á»™ng viÃªn vÃ  mÃ¬nh cÅ©ng ham há»‘ Ä‘i nÃªn thÃ´i nháº¯m máº¯t chá»n luÃ´n :joy:. Khi qua Ä‘Ã¢y thÃ¬ mÃ¬nh Ä‘c vÃ o má»™t lab cÃ³ Ä‘iá»u kiá»‡n cÅ©ng khÃ¡ tá»‘t, giÃ¡o cÅ©ng khÃ¡ nice, tuy nhiÃªn thÃ¬ cÅ©ng cÃ³ má»™t vÃ i Ä‘iá»u khÃ´ng thÃ­ch thÃ¬ Ä‘Ã³ lÃ  do cÃ¡ch cáº£m nháº­n cá»§a má»—i ngÆ°á»i khi lÃ m viá»‡c á»Ÿ lab thÃ´i, báº£n thÃ¢n mÃ¬nh cáº£m tháº¥y chÆ°a cÃ³ gÃ¬ lÃ  quÃ¡ Ä‘Ã¡ng. Tuy nhiÃªn, Ä‘iá»u mÃ¬nh cáº£m tháº¥y thiáº¿u á»Ÿ lab hiá»‡n táº¡i lÃ  cÃ¡c member trong lab má»—i ngÆ°á»i lÃ m má»™t viá»‡c khÃ¡c nhau nÃªn cÅ©ng khÃ³ cÃ³ thá»ƒ trao Ä‘á»•i, hÆ¡n ná»¯a, cÃ¡ nhÃ¢n mÃ¬nh thÃ­ch cÃ¡c cuÃ´c thi Ä‘á»ƒ nÃ¢ng cao kháº£ nÄƒng nhÆ°ng trong lab ko ai thÃ­ch thÃº cáº£, cÃ³ ngÆ°á»i thÃ¬ chá»‰ Ä‘Äƒng kÃ­ xong, rá»“i download data, xong rá»“i Ä‘á»ƒ Ä‘Ã³ cÅ©ng cháº³ng lÃ m gÃ¬, vÃ¬ váº­y mÃ¬nh hiá»‡n táº¡i váº«n Ä‘ang alone (cÃ´ Ä‘á»™c) trong lab =)))))))\n6. Future Trong tÆ°Æ¡ng lai, cÃ³ thá»ƒ mÃ¬nh sáº½ ko hoÃ n thÃ nh chÆ°Æ¡ng trÃ¬nh Tiáº¿n sÄ© mÃ  sáº½ xin xuá»‘ng Tháº¡c sÄ© vÃ  vá» nÆ°á»›c xin viá»‡c, hoáº·c mÃ¬nh sáº½ hoÃ n thÃ nh luÃ´n Tiáº¿n sÄ© vÃ  xin Postdoc á»Ÿ má»™t nÆ°á»›c khÃ¡c hoáº·c cÃ³ thá»ƒ vá» nÆ°á»›c xin viá»‡c =))), 2 Ä‘áº¥t nÆ°á»›c mÃ  mÃ¬nh thÃ­ch nháº¥t bÃ¢y giá» cÃ³ láº½ lÃ  nÆ°á»›c Anh (vÃ  trÆ°á»ng mÃ  mÃ¬nh thÃ­ch nháº¥t á»Ÿ Anh lÃ  Imperial College London) vÃ  Thá»¥y Äiá»ƒn (trÆ°á»ng mÃ¬nh thÃ­ch nháº¥t lÃ  Royal KTH), anyway, Ä‘Ã³ lÃ  má»™t cÃ¢u chuyá»‡n khÃ¡ xa, bÃ¢y giá» mÃ¬nh chá»‰ muá»‘n ra Ä‘c má»™t, hai paper thÃ´i, thá»ƒ lÃ  Ä‘á»§ Ä‘á»ƒ tá»‘t nghiá»‡p, kakaka.\n(TÃ­n Nguyá»…n)  ","link":"fingerstin.org/post/personal/career/","section":"post","tags":["personal"],"title":"My Career"},{"body":"Hi, xin chÃ o cÃ¡c báº¡n, hÃ´m nÃ y mÃ¬nh sáº½ giá»›i thiá»‡u cho cÃ¡c báº¡n bÃ i toÃ¡n Multiple Object Tracking sá»­ dá»¥ng Kalman Filter Ä‘á»ƒ theo váº¿t Ä‘á»‘i tÆ°á»£ng vÃ  thuáº­t toÃ¡n Hungary Ä‘á»ƒ giáº£i bÃ i toÃ¡n credit assignment, nÃ³i nÃ´m na lÃ  lÃ m sao gÃ¡n tá»«ng tracker vÃ o má»—i object sao cho chi phÃ­ lÃ  Ã­t nháº¥t. NgoÃ i ra, á»Ÿ bÃ i nÃ y, mÃ¬nh chá»‰ sá»­ dá»¥ng phÆ°Æ¡ng phÃ¡p trá»« ná»n (Background Subtraction) Ä‘á»ƒ detect Ä‘á»‘i tÆ°á»£ng Ä‘á»™ng. CÃ¡c báº¡n cÃ³ thá»ƒ thay tháº¿ báº±ng cÃ¡c thuáº­t toÃ¡n object detection khÃ¡c nhÆ° YOLO, Faster RCNN, Centernet, etc. Link code: ÄÃ¢y lÃ  code cá»§a thuáº­t toÃ¡n, Ä‘Ã£ Ä‘Æ°á»£c mÃ¬nh implement báº±ng C++, Ä‘Ã¢y cÅ©ng lÃ  Ä‘á»“ Ã¡n mÃ´n Computer Vision cá»§a mÃ¬nh há»“i nÄƒm 3 táº¡i trÆ°á»ng Ä‘áº¡i há»c khoa há»c tá»± nhiÃªn, Há»“ ChÃ­ Minh. Code\nNá»™i dung chÃ­nh sáº½ bao gá»“m cÃ¡c pháº§n sau: 1. Giá»›i thiá»‡u bÃ i toÃ n Multiple Object Tracking  2. NguyÃªn lÃ½  3. PhÆ°Æ¡ng phÃ¡p \n 3.1 Background Generation 3.2 Object Detection  3.3 Kalman Filter  3.4 Hungary Algorithm   4. á»¨ng dá»¥ng  5. Tham kháº£o \n1. Giá»›i thiá»‡u bÃ i toÃ¡n Multiple Object Tracking  ÄÃ¢y Ä‘Æ¡n giáº£n lÃ  bÃ i toÃ¡n theo váº¿t nhiá»u Ä‘á»‘i tÆ°á»£ng cÃ¹ng má»™t lÃºc. 2. NguyÃªn lÃ½  NguyÃªn lÃ­ cá»§a bÃ i toÃ¡n nÃ y váº«n lÃ  tÃ¬m kiáº¿m nhiá»u Ä‘á»‘i tÆ°á»£ng (object detection) vÃ  so khá»›p (matching) Ä‘á»‘i tÆ°á»£ng vá»›i nhá»¯ng Ä‘á»‘i tÆ°á»£ng á»Ÿ frame trÆ°á»›c Ä‘á»ƒ xÃ¡c Ä‘á»‹nh Ä‘Ã¢u lÃ  nhá»¯ng Ä‘á»‘i tÆ°á»£ng cáº§n theo váº¿t. 3. PhÆ°Æ¡ng phÃ¡p  á» frame Ä‘áº§u tiÃªn, ta sáº½ dÃ¹ng phÆ°Æ¡ng phÃ¡p trá»« ná»n Ä‘á»ƒ phÃ¡t hiá»‡n Ä‘á»‘i tÆ°á»£ng vÃ  cÅ©ng sáº½ Ä‘Æ°á»£c dÃ¹ng á»Ÿ nhá»¯ng frame sau vá»›i má»¥c Ä‘Ã­ch detect Ä‘á»‘i tÆ°á»£ng Ä‘á»™ng. Sau Ä‘Ã³, ta sáº½ dÃ¹ng Kalman Filter (KF) Ä‘á»ƒ dá»± Ä‘oÃ¡n vá»‹ trÃ­ tiáº¿p theo cá»§a tá»«ng Ä‘á»‘i tÆ°á»£ng.\nÄá»ƒ cÃ³ thá»ƒ dá»± Ä‘oÃ¡n Ä‘Æ°á»£c vá»‹ trÃ­ báº±ng KF chÃ­nh xÃ¡c, ta pháº£i thá»±c hiá»‡n so khá»›p (matching). á» bÆ°á»›c nÃ y, ta pháº£i xÃ¡c Ä‘á»‹nh Ä‘Æ°á»£c Ä‘á»‘i tÆ°á»£ng nÃ o lÃ  Ä‘á»‘i tÆ°á»£ng nÃ o á»Ÿ frame trÆ°á»›c Ä‘Ã³, vÃ  ta sáº½ giáº£i quyáº¿t báº±ng thuáº­t toÃ¡n Hungary Algorithm.\nCuá»‘i cÃ¹ng lÃ  láº·p láº¡i quÃ¡ trÃ¬nh trÃªn Ä‘áº¿n khi video káº¿t thÃºc.\n  3.1 Background Generation Äá»ƒ sá»­ dá»¥ng phÆ°Æ¡ng phÃ¡p trá»« ná»n, yÃªu cáº§u lÃ  background cá»§a chÃºng ta pháº£i khÃ¡ tÄ©nh, náº¿u background Ä‘á»™ng thÃ¬ phÆ°Æ¡ng phÃ¡p khÃ´ng cÃ²n tÃ¡c dá»¥ng vÃ¬ phÆ°Æ¡ng phÃ¡p nÃ y má»¥c Ä‘Ã­ch lÃ  Ä‘á»ƒ trÃ­ch xuáº¥t Ä‘Æ°á»£c nhá»¯ng Ä‘á»‘i tÆ°á»£ng Ä‘á»™ng.  Äá»ƒ trá»« ná»n, ta Ä‘Æ¡n giáº£n chá»‰ cáº§n dÃ¹ng background á»Ÿ frame (t) - background á»Ÿ frame (t-1). Tuy nhiÃªn, mÃ¬nh Ä‘Ã£ thá»­ vÃ  tháº¥y cÃ³ má»™t phÆ°Æ¡ng phÃ¡p khÃ¡c hay hÆ¡n, Ä‘Ã³ lÃ  Pixel Histrogram. Pixel Histogram lÃ  phÆ°Æ¡ng phÃ¡p tÃ¡i táº¡o ná»n, input sáº½ lÃ  má»™t histogram, output lÃ  ná»n Ä‘Æ°á»£c tÃ¡i táº¡o dÆ°á»›i dáº¡ng grayscale. Giáº£ sá»­ má»—i kÃ­ch thÆ°á»›c cá»§a má»™t frame lÃ  w (width) vÃ  h (height). á»¨ng vá»›i má»—i pixel trÃªn frame, ta sáº½ cÃ³ má»™t histogram 256 chiá»u. Sau khi cÃ³ Ä‘Æ°á»£c táº¥t cáº£ lÃ  (w x h) histogram, ta sáº½ láº¥y ra giÃ¡ trá»‹ mÃ u lá»›n nháº¥t á»Ÿ má»—i histogram vÃ  Ä‘áº·t lÃ m giÃ¡ trá»‹ mÃ u táº¡i pixel tÆ°Æ¡ng á»©ng. Cuá»‘i cÃ¹ng sáº½ tÃ¡i táº¡o Ä‘Æ°á»£c background. Äá»ƒ táº¡o ra Ä‘Æ°á»£c tá»«ng histogram Ä‘Ã³, ta cáº§n pháº£i lÆ°á»›t qua K frame cá»§a video, á»©ng vá»›i má»—i frame ta sáº½ lÆ°á»›t tá»«ng pixel, láº¥y ra giÃ¡ trá»‹ mÃ u á»Ÿ pixel Ä‘Ã³ vÃ  cuá»‘i cÃ¹ng lÃ  tÄƒng thÃªm 1 cho bin mÃ u tÆ°Æ¡ng á»©ng cá»§a histogram. Sau khi lÆ°á»›t háº¿t K frame, ta sáº½ cÃ³ Ä‘Æ°á»£c (w x h) histogram.\n  3.2 Object Detection Sau khi cÃ³ Ä‘Æ°á»£c ná»n, ta sáº½ bÆ°á»›c Ä‘áº¿n giai Ä‘oáº¡n detection \u0026amp; tracking. Äá»ƒ detect nhá»¯ng Ä‘á»‘i tÆ°á»£ng Ä‘á»™ng, má»—i láº§n process frame, ta sáº½ láº¥y frame Ä‘Ã³ trá»« cho ná»n Ä‘Ã£ Ä‘Æ°á»£c tÃ¡i táº¡o báº±ng phÆ°Æ¡ng phÃ¡p á»Ÿ trÃªn. PhÆ°Æ¡ng phÃ¡p nÃ y ráº¥t Ä‘Æ¡n giáº£n, náº¿u 2 Ä‘á»‘i tÆ°á»£ng Ä‘i gáº§n nhau quÃ¡ sáº½ bá»‹ dÃ­nh vÃ  cho lÃ  1 Ä‘á»‘i tÆ°á»£ng nhÆ°ng Ä‘Æ°á»£c cÃ¡i lÃ  nÃ³ cá»±c kÃ¬ nhanh =)) ÄÃ¢y lÃ  phÆ°Æ¡ng phÃ¡p Ä‘Æ¡n giáº£n, vÃ¬ há»“i Ä‘Ã³ má»›i sinh viÃªn, cÃ³ biáº¿t deep learning Ä‘Ã¢u nÃªn lÃ m cÃ¡ch nÃ y haha. BÃ¢y giá» cÃ¡c báº¡n cÃ³ thá»ƒ dÃ¹ng YOLO hoáº·c Faster RCNN, CenterNet Ä‘á»ƒ detect cho chÃ­nh xÃ¡c hÆ¡n.\n    3.3 Kalman Filter Kalman Filter lÃ  má»™t mÃ´ hÃ¬nh lá»c nhiá»…u, nÃ³ bao gá»“m 2 pháº§n Ä‘Ã³ lÃ  dá»± Ä‘oÃ¡n (predict) vÃ  cáº­p nháº­t (update). á» bÆ°á»›c predict, nÃ³ sáº½ dá»± Ä‘oÃ¡n vá»‹ trÃ­ cá»§a tá»«ng Ä‘á»‘i tÆ°á»£ng, sau Ä‘Ã³ á»Ÿ bÆ°á»›c Update nÃ³ sáº½ cáº­p nháº­t, sá»­a láº¡i cho Ä‘Ãºng hÆ¡n.\n  3.4 Hungary Algorithm ÄÃ¢y lÃ  thuáº­t toÃ¡n dÃ¹ng Ä‘á»ƒ giáº£i quyáº¿t assignment problem. Assignment Problem lÃ  bÃ i toÃ¡n cÃ³ N Ä‘á»‘i tÆ°á»£ng, vÃ  M cÃ´ng viá»‡c, má»—i Ä‘á»‘i tÆ°á»£ng khi lÃ m má»™t cÃ´ng viá»‡c nÃ o Ä‘Ã³ sáº½ cÃ³ má»™t chi phÃ­ nháº¥t Ä‘á»‹nh. VÃ  nhiá»‡m vá»¥ Ä‘Ã³ lÃ  lÃ m sao gÃ¡n má»—i Ä‘á»‘i tÆ°á»£ng cho má»™t cÃ´ng viá»‡c nÃ o Ä‘Ã³ sao cho tá»•ng chi phÃ­ lÃ  nhá» nháº¥t. \n  Äá»‘i vá»›i bÃ i toÃ¡n tracking, ta cÃ³ thá»ƒ Ã¡p dá»¥ng nhÆ° sau: Ta cÃ³ N tracker vÃ  M Ä‘á»‘i tÆ°á»£ng detect Ä‘Æ°á»£c, vÃ  ta pháº£i gÃ¡n tá»«ng tracker vá»›i tá»«ng Ä‘á»‘i tÆ°á»£ng sao cho chi phÃ­ lÃ  nhá» nháº¥t. Váº­y chi phÃ­ á»Ÿ Ä‘Ã¢y lÃ  gÃ¬ ? Má»—i tracker Ä‘Ã³ chÃ­nh lÃ  má»™t Kalman Filter (KF), á»Ÿ má»—i frame, KF sáº½ dá»± Ä‘oÃ¡n vá»‹ trÃ­ cá»§a Ä‘á»‘i tÆ°á»£ng trÆ°á»›c, gá»i lÃ  p_predict, vÃ  á»Ÿ má»—i frame ta láº¡i detect Ä‘á»‘i tÆ°á»£ng vÃ  ra Ä‘Æ°á»£c vá»‹ trÃ­ cá»§a chÃºng gá»i lÃ  p_object. Váº­y, khá»ang cÃ¡ch giá»¯a p_predict vÃ  p_object chÃ­nh lÃ  chi phÃ­. Ta sáº½ Ä‘Æ°a thÃ´ng tin nÃ y qua thuáº­t toÃ¡n Hungary Ä‘á»ƒ giáº£i quyáº¿t bÃ i toÃ¡n assignment, vÃ  KF sáº½ cáº­p nháº­t láº¡i vá»‹ trÃ­ tracking cá»§a mÃ¬nh. 5. á»¨ng dá»¥ng vÃ  BÃ n luáº­n  BÃ i toÃ¡n nÃ y Ä‘Æ°á»£c á»©ng dá»¥ng trong theo váº¿t Ä‘á»‘i tÆ°á»£ng giao thÃ´ng, Ä‘á»‘i tÆ°á»£ng trong cÃ¡c siÃªu thá»‹, cá»­a hÃ ng, ... á» bÃ i viáº¿t nÃ y, mÃ¬nh chá»‰ viáº¿t trÃ¬nh bÃ y Ä‘Æ¡n giáº£n cÃ¡c bÆ°á»›c, chÆ°a trÃ¬nh bÃ y kÄ© thuáº­t toÃ¡n cÅ©ng nhÆ° cÃ³ code minh há»a vÃ¬ mÃ¬nh khÃ´ng cÃ³ thá»i gian nhiá»u Ä‘á»ƒ lÃ m kÄ©, mong cÃ¡c báº¡n thÃ´ng cáº£m. Äá»ƒ hiá»ƒu hÆ¡n vá» bÃ i viáº¿t, cÃ¡c báº¡n cÃ³ thá»ƒ tham kháº£o link repo cá»§a mÃ¬nh nhÃ©. Náº¿u tháº¥y hay, cho mÃ¬nh má»™t star hoáº·c fork trÃªn repo nhÃ©. Thank you for reading.\n6. Tham kháº£o  Code\n(TÃ­n Nguyá»…n) ","link":"fingerstin.org/post/tracking/multiple_object_tracking/","section":"post","tags":["multiple-object-tracking"],"title":"Multiple Object Tracking with Kalman Filter and Hungary Algorithm"},{"body":"","link":"fingerstin.org/tags/multiple-object-tracking/","section":"tags","tags":null,"title":"multiple-object-tracking"},{"body":"","link":"fingerstin.org/categories/object-tracking/","section":"categories","tags":null,"title":"Object Tracking"},{"body":"In this post, I want to introduce a hot topic in Reinforcement Learning which is Instruction Navigation. Although Navigation can be tackled by using Supervised Learning, but using Reinforcement Learning help us learn without any human-labeled data.\nLink paper: Paper Link code: Code\nThe content is as following: 1. Introduction to Instruction Navigation  2. Principle  3. Methodology \n 3.1 Image Representation Module  3.2 Text Representation Module  3.3 Attented Representation Module  3.4 Policy Learning   4. Application  5. Reference \n1. Introduction to Instruction Navigation  Navigation problem is a familiar topic and it has been carried out many experiments in so many years. The problem is to make an agent move in an environment and achieve a predefined target. In general, this problem can be solved by Reinforcement Learning, the agent will receive an observation which contains several information such as image, depth, segmentation or sensor information, etc. Howerver, human want to make command for the agent through instruction, so the agent now has an additional information which is a text, or voice. The low-level instruction will be simple commands such as go straight, go left, go right, etc, but in practice, the instruction is more complex, it needs to consider other elements such as size, color, etc of the objects nearby. And that is the motivation of the Instruction Navigation problem. 2. Principle  The principle of Vision-Language problems is how to fuse multiple features together.  And with this problem, it composes of 3 components, (1) is to get image features, (2) is to get textual features, (3) is how to fuse these features together which is the most important part. In this paper, the fusion strategy they've used is concatenation and Hadarmard (element-wise) product. The final stage is the decision-making part, which employs a policy learning algorithm to make decision. A well-known but simple algorithm used in this situation is Asynchronous Actor Critic (A3C). 3. Methodology  The methodology simply takes an image and an instruction as inputs. Noted that, with each episode, there is only one instruction, but the image changes continually.   3.1 Image Representation Module In order to extract visual features, they employed a simple 3-layer CNN.\n  3.2 Text Representation Module In terms of extracting textual features, first, they employed Word Embedding on the text input, then converted it to sentence embedding by using LSTM or GRU.\n  3.3 Attented Representation Module\n  After getting a hold of 2 feature vectors, they use Hadardmard (element-wise) product to fuse the features together, and this is called Gated Attention.  3.4 Policy Learning  The policy learning will help the agent make decision which direction is going on. In this paper, the author use A3C, which is a well-known but simple reinforcement learning algorithm. 5. Application  This algorithm can be applied to robotics, however, this stll have some limits such as only handling short, and simple instructions. 6. Reference  Paper Code\n(TÃ­n Nguyá»…n) ","link":"fingerstin.org/post/rl/vision_language_navigation/","section":"post","tags":["Reinforcement Learning","Vision Language"],"title":"Instruction Navigation"},{"body":"","link":"fingerstin.org/tags/korea/","section":"tags","tags":null,"title":"korea"},{"body":"Láº§n Ä‘áº§u tiÃªn tháº¥y tuyáº¿t, wow, nÄƒm nay láº¡i lÃ  nÄƒm mÃ  Seoul láº¡nh ká»‰ lá»¥c, nhá»› khÃ´ng nháº§m lÃ  nhiá»‡t Ä‘á»™ rÆ¡i xuá»‘ng táº­n -2x Ä‘á»™ C. NÃ³i chung cáº£m giÃ¡c láº§n Ä‘áº§u tháº¥y tuyáº¿t rÆ¡i khÃ¡ thÃº vá»‹, nhÆ°ng mÃ¬nh láº¡i ko thÃ­ch láº¡nh nhÆ° tháº¿ vÃ¬ mÃ¬nh cÃ³ váº¥n Ä‘á» vá» mÅ©i, cá»™ng thÃªm ná»¯a lÃ  Ä‘i bá»™ má»™t mÃ¬nh dÆ°á»›i tuyáº¿t chÃ¡n tháº­t sá»± :smiling_face_with_tear:, náº¿u cÃ³ thÃªm báº¡n gÃ¡i Ä‘i cÃ¹ng ná»¯a thÃ¬ tuyá»‡t :rofl:.\n ","link":"fingerstin.org/post/personal/winter-korean-2020/","section":"post","tags":["korea","winter"],"title":"MÃ¹a Ä‘Ã´ng Ä‘áº§u tiÃªn táº¡i HÃ n Quá»‘c 12/2020"},{"body":"","link":"fingerstin.org/tags/reinforcement-learning/","section":"tags","tags":null,"title":"Reinforcement Learning"},{"body":"","link":"fingerstin.org/categories/reinforcement-learning/","section":"categories","tags":null,"title":"Reinforcement Learning"},{"body":"","link":"fingerstin.org/tags/winter/","section":"tags","tags":null,"title":"winter"},{"body":"Hi everyone, hÃ´m nay mÃ¬nh quyáº¿t Ä‘á»‹nh chia sáº½ vá» quÃ¡ trÃ¬nh xin há»c bá»•ng á»Ÿ HÃ n Quá»‘c cá»§a mÃ¬nh trong mÃ¹a dá»‹ch Covid 2020. NÃ³i sÆ¡ qua má»™t chÃºt, mÃ¬nh may máº¯n nháº­n Ä‘Æ°á»£c há»c bá»•ng giÃ¡o sÆ° táº¡i HQ vÃ o thÃ¡ng 9/2020 táº¡i trÆ°á»ng Ä‘áº¡i há»c Sejong ngÃ nh Computer Science and Engineering nhá» vÃ o sá»± giá»›i thiá»‡u cá»§a giÃ¡o sÆ° á»Ÿ trÆ°á»ng Ä‘áº¡i há»c cá»§a mÃ¬nh. VÃ  cÅ©ng may máº¯n khi giÃ¡o sÆ° trao mÃ¬nh há»c bá»•ng cÃ³ hÆ°á»›ng nghiÃªn cá»©u mÃ  mÃ¬nh Æ°a thÃ­ch Ä‘Ã³ lÃ  Computer Vision in Robotics, Drone.\nP/s: LÃºc Ä‘áº§u mÃ¬nh cÅ©ng ko muá»‘n Ä‘i qua HÃ n vÃ¬ khÃ¡ nhiá»u lÃ­ do, má»™t lÃ  Ä‘ang trong mÃ¹a dá»‹ch, mÃ¬nh cÅ©ng cháº£ muá»‘n Ä‘i Ä‘Ã¢u vÃ¬ sá»£ bá»‹ dÃ­nh covid, hai lÃ  cáº£m tháº¥y báº£n thÃ¢n chÆ°a Ä‘á»§ tá»‘t Ä‘á»ƒ Ä‘i há»c tiáº¿p lÃªn, ba lÃ  mÃ¬nh ko biáº¿t tiáº¿ng HÃ n, nhÆ°ng giÃ¡o sÆ° á»Ÿ VN cá»§a mÃ¬nh Ä‘Ã£ Ä‘á»™ng viÃªn vÃ  cÅ©ng tháº¥y nhiá»u a/c Ä‘Ã£ sang HÃ n vÃ  thÃ nh cÃ´ng nÃªn mÃ¬nh quyáº¿t Ä‘á»‹nh thá»­ sá»©c. Sau 2 nÄƒm, mÃ¬nh cáº£m tháº¥y Ä‘Ã¢y lÃ  má»™t quyáº¿t Ä‘á»‹nh bÆ°á»›c ngoáº·t cá»§a mÃ¬nh, vÃ¬ mÃ¬nh há»c Ä‘Æ°á»£c ráº¥t nhiá»u thá»©, ká»ƒ cáº£ kiáº¿n thá»©c láº«n kÄ© nÄƒng sá»‘ng á»Ÿ má»™t Ä‘áº¥t nÆ°á»›c xa láº¡.\n!(Sejong Computer Science Department)(/images/scholarship/sejong.jpg)\n1. Apply há»c bá»•ng Viá»‡c apply há»c bá»•ng giÃ¡o sÆ° Ä‘Æ¡n giáº£n hÆ¡n cÃ¡c loáº¡i há»c bá»•ng khÃ¡c, Ä‘Æ°Æ¡ng nhiÃªn lÃ  náº¿u há»“ sÆ¡ cá»§a báº¡n cÃ ng tá»‘t thÃ¬ kháº£ nÄƒng báº¡n Ä‘Æ°á»£c nháº­n cÃ ng cao. Táº¡i thá»i Ä‘iá»ƒm mÃ¬nh xin há»c bá»•ng, há»“ sÆ¡ cá»§a mÃ¬nh cÅ©ng khÃ´ng thuá»™c dáº¡ng quÃ¡ khá»§ng, mÃ¬nh chá»‰ cÃ³ 1 paper ná»™p á»Ÿ má»™t táº¡p chÃ­ quá»‘c táº¿ bÃ¬nh thÆ°á»ng, tiáº¿ng anh thÃ¬ cÃ³ báº±ng ielts 6.0, 1 CV, báº£ng Ä‘iá»ƒm thuá»™c dáº¡ng khÃ¡ vÃ  má»™t káº¿ hoáº¡ch há»c táº­p (study plan). NgoÃ i ra, náº¿u báº¡n cÃ³ thÃªm thÃ nh tÃ­ch, chá»©ng chá»‰ gÃ¬ thÃ¬ ná»™p thÃªm cÅ©ng Ä‘Æ°á»£c, miá»…n lÃ  tháº¥y nÃ³ phÃ¹ há»£p.\nKhi cÃ³ Ä‘á»§ giáº¥y tá» trÃªn, báº¡n cáº§n liÃªn láº¡c vá»›i giÃ¡o sÆ° sá»›m Ä‘á»ƒ ná»™p há»“ sÆ¡, náº¿u gs cháº¥p nháº­n thÃ¬ sáº½ phá»ng váº¥n Ä‘á»ƒ há»i vá» thÃ nh tÃ­ch cá»§a báº¡n, náº¿u gs Ä‘á»“ng Ã½ cho báº¡n há»c bá»•ng thÃ¬ 99% lÃ  báº¡n Ä‘i sang hq Ä‘Æ°á»£c rá»“i Ä‘áº¥y, 1% cÃ²n láº¡i lÃ  lÃ m cÃ¡c thá»§ tá»¥c cáº§n thiáº¿t Ä‘á»ƒ trÆ°á»ng xÃ©t vÃ  xin visa.\n2. Chuáº©n bá»‹ giáº¥y tá» ná»™p cho trÆ°á»ng Vá» pháº§n nÃ y thÃ¬ tÃ¹y tá»«ng trÆ°á»ng yÃªu cáº§u, báº¡n nÃªn lÃªn trang web cá»§a trÆ°á»ng Ä‘á»ƒ tÃ¬m hiá»ƒu hoáº·c liÃªn láº¡c vá»›i phÃ²ng quan há»‡ quá»‘c táº¿ cá»§a trÆ°á»ng Ä‘Ã³ Ä‘á»ƒ há»i cho cháº¯c. May máº¯n trÆ°á»ng mÃ¬nh xin vÃ o cÃ³ cá»™ng Ä‘á»“ng ngÆ°á»i Viá»‡t khÃ¡ nhiá»u nÃªn mÃ¬nh cÅ©ng Ä‘Æ°á»£c há» giÃºp Ä‘á»¡ giáº¥y tá» láº«n xin á»Ÿ kÃ­ tÃºc xÃ¡ á»Ÿ trÆ°á»ng. MÃ¬nh cáº£m tháº¥y khÃ¡ may máº¯n vÃ¬ mÃ¬nh khÃ´ng biáº¿t tiáº¿ng hÃ n vÃ  cÅ©ng Ä‘i trong mÃ¹a dá»‹ch nÃªn cÃ³ ráº¥t nhiá»u khÃ³ khÄƒn trong giao tiáº¿p vÃ  nÆ¡i á»Ÿ trong thá»i gian Ä‘áº§u qua HÃ n.\n3. Chá» giáº¥y má»i nháº­p há»c, Ä‘Ã³ng tiá»n vÃ  xin visa Sau khi xong 2 bÆ°á»›c trÃªn, thÃ¬ báº¡n pháº£i chá» 1,2 thÃ¡ng Ä‘á»ƒ trÆ°á»ng ra danh sÃ¡ch sinh viÃªn Ä‘áº­u vÃ o trÆ°á»ng, sau Ä‘Ã³ lÃ  Ä‘Ã³ng tiá»n vÃ  chá» giáº¥y bÃ¡o nháº­p há»c gá»­i vá», cuá»‘i cÃ¹ng lÃ  khÃ¡m sá»©c khá»e vÃ  xin visa.\n3. Xin Visa Khi xin visa, báº¡n nÃªn liÃªn há»‡ vá»›i trung tÃ¢m Ä‘Äƒng kÃ­ visa hÃ n quá»‘c (Korea Visa Application Center) Ä‘á»ƒ há»i cÃ¡c giáº¥y tá» cáº§n thiáº¿t thay vÃ¬ chá»‰ nghe má»™t chiá»u tá»« phÃ²ng quan há»‡ quá»‘c táº¿ cá»§a trÆ°á»ng mÃ  báº¡n du há»c, trÃ¡nh trÆ°á»ng há»£p pháº£i lÃ m Ä‘i lÃ m láº¡i giáº¥y tá». Trong trÆ°á»ng há»£p cá»§a mÃ¬nh, mÃ¬nh Ä‘Ã£ pháº£i máº¥t táº­n 5 láº§n má»›i hoÃ n thÃ nh Ä‘Æ°á»£c há»“ sÆ¡ xin visa, láº§n 1 thÃ¬ thiáº¿u giáº¥y báº£o lÃ£nh, giáº¥y sá»‘ dÆ° tÃ i khoáº£n vÃ  giáº¥y chá»©ng nháº­n RA (Research Assistant), láº§n 2 thÃ¬ sai form giáº¥y báº£o lÃ£nh cá»§a trung tÃ¢m visa, thiáº¿u giáº¥y chá»©ng nháº­n con dáº¥u cá»§a giÃ¡o sÆ° (cÃ¡i nÃ y giÃ¡o sÆ° pháº£i ra cÆ¡ quan Ä‘á»‹a phÆ°Æ¡ng xin), láº§n 3 thÃ¬ do con dáº¥u trong giáº¥y báº£o lÃ£nh khÃ´ng khá»›p vá»›i giáº¥y chÆ°ng nháº­n con dáº¥u (do 1 giÃ¡o sÆ° cÃ³ thá»ƒ cÃ³ nhiá»u con dáº¥u), láº§n 4 thÃ¬ bÃªn trung tÃ¢m visa khÃ´ng cháº¥p nháº­n giáº¥y Chá»©ng nháº­n RA vÃ  giáº¥y báº£o lÃ£nh vÃ¬ thá»i Ä‘iá»ƒm mÃ  giÃ¡o sÆ° kÃ­ 2 giáº¥y Ä‘Ã³ quÃ¡ 3 thÃ¡ng gáº§n nháº¥t, tháº¿ lÃ  mÃ¬nh pháº£i nhá» gs gá»­i láº¡i 2 báº£n má»›i vá»›i thá»i Ä‘iá»ƒm Ä‘Æ°á»£c cáº­p nháº­t, vÃ  tá»›i láº§n 5 thÃ¬ má»›i oke.  P/s: CÃ¡ nhÃ¢n mÃ¬nh tháº¥y trung tÃ¢m Visa lÃ m viá»‡c khÃ¡ thiáº¿u chuyÃªn nghiá»‡p, nhá»¯ng thÃ´ng tin nÃ y ko há» Ä‘Æ°á»£c ghi trÃªn web, nhÃ¢n viÃªn thÃ¬ ko nÃ³i rÃµ rÃ ng Ä‘á»ƒ trÃ¡nh viá»‡c xin Ä‘i xin láº¡i. VÃ  riÃªng Ä‘á»‘i vá»›i mÃ¬nh, cay nháº¥t lÃ  á»Ÿ láº§n xin visa thá»© 3, bÃªn KVAC cÃ³ báº£o mÃ¬nh bá»• sung má»™t loáº¡i giáº¥y tá» thá»ƒ hiá»‡n thÃ´ng tin cá»§a gs vÃ  mÃ¬nh, nhÆ°ng tá»›i láº§n 4 lÃªn ná»™p thÃ¬ trung tÃ¢m láº¡i báº£o khÃ´ng cáº§n giáº¥y Ä‘Ã³ ná»¯a. VÃ¬ váº­y, cÃ¡c báº¡n nÃªn há»i tháº­t kÄ© trung tÃ¢m nhÃ©.\nTrÃªn Ä‘Ã¢y lÃ  nhá»¯ng kinh nghiá»‡m Ä‘Ãºt káº¿t cá»§a mÃ¬nh, báº¡n nÃ o cÃ³ Ã½ Ä‘á»‹nh sang HÃ n hÃ£y tÃ¬m hiá»ƒu ká»¹ nhÃ©. Good luck!\n(TÃ­n Nguyá»…n) ","link":"fingerstin.org/post/personal/korea_prof_scholarship/","section":"post","tags":["scholarship","korea"],"title":"Professor Scholarship in Korea"},{"body":"","link":"fingerstin.org/archives/","section":"","tags":null,"title":""},{"body":"Written in Go, Hugo is an open source static site generator available under the Apache Licence 2.0. Hugo supports TOML, YAML and JSON data file types, Markdown and HTML content files and uses shortcodes to add rich content. Other notable features are taxonomies, multilingual mode, image processing, custom output formats, HTML/CSS/JS minification and support for Sass SCSS workflows.\nHugo makes use of a variety of open source projects including:\n https://github.com/yuin/goldmark https://github.com/alecthomas/chroma https://github.com/muesli/smartcrop https://github.com/spf13/cobra https://github.com/spf13/viper  Hugo is ideal for blogs, corporate websites, creative portfolios, online magazines, single page applications or even a website with thousands of pages.\nHugo is for people who want to hand code their own website without worrying about setting up complicated runtimes, dependencies and databases.\nWebsites built with Hugo are extremelly fast, secure and can be deployed anywhere including, AWS, GitHub Pages, Heroku, Netlify and any other hosting provider.\nLearn more and contribute on GitHub.\n","link":"fingerstin.org/about/","section":"","tags":null,"title":"About"},{"body":"Using Notices functionality within this theme\nThe \u0026quot;Notices\u0026quot; shortcode enables you to call out pieces of information - sidebars, warnings, tips, etc.\nTo create a notice on a page, you can use the notice shortcode.\nYou use the notice shortcode, with the first parameter being one of note, info, tip, and warning. Then add a title for your note in quotes as the second parameter. The inner body of the note can be whatever markdown you want to create.\nThe following shortcode syntax within a markdown doc:\n1{{% notice note \u0026#34;Note\u0026#34; %}} 2This is a standard \u0026#34;note\u0026#34; style. 3{{% /notice %}} will render as:\nNote This is a standard \u0026quot;note\u0026quot; style.\n The other three variants follow.\nInfo Here is the \u0026quot;info\u0026quot; style.\n Tip Here is a \u0026quot;tip\u0026quot; variant of a notice.\n Warning Here is the \u0026quot;warning\u0026quot; flavor of a notice.\n Also note that the content of a notice can contain anything you could put on a normal page - as shown below:\nComplex Notices are Possible! This is a notice that has a lot of various kinds of content in it.\n Here is a bulleted list With more than one bullet  And even more than one level    Code blocks are fine here, too....\n1public void SayHello() 2{ 3Console.WriteLine(\u0026#34;Hello, world!\u0026#34;); 4}   Productivity Booster! If you're using VS Code for your editing, copy the .vscode\\clarity.code-snippets file into a .vscode root folder on your repo. This will enable you to type note then \u0026lt;tab\u0026gt; then choose with up/down arrows which flavor notice you want, then \u0026lt;tab\u0026gt; again to provide a title, then \u0026lt;tab\u0026gt; to add your content!\n    To use the snippet, you need to first enable quickSuggestions for Markdown (one time only):\n Go to Preferences-\u0026gt;Settings then search for quickSuggestions Follow the link to Edit in settings.json Toward the bottom of the file, paste in the following JSON:  1\u0026#34;[markdown]\u0026#34;: { 2\u0026#34;editor.quickSuggestions\u0026#34;: true 3} Close and save the settings.    Emoji can be enabled in a Hugo project in a number of ways.\nThe emojify function can be called directly in templates or Inline Shortcodes.\nTo enable emoji globally, set enableEmoji to true in your site's configuration and then you can type emoji shorthand codes directly in content files; e.g.\nğŸ™ˆ :see_no_evil: ğŸ™‰ :hear_no_evil: ğŸ™Š :speak_no_evil:\nThe Emoji cheat sheet is a useful reference for emoji shorthand codes.\n N.B. The above steps enable Unicode Standard emoji characters and sequences in Hugo, however the rendering of these glyphs depends on the browser and the platform. To style the emoji you can either use a third party emoji font or a font stack; e.g.\n1.emoji { 2font-family: Apple Color Emoji, Segoe UI Emoji, NotoColorEmoji, Segoe UI Symbol, Android Emoji, EmojiSymbols; 3}  Mathematical notation in a Hugo project can be enabled by using third party JavaScript libraries.\n In this example we will be using KaTeX\n Create a partial under /layouts/partials/math.html Within this partial reference the Auto-render Extension or host these scripts locally. Include the partial in your templates like so:  1{{ if or .Params.math .Site.Params.math }} 2{{ partial \u0026#34;math.html\u0026#34; . }} 3{{ end }}  To enable KaTex globally set the parameter math to true in a project's configuration To enable KaTex on a per page basis include the parameter math: true in content files  Note: Use the online reference of Supported TeX Functions\nExamples Block math: $$ \\varphi = 1+\\frac{1} {1+\\frac{1} {1+\\frac{1} {1+\\cdots} } } $$\n This article offers a sample of basic Markdown syntax that can be used in Hugo content files, also it shows whether basic HTML elements are decorated with CSS in a Hugo theme.\n Headings The following HTML \u0026lt;h1\u0026gt;â€”\u0026lt;h6\u0026gt; elements represent six levels of section headings. \u0026lt;h1\u0026gt; is the highest section level while \u0026lt;h6\u0026gt; is the lowest.\nH1 H2 H3 H4 H5 H6 Paragraph Xerum, quo qui aut unt expliquam qui dolut labo. Aque venitatiusda cum, voluptionse latur sitiae dolessi aut parist aut dollo enim qui voluptate ma dolestendit peritin re plis aut quas inctum laceat est volestemque commosa as cus endigna tectur, offic to cor sequas etum rerum idem sintibus eiur? Quianimin porecus evelectur, cum que nis nust voloribus ratem aut omnimi, sitatur? Quiatem. Nam, omnis sum am facea corem alique molestrunt et eos evelece arcillit ut aut eos eos nus, sin conecerem erum fuga. Ri oditatquam, ad quibus unda veliamenimin cusam et facea ipsamus es exerum sitate dolores editium rerore eost, temped molorro ratiae volorro te reribus dolorer sperchicium faceata tiustia prat.\nItatur? Quiatae cullecum rem ent aut odis in re eossequodi nonsequ idebis ne sapicia is sinveli squiatum, core et que aut hariosam ex eat.\nImages Local image, alt text as caption The following image is located within the Hugo site. Because it has alt text but no title text, the caption is generated by the alt text.\n    Remote image, specified caption The following image is loaded from a remote URL. The alt text is the same (for screen readers and in cases when the image doesn't load) but because a separate title is provided, the title is used for the caption:\n  This is Jane Doe  Image with alt text and no caption Alt text is always recommended for SEO, accessibility and in cases when images don't load. However, you don't necessarily always want an image to have a caption. In that case, use a title with one space:\n    Blockquotes The blockquote element represents content that is quoted from another source, optionally with a citation which must be within a footer or cite element, and optionally with in-line changes such as annotations and abbreviations.\nBlockquote without attribution  Tiam, ad mint andaepu dandae nostion secatur sequo quae. Note that you can use Markdown syntax within a blockquote.\n Blockquote with attribution  Don't communicate by sharing memory, share memory by communicating.\nâ€” Rob Pike1\n Tables Tables aren't part of the core Markdown spec, but Hugo supports supports them out-of-the-box.\n   Name Age     Bob 27   Alice 23    Inline Markdown within tables    Italics Bold Code     italics bold code    Code Blocks Code block with backticks 1\u0026lt;!doctype html\u0026gt; 2\u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; 3\u0026lt;head\u0026gt; 4\u0026lt;meta charset=\u0026#34;utf-8\u0026#34;\u0026gt; 5\u0026lt;title\u0026gt;Example HTML5 Document\u0026lt;/title\u0026gt; 6\u0026lt;/head\u0026gt; 7\u0026lt;body\u0026gt; 8\u0026lt;p\u0026gt;Test\u0026lt;/p\u0026gt; 9\u0026lt;/body\u0026gt; 10\u0026lt;!-- this line is extraneous 2Error from server (Forbidden): deployments.apps is forbidden: User \u0026#34;chiptest\u0026#34; cannot create resource \u0026#34;deployments\u0026#34; in API group \u0026#34;apps\u0026#34; in the namespace \u0026#34;default\u0026#34; --\u0026gt; 11\u0026lt;/html\u0026gt; Code block indented with four spaces \u0026lt;!doctype html\u0026gt; \u0026lt;html lang=\u0026quot;en\u0026quot;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026quot;utf-8\u0026quot;\u0026gt; \u0026lt;title\u0026gt;Example HTML5 Document\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;Test\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt;  Code block with Hugo's internal highlight shortcode 1\u0026lt;!doctype html\u0026gt; 2\u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; 3\u0026lt;head\u0026gt; 4\u0026lt;meta charset=\u0026#34;utf-8\u0026#34;\u0026gt; 5\u0026lt;title\u0026gt;Example HTML5 Document\u0026lt;/title\u0026gt; 6\u0026lt;/head\u0026gt; 7\u0026lt;body\u0026gt; 8\u0026lt;p\u0026gt;Test\u0026lt;/p\u0026gt; 9\u0026lt;/body\u0026gt; 10\u0026lt;/html\u0026gt; List Types Ordered List  First item Second item Third item  Unordered List  List item Another item And another item  Nested list  Fruit  Apple Orange Banana   Dairy  Milk Cheese    Other Elements â€” abbr, sub, sup, kbd, mark GIF is a bitmap image format.\nH2O\nXn + Yn = Zn\nPress CTRL+ALT+Delete to end the session.\nMost salamanders are nocturnal, and hunt for insects, worms, and other small creatures.\n Lorem est tota propiore conpellat pectoribus de pectora summo. Redit teque digerit hominumque toris verebor lumina non cervice subde tollit usus habet Arctonque, furores quas nec ferunt. Quoque montibus nunc caluere tempus inhospita parcite confusaque translucet patri vestro qui optatis lumine cognoscere flos nubis! Fronde ipsamque patulos Dryopen deorum.\n Exierant elisi ambit vivere dedere Duce pollice Eris modo Spargitque ferrea quos palude  Rursus nulli murmur; hastile inridet ut ab gravi sententia! Nomine potitus silentia flumen, sustinet placuit petis in dilapsa erat sunt. Atria tractus malis.\n Comas hunc haec pietate fetum procerum dixit Post torum vates letum Tiresia Flumen querellas Arcanaque montibus omnes Quidem et  Vagus elidunt \nThe Van de Graaf Canon\nMane refeci capiebant unda mulcebat Victa caducifer, malo vulnere contra dicere aurato, ludit regale, voca! Retorsit colit est profanae esse virescere furit nec; iaculi matertera et visa est, viribus. Divesque creatis, tecta novat collumque vulnus est, parvas. Faces illo pepulere tempus adest. Tendit flamma, ab opes virum sustinet, sidus sequendo urbis.\nIubar proles corpore raptos vero auctor imperium; sed et huic: manus caeli Lelegas tu lux. Verbis obstitit intus oblectamina fixis linguisque ausus sperare Echionides cornuaque tenent clausit possit. Omnia putatur. Praeteritae refert ausus; ferebant e primus lora nutat, vici quae mea ipse. Et iter nil spectatae vulnus haerentia iuste et exercebat, sui et.\nEurytus Hector, materna ipsumque ut Politen, nec, nate, ignari, vernum cohaesit sequitur. Vel mitis temploque vocatus, inque alis, oculos nomen non silvis corpore coniunx ne displicet illa. Crescunt non unus, vidit visa quantum inmiti flumina mortis facto sic: undique a alios vincula sunt iactata abdita! Suspenderat ego fuit tendit: luna, ante urbem Propoetides parte.\n Hugo ships with several Built-in Shortcodes for rich content, along with a Privacy Config and a set of Simple Shortcodes that enable static and no-JS versions of various social media embeds.\n  Instagram Simple Shortcode  YouTube Privacy Enhanced Shortcode    Twitter Simple Shortcode Owl bet you\u0026#39;ll lose this staring contest ğŸ¦‰ pic.twitter.com/eJh4f2zncC\n\u0026mdash; San Diego Zoo Wildlife Alliance (@sandiegozoo) October 26, 2021  See documentation https://gohugo.io/content-management/shortcodes/#tweet for more details\n Vimeo Simple Shortcode  .__h_video { position: relative; padding-bottom: 56.23%; height: 0; overflow: hidden; width: 100%; background: #000; } .__h_video img { width: 100%; height: auto; color: #000; } .__h_video .play { height: 72px; width: 72px; left: 50%; top: 50%; margin-left: -36px; margin-top: -36px; position: absolute; cursor: pointer; }    Page bundles are an optional way to organize page resources within Hugo.\nYou can opt-in to using page bundles in Hugo Clarity with usePageBundles in your site configuration or in a page's front matter. Read more about usePageBundles.\nWith page bundles, resources for a page or section, like images or attached files, live in the same directory as the content itself rather than in your static directory.\nHugo Clarity supports the use of leaf bundles, which are any directories within the content directory that contain an index.md file. Hugo's documentation gives this example:\n1content 2â”œâ”€â”€ about 3â”‚ â”œâ”€â”€ index.md 4â”œâ”€â”€ posts 5â”‚ â”œâ”€â”€ my-post 6â”‚ â”‚ â”œâ”€â”€ content1.md 7â”‚ â”‚ â”œâ”€â”€ content2.md 8â”‚ â”‚ â”œâ”€â”€ image1.jpg 9â”‚ â”‚ â”œâ”€â”€ image2.png 10â”‚ â”‚ â””â”€â”€ index.md 11â”‚ â””â”€â”€ my-other-post 12â”‚ â””â”€â”€ index.md 13â”‚ 14â””â”€â”€ another-section 15â”œâ”€â”€ .. 16â””â”€â”€ not-a-leaf-bundle 17â”œâ”€â”€ .. 18â””â”€â”€ another-leaf-bundle 19â””â”€â”€ index.md  In the above example `content` directory, there are four leaf bundles: about: This leaf bundle is at the root level (directly under content directory) and has only the index.md.\nmy-post: This leaf bundle has the index.md, two other content Markdown files and two image files. image1 is a page resource of my-post and only available in my-post/index.md resources. image2 is a page resource of my-post and only available in my-post/index.md resources.\nmy-other-post: This leaf bundle has only the index.md.\nanother-leaf-bundle: This leaf bundle is nested under couple of directories. This bundle also has only the index.md.\nThe hierarchy depth at which a leaf bundle is created does not matter, as long as it is not inside another leaf bundle.\n Advantages to using page bundles The image below is part of the bundle of this page, and is located at content/post/bundle/building.png. Because it's within this page's bundle, the markup for the image only has to specify the image's filename, building.png.\n    If you ever change the name of the directory in which this Markdown file and the image reside, the reference to the image would not need to be updated.\nIn addition to more cleanly organizing your content and related assets, when using page bundles, Hugo Clarity will automatically generate markup for modern image formats, which are smaller in file size.\nFor instance, when you reference an image like building.png, Hugo Clarity will check to see if the same image (based on filename) exists in WebP, AVIF or JXL formats. If you inspect the image above, you'll see a \u0026lt;source\u0026gt; element for building.webp, because that file is also present. Hugo Clarity will only include the markup if these images exist.\nBrowsers that support these formats and the \u0026lt;picture\u0026gt; element will load them, while browsers that do not will fall-back to the default image. Read more about this process.\nFinally, note that page assets can be further managed and refined within the page's front matter if you wish, and are not limited to images alone.\nDisadvantages to using page bundles Page resources in a bundle are only available to the page with which they are bundled â€” that means you can't include an image with one page and then reference it from another.\nImages that are being used in multiple places are more appropriate for your Hugo assets directory. Unlike files in the Hugo static directory, files in the assets directory can be run through Hugo Pipes, which includes image processing.\n  The above quote is excerpted from Rob Pike's talk during Gopherfest, November 18, 2015.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n  ","link":"fingerstin.org/post/hugo_guidance/","section":"post","tags":null,"title":"Hugo Usage"},{"body":"","link":"fingerstin.org/tags/index/","section":"tags","tags":null,"title":"index"}]